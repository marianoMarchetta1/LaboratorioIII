{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Este baseline se basara en armar un modelo LSTM por cada producto, con una optimizacion de hiper parametros escueta, para poder comparar con futuros experimientos. En caso de que esta alternativa funcione bien, seria recomendable incorporar parametros de optimizacion extra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.read_csv('../../Datasets/final_dataset.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>y</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>stock_final</th>\n",
       "      <th>close_quarter</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>479</td>\n",
       "      <td>937.72717</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201702</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>833.72187</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201703</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>509</td>\n",
       "      <td>1330.74697</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201704</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>1132.94430</td>\n",
       "      <td>1069.96130</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201705</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>701</td>\n",
       "      <td>1550.68936</td>\n",
       "      <td>1502.20132</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   periodo  product_id  plan_precios_cuidados  cust_request_qty  \\\n",
       "0   201701       20001                      0               479   \n",
       "1   201702       20001                      0               432   \n",
       "2   201703       20001                      0               509   \n",
       "3   201704       20001                      0               279   \n",
       "4   201705       20001                      0               701   \n",
       "\n",
       "   cust_request_tn           y cat1         cat2     cat3  brand  sku_size  \\\n",
       "0        937.72717   934.77222   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "1        833.72187   798.01620   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "2       1330.74697  1303.35771   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "3       1132.94430  1069.96130   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "4       1550.68936  1502.20132   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "\n",
       "   stock_final  close_quarter  age  \n",
       "0          NaN              0    0  \n",
       "1          NaN              0    1  \n",
       "2          NaN              1    2  \n",
       "3          NaN              0    3  \n",
       "4          NaN              0    4  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['plan_precios_cuidados', 'cust_request_qty', 'cust_request_tn', 'close_quarter', 'age', 'y']\n",
    "columns = ['plan_precios_cuidados', 'cust_request_qty', 'cust_request_tn', 'close_quarter','y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion para preparar los datos y crear el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es predecir 2 dias en el futuro, por lo que la idea es re-armar el dataset. Donde el valor de X sera el conjunto de datos desde i-0 hasta i-n, y el valor de \"y\" sera el valor de \"y\" 2 meses en el futuro ( i+2 )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix >= len(data):\n",
    "            break\n",
    "        seq_x, seq_y = data[:i+1, :], data[end_ix, -1]  # y es 2 periodos en el futuro\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X, dtype=object), np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la funcion para crear el modelo LSTM, sobre este se ejecutara la optimizacion bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    penalty = K.mean(K.square(K.minimum(y_pred, 0)), axis=-1)\n",
    "    mse_loss = K.mean(K.square(y_true - y_pred), axis=-1)\n",
    "    return mse_loss + penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation='relu', units=128, dropout=0.2, learning_rate=0.001, l2_penalty=0.001, depth=3, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(units/2), activation=activation, input_shape=(None, n_features), return_sequences=True, kernel_regularizer=l2(l2_penalty)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    for _ in range(depth - 1):\n",
    "        model.add(LSTM(units=units, activation=activation, return_sequences=True, kernel_regularizer=l2(l2_penalty)))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LSTM(units=int(units*2), activation=activation, kernel_regularizer=l2(l2_penalty)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='relu'))  # Unidades de salida ajustadas a 1 para regresión\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armado de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2  # número de pasos de tiempo\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Codigo para visualizar como queda la estructura de X e y para 1 producto en particular\n",
    "# product_ids = final_dataset['product_id'].unique()\n",
    "# product_id = product_ids[0]\n",
    "# product_data = final_dataset[final_dataset['product_id'] == product_id].sort_values(by='periodo')[columns]\n",
    "# product_data_array = product_data.values\n",
    "# X, y = prepare_data(product_data_array, n_steps)\n",
    "\n",
    "# display(product_data)\n",
    "# display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Modelo para el producto 20001 entrenado y guardado. Predicción a 2 meses: 23.417675018310547\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20002 entrenado y guardado. Predicción a 2 meses: 207.6094970703125\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20003 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20004 entrenado y guardado. Predicción a 2 meses: 817.0665893554688\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "Modelo para el producto 20005 entrenado y guardado. Predicción a 2 meses: 772.1746826171875\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20006 entrenado y guardado. Predicción a 2 meses: 18.655494689941406\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "Modelo para el producto 20007 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20008 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "Modelo para el producto 20009 entrenado y guardado. Predicción a 2 meses: 1210.3585205078125\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Modelo para el producto 20010 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20011 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20012 entrenado y guardado. Predicción a 2 meses: 6.794393062591553\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20013 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Modelo para el producto 20014 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "Modelo para el producto 20015 entrenado y guardado. Predicción a 2 meses: 114.26605224609375\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20016 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "Modelo para el producto 20017 entrenado y guardado. Predicción a 2 meses: 7.353462219238281\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20018 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Modelo para el producto 20019 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20020 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20021 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20022 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Modelo para el producto 20023 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20024 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 10s 10s/step\n",
      "Modelo para el producto 20025 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20026 entrenado y guardado. Predicción a 2 meses: 6.430136203765869\n",
      "1/1 [==============================] - 12s 12s/step\n",
      "Modelo para el producto 20027 entrenado y guardado. Predicción a 2 meses: 36.811309814453125\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Modelo para el producto 20028 entrenado y guardado. Predicción a 2 meses: 33.42327117919922\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20029 entrenado y guardado. Predicción a 2 meses: 2.9641273021698\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20030 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 12s 12s/step\n",
      "Modelo para el producto 20031 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20033 entrenado y guardado. Predicción a 2 meses: 3.0583112239837646\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20035 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20037 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 12s 12s/step\n",
      "Modelo para el producto 20038 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "Modelo para el producto 20039 entrenado y guardado. Predicción a 2 meses: 8.015315055847168\n",
      "1/1 [==============================] - 12s 12s/step\n",
      "Modelo para el producto 20041 entrenado y guardado. Predicción a 2 meses: 5.556856632232666\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20042 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20043 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20044 entrenado y guardado. Predicción a 2 meses: 87.22306823730469\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20045 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Modelo para el producto 20046 entrenado y guardado. Predicción a 2 meses: 0.5313089489936829\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20047 entrenado y guardado. Predicción a 2 meses: 134.07814025878906\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "Modelo para el producto 20050 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20051 entrenado y guardado. Predicción a 2 meses: 119.46531677246094\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20052 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 12s 12s/step\n",
      "Modelo para el producto 20053 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20054 entrenado y guardado. Predicción a 2 meses: 30.980419158935547\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "Modelo para el producto 20055 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "Modelo para el producto 20056 entrenado y guardado. Predicción a 2 meses: 29.899333953857422\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20057 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "Modelo para el producto 20058 entrenado y guardado. Predicción a 2 meses: 31.623897552490234\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20059 entrenado y guardado. Predicción a 2 meses: 127.37657928466797\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Modelo para el producto 20061 entrenado y guardado. Predicción a 2 meses: 157.4052276611328\n",
      "1/1 [==============================] - 13s 13s/step\n",
      "Modelo para el producto 20062 entrenado y guardado. Predicción a 2 meses: 0.0\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Modelo para el producto 20063 entrenado y guardado. Predicción a 2 meses: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m last_record \u001b[38;5;241m=\u001b[39m last_record\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, last_record\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], last_record\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# predicted_y = best_model.predict(last_record)[0][0]\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m predicted_y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_record\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Agregar predicción al resultado\u001b[39;00m\n\u001b[1;32m     82\u001b[0m predictions\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m: product_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_y\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted_y})\n",
      "File \u001b[0;32m~/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/keras/src/engine/training.py:2554\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2552\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2553\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2554\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2556\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:897\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    893\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_function_spec  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    894\u001b[0m       \u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    895\u001b[0m           args, kwds))\n\u001b[1;32m    896\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[0;32m--> 897\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    898\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds, inner_filtered_flat_args):\n\u001b[1;32m    902\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "product_ids = final_dataset['product_id'].unique()\n",
    "    \n",
    "for product_id in product_ids:\n",
    "    product_data = final_dataset[final_dataset['product_id'] == product_id].sort_values(by='periodo')[columns]\n",
    "    \n",
    "    # Convertir los datos a numpy array\n",
    "    product_data_array = product_data.values\n",
    "    \n",
    "    # Preparar los datos para LSTM\n",
    "    X, y = prepare_data(product_data_array, n_steps)\n",
    "    n_features = product_data_array.shape[1]  # Número de características por observación\n",
    "    \n",
    "    # def build_model(hp):\n",
    "    #     # activation = hp.Choice('activation', ['relu', 'tanh', 'swish', 'selu'])\n",
    "    #     # units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    #     # dropout = hp.Float('dropout', min_value=0.1, max_value=0.4, step=0.1)\n",
    "    #     # learning_rate = hp.Choice('learning_rate', [0.01, 0.001, 0.0001])\n",
    "    #     # l2_penalty = hp.Choice('l2_penalty', [0.001, 0.01, 0.1])\n",
    "    #     # depth = hp.Int('depth', min_value=2, max_value=5)\n",
    "    #     # optimizer = hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
    "        \n",
    "    #     #DEFINO UNA CANTIDAD MENOR DE PARAMETROS PARA PRUEBA DE CONCEPTO,\n",
    "    #     #DESPUES SERIA MEJOR PROBAR LA OPTIMIZACION COMPLETA DE ARRIBA.\n",
    "    #     activation = hp.Choice('activation', ['relu'])\n",
    "    #     units = hp.Choice('units', [32])\n",
    "    #     dropout = hp.Choice('dropout', [0.1])\n",
    "    #     learning_rate = hp.Choice('learning_rate', [0.01])\n",
    "    #     l2_penalty = hp.Choice('l2_penalty', [0.01])\n",
    "    #     depth = hp.Choice('depth', [2])\n",
    "    #     optimizer = hp.Choice('optimizer', ['adam'])\n",
    "\n",
    "    #     return create_model(activation, units, dropout, learning_rate, l2_penalty, depth, optimizer)\n",
    "\n",
    "    # # Definir la búsqueda de hiperparámetros\n",
    "    # tuner = BayesianOptimization(\n",
    "    #     build_model,\n",
    "    #     objective='val_loss',\n",
    "    #     max_trials=1,  # número de combinaciones de hiperparámetros a probar, lo pongo en 1 para la primer prueba\n",
    "    #     executions_per_trial=2,\n",
    "    #     directory='bayesian_optimization',\n",
    "    #     project_name=f'product_{product_id}'\n",
    "    # )\n",
    "    model = create_model()\n",
    "\n",
    "    # Callback para detener el entrenamiento temprano\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
    "\n",
    "    # Convertir X a una lista de arrays para que funcione con keras tuner\n",
    "    X_list = [x.tolist() for x in X]\n",
    "\n",
    "    # Realizar la búsqueda de hiperparámetros\n",
    "    # tuner.search(np.array(X_list, dtype=object), y, epochs=epochs, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "    # Obtener el mejor modelo\n",
    "    # best_trials = tuner.oracle.get_best_trials()\n",
    "    # if not best_trials:\n",
    "    #     print(f\"No se encontraron modelos válidos para el producto {product_id}\")\n",
    "    #     continue\n",
    "\n",
    "    max_length = max(len(seq) for seq in X)\n",
    "    X_padded = np.array([np.pad(seq, ((max_length - len(seq), 0), (0, 0)), 'constant') for seq in X])\n",
    "\n",
    "    # best_model = tuner.load_model(best_trials[0])\n",
    "    model.fit(X_padded, y, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping, reduce_lr], verbose= 0)\n",
    "\n",
    "\n",
    "    # Guardar el modelo\n",
    "    os.makedirs('Models_params', exist_ok=True)\n",
    "    # best_model.save(f'Models_params/model_product_{product_id}.h5')\n",
    "    model.save(f'Models_params/model_product_{product_id}.h5')\n",
    "\n",
    "    last_record = product_data_array\n",
    "    last_record = last_record.reshape((1, last_record.shape[0], last_record.shape[1]))\n",
    "    # predicted_y = best_model.predict(last_record)[0][0]\n",
    "    predicted_y = model.predict(last_record)[0][0]\n",
    "\n",
    "    # Agregar predicción al resultado\n",
    "    predictions.append({'product_id': product_id, 'predicted_y': predicted_y})\n",
    "\n",
    "    print(f'Modelo para el producto {product_id} entrenado y guardado. Predicción a 2 meses: {predicted_y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las predicciones han sido generadas y guardadas en predictions.csv.\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.to_csv('../../Datasets/predictions.csv', index=False)\n",
    "\n",
    "print('Todas las predicciones han sido generadas y guardadas en predictions.csv.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
