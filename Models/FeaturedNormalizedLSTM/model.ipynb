{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea de esta variante, es predecir solamente los productos que tengan mas de 12 meses de datos (usando los ultimos 12 solamente), y aquellos con menos datos, predecir la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from skopt import BayesSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.metrics import MeanSquaredError\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization\n",
    "from skopt.space import Categorical\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.read_csv('../../Datasets/final_dataset.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset['periodo'] = pd.to_datetime(final_dataset['periodo'], format='%Y%m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promediamos las vtas de agosto, como las de julio y setpiembre\n",
    "july_september_data = final_dataset[\n",
    "    final_dataset['periodo'].isin([pd.Timestamp('2019-07-01'), pd.Timestamp('2019-09-01')])\n",
    "]\n",
    "\n",
    "# Agrupar por producto y calcular el promedio\n",
    "august_average = july_september_data.groupby('product_id')['y'].mean().reset_index()\n",
    "august_average['periodo'] = pd.Timestamp('2019-08-01')\n",
    "\n",
    "# Reemplazar los valores de agosto en el DataFrame original\n",
    "final_dataset = final_dataset.set_index(['product_id', 'periodo'])\n",
    "final_dataset.update(august_average.set_index(['product_id', 'periodo']))\n",
    "final_dataset = final_dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agreog el MES del quarter, en vez de si es close_quarter\n",
    "final_dataset['month'] = final_dataset['periodo'].dt.month\n",
    "\n",
    "def month_in_quarter(month):\n",
    "    if month in [1, 4, 7, 10]:\n",
    "        return 1  # Primer mes del trimestre\n",
    "    elif month in [2, 5, 8, 11]:\n",
    "        return 2  # Segundo mes del trimestre\n",
    "    elif month in [3, 6, 9, 12]:\n",
    "        return 3  # Tercer mes del trimestre\n",
    "\n",
    "final_dataset['month_in_quarter'] = final_dataset['month'].apply(month_in_quarter)\n",
    "\n",
    "# Remover la columna 'month' si no es necesaria\n",
    "final_dataset = final_dataset.drop(columns=['month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['plan_precios_cuidados', 'cust_request_qty', 'cust_request_tn', 'month_in_quarter', 'brand', 'sku_size', 'cat1', 'cat2', 'cat3','y'] #'close_quarter'\n",
    "non_scalable_columns = ['cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'plan_precios_cuidados', 'month_in_quarter'] # 'close_quarter'\n",
    "n_features = len(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valido el promedio de agosto (este es el mes en que la empresa decidio no vender por unos dias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los datos para los productos en julio, agosto y septiembre de 2020\n",
    "august_data = final_dataset[\n",
    "    final_dataset['periodo'] == pd.Timestamp('2019-08-01')\n",
    "]\n",
    "\n",
    "july_data = final_dataset[\n",
    "    final_dataset['periodo'] == pd.Timestamp('2019-07-01')\n",
    "]\n",
    "\n",
    "september_data = final_dataset[\n",
    "    final_dataset['periodo'] == pd.Timestamp('2019-09-01')\n",
    "]\n",
    "\n",
    "# Mostrar algunos datos de agosto para revisar que el promedio se haya aplicado\n",
    "print(\"Datos de agosto de 2019:\")\n",
    "display(august_data.head())\n",
    "\n",
    "# Mostrar algunos datos de julio para comparar\n",
    "print(\"\\nDatos de julio de 2019:\")\n",
    "display(july_data.head())\n",
    "\n",
    "# Mostrar algunos datos de septiembre para comparar\n",
    "print(\"\\nDatos de septiembre de 2019:\")\n",
    "display(september_data.head())\n",
    "\n",
    "# Verificar el cálculo del promedio manualmente para algunos productos\n",
    "product_ids = august_data['product_id'].unique()\n",
    "\n",
    "for product_id in product_ids[:5]:  # Limitar a los primeros 5 productos para revisar\n",
    "    july_sales = july_data[july_data['product_id'] == product_id]['y'].values\n",
    "    september_sales = september_data[september_data['product_id'] == product_id]['y'].values\n",
    "    august_sales = august_data[august_data['product_id'] == product_id]['y'].values\n",
    "\n",
    "    print(f\"\\nProducto ID: {product_id}\")\n",
    "    print(f\"Ventas de julio: {july_sales}\")\n",
    "    print(f\"Ventas de septiembre: {september_sales}\")\n",
    "    print(f\"Ventas de agosto (calculadas): {august_sales}\")\n",
    "    if len(july_sales) > 0 and len(september_sales) > 0:\n",
    "        calculated_average = (july_sales[0] + september_sales[0]) / 2\n",
    "        print(f\"Promedio calculado: {calculated_average}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muetro cual es el primer mes de venta de cada producto, para debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_months = final_dataset.groupby('product_id')['periodo'].min().reset_index()\n",
    "first_months.columns = ['product_id', 'first_month']\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Primer mes de cada producto:\")\n",
    "display(first_months.sort_values(by=['first_month', 'product_id']).tail(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['cat1', 'cat2', 'cat3', 'brand', 'sku_size']\n",
    "\n",
    "# Transformar las columnas categóricas en numéricas\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    final_dataset[col] = le.fit_transform(final_dataset[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = final_dataset.groupby(['product_id', 'cat1', 'cat2', 'cat3'])\n",
    "\n",
    "for name, group in grouped:\n",
    "    print(f\"Group name: {name}\")\n",
    "    print(group.head())\n",
    "    print(\"\\n\")\n",
    "    # break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {col: {} for col in columns}\n",
    "scaled_data_list = []\n",
    "\n",
    "for (product_id, _, _, _ ), group in grouped:\n",
    "    scaled_group = group.copy()\n",
    "    for col in columns:\n",
    "        if col not in non_scalable_columns:\n",
    "            scaler = StandardScaler()\n",
    "            # print(col)\n",
    "            scaled_group[col] = scaler.fit_transform(group[[col]])\n",
    "            scalers[col][product_id] = scaler\n",
    "    scaled_data_list.append(scaled_group)\n",
    "\n",
    "# Combinar todos los datos escalados en un solo DataFrame\n",
    "scaled_data = pd.concat(scaled_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(scaled_data[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_data[scaled_data['cat1'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion para preparar los datos y crear el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es predecir 2 dias en el futuro, por lo que la idea es re-armar el dataset. Donde el valor de X sera el conjunto de datos hasta N-2 e Y va a ser N (siendo N la cantidad de ventas para ese producto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data,validation=False):\n",
    "    X, y = [], []\n",
    "    unique_product_ids = data['product_id'].unique()\n",
    "    predicciones = {}\n",
    "\n",
    "    for product_id in unique_product_ids:\n",
    "        product_data = data[data['product_id'] == product_id].copy()\n",
    "        product_values = product_data[columns].values\n",
    "        \n",
    "        if len(product_values) < timeframe + 2:\n",
    "            if validation:\n",
    "                predicciones[product_id] = np.mean(product_values)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if validation:\n",
    "            X.append(product_values[-timeframe:]) # Los ultimos 14 meses para re-entrenar el modelo antes de las predicciones finales\n",
    "            y.append(product_id)\n",
    "        else:\n",
    "            # Todas las observaciones menos las últimas dos. Como despues necesito agregar esos 2 registros\n",
    "            # para predecir el future, agrego dos registros previos\n",
    "            X.append(product_values[-(timeframe + 2):-2])\n",
    "            y.append(product_values[-1, -1])      # Última observación\n",
    "    \n",
    "    if validation:\n",
    "        return np.array(X), np.array(y), predicciones\n",
    "    else:\n",
    "        return np.array(X), np.array(y), predicciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la funcion para crear el modelo LSTM, sobre este se ejecutara la optimizacion bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2  # número de pasos de tiempo\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scaled_data[columns].values\n",
    "X, y, _ = prepare_data(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.shape)\n",
    "display(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisamos que la funcion genere registros coherentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestro todos los registros del ultimo producto\n",
    "unique_product_ids = scaled_data['product_id'].unique()\n",
    "product_data = scaled_data[scaled_data['product_id'] == unique_product_ids[0]] #<= cambiar el indice entre 0 y -1 para ver la diferencia agregada por el padleft\n",
    "product_values = product_data[columns].values\n",
    "display(product_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X[0]) #<= cambiar el indice entre 0 y -1 para ver la diferencia agregada por el padleft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y[0]) #<= cambiar el indice entre 0 y -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def create_model(units, learning_rate, optimizer='adam', dropout=0.1, activation=\"tanh\", depth=2, l2_penalty=1e-6):\n",
    "    display(f\"Creating model with parameters: units={units}, learning_rate={learning_rate}, \"\n",
    "                f\"optimizer={optimizer}, dropout={dropout}, activation={activation}, \"\n",
    "                f\"depth={depth}, l2_penalty={l2_penalty}\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(depth):\n",
    "        if i == 0:\n",
    "            model.add(LSTM(units=units, return_sequences=True, input_shape=(timeframe, n_features), activation=activation, kernel_regularizer=l2(l2_penalty)))\n",
    "            model.add(BatchNormalization())\n",
    "        else:\n",
    "            model.add(LSTM(units=units, return_sequences=True, activation=activation, kernel_regularizer=l2(l2_penalty)))\n",
    "            model.add(Dropout(dropout))\n",
    "            model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LSTM(units=units, return_sequences=False, activation=activation, kernel_regularizer=l2(l2_penalty)))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    # Usamos el error cuadratico medio, porque penaliza errores grandes. Como tenemos ciertos\n",
    "    # productos \"estrella\", para los cuales hay mas ventas, y tener un error en lo mismos\n",
    "    # puede implicar una gran diferencia de las estimaciones, decidimos probar con esta funcion de perdida.\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armado de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'depth': [1, 2, 3, 4],#, 5, 6],\n",
    "    'activation': ['relu', 'tanh'], #'selu', 'swish'\n",
    "    'units': [64, 128, 256, 512],\n",
    "    'dropout': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': Categorical(categories=(0.0001, 0.001), prior=None),#0.01\n",
    "    'epochs': [10, 20, 30, 50, 100],\n",
    "    'batch_size': Categorical([32, 128], prior=None),#[32, 64, 128],\n",
    "    'optimizer': ['adam', 'rmsprop', 'sgd'],\n",
    "    'l2_penalty': [1e-6, 1e-2, 1e-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5) mean_squared_error\n",
    "early_stopping = EarlyStopping(monitor='mean_squared_error', patience=5)\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "model = KerasRegressor(\n",
    "    build_fn=create_model,\n",
    "    verbose=1,\n",
    "    units=64,\n",
    "    learning_rate=0.01,\n",
    "    dropout=0.1,\n",
    "    activation=\"tanh\",\n",
    "    depth=1,\n",
    "    l2_penalty=1e-6,\n",
    "    callbacks = callbacks\n",
    ")\n",
    "\n",
    "# Como ahora cada observacion, representa la serie de un producto, no hace falta usar \n",
    "# un cv especifico de time series, con el cv normal deberia ser suficiente.\n",
    "# cv = TimeSeriesSplit(n_splits=5).split(X)\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    # n_iter=50,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    # n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_search.fit(X, y, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardo los mejores hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('activation', 'tanh'),\n",
       "             ('batch_size', 32),\n",
       "             ('depth', 2),\n",
       "             ('dropout', 0.1),\n",
       "             ('epochs', 50),\n",
       "             ('l2_penalty', 0.01),\n",
       "             ('learning_rate', 0.001),\n",
       "             ('optimizer', 'sgd'),\n",
       "             ('units', 128)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Creating model with parameters: units=128, learning_rate=0.001, optimizer=sgd, dropout=0.1, activation=tanh, depth=2, l2_penalty=0.01'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/my_env/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 5.5061 - mean_squared_error: 1.2081\n",
      "Epoch 2/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.1077 - mean_squared_error: 0.8130\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.9761 - mean_squared_error: 0.6848\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.9742 - mean_squared_error: 0.6863\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.9485 - mean_squared_error: 0.6640\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 4.9107 - mean_squared_error: 0.6296\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.8580 - mean_squared_error: 0.5803\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 4.7784 - mean_squared_error: 0.5041\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.9715 - mean_squared_error: 0.7005\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 4.8903 - mean_squared_error: 0.6227\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 4.8429 - mean_squared_error: 0.5787\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 4.8971 - mean_squared_error: 0.6363\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 4.8323 - mean_squared_error: 0.5748\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 4.7976 - mean_squared_error: 0.5435\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 4.8184 - mean_squared_error: 0.5677\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 4.8736 - mean_squared_error: 0.6262\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 4.8176 - mean_squared_error: 0.5736\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 4.7874 - mean_squared_error: 0.5467\n",
      "Epoch 19/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.8022 - mean_squared_error: 0.5649\n",
      "Epoch 20/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.8283 - mean_squared_error: 0.5944\n",
      "Epoch 21/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 4.7188 - mean_squared_error: 0.4883\n",
      "Epoch 22/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.7312 - mean_squared_error: 0.5039\n",
      "Epoch 23/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 4.7435 - mean_squared_error: 0.5196\n",
      "Epoch 24/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 4.7319 - mean_squared_error: 0.5114\n",
      "Epoch 25/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 4.8284 - mean_squared_error: 0.6112\n",
      "Epoch 26/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 4.7579 - mean_squared_error: 0.5441\n",
      "Epoch 27/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.7550 - mean_squared_error: 0.5444\n",
      "Epoch 28/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 4.7791 - mean_squared_error: 0.5719\n",
      "Epoch 29/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.7572 - mean_squared_error: 0.5533\n",
      "Epoch 30/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 4.6612 - mean_squared_error: 0.4606\n",
      "Epoch 31/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 4.7232 - mean_squared_error: 0.5260\n",
      "Epoch 32/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.7117 - mean_squared_error: 0.5177\n",
      "Epoch 33/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 4.7647 - mean_squared_error: 0.5741\n",
      "Epoch 34/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 4.7086 - mean_squared_error: 0.5214\n",
      "Epoch 35/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 4.6951 - mean_squared_error: 0.5111\n",
      "Epoch 36/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.7230 - mean_squared_error: 0.5423\n",
      "Epoch 37/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.7083 - mean_squared_error: 0.5310\n",
      "Epoch 38/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 4.6824 - mean_squared_error: 0.5083\n",
      "Epoch 39/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 4.6548 - mean_squared_error: 0.4840\n",
      "Epoch 40/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 4.6697 - mean_squared_error: 0.5022\n",
      "Epoch 41/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 4.6713 - mean_squared_error: 0.5071\n",
      "Epoch 42/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.6827 - mean_squared_error: 0.5218\n",
      "Epoch 43/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.6735 - mean_squared_error: 0.5158\n",
      "Epoch 44/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 4.6714 - mean_squared_error: 0.5171\n",
      "Epoch 45/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.6730 - mean_squared_error: 0.5219\n",
      "Epoch 46/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 4.7449 - mean_squared_error: 0.5971\n",
      "Epoch 47/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.6285 - mean_squared_error: 0.4839\n",
      "Epoch 48/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.6885 - mean_squared_error: 0.5473\n",
      "Epoch 49/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.6897 - mean_squared_error: 0.5517\n",
      "Epoch 50/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.6548 - mean_squared_error: 0.5201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('activation', 'tanh'),\n",
       "             ('batch_size', 32),\n",
       "             ('depth', 2),\n",
       "             ('dropout', 0.1),\n",
       "             ('epochs', 50),\n",
       "             ('l2_penalty', 0.01),\n",
       "             ('learning_rate', 0.001),\n",
       "             ('optimizer', 'sgd'),\n",
       "             ('units', 128)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_757, built=True>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = bayes_search.cv_results_['params'][bayes_search.best_index_]\n",
    "display(best_params)\n",
    "\n",
    "best_model = create_model(\n",
    "    units=best_params['units'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    optimizer=best_params['optimizer'],\n",
    "    dropout=best_params['dropout'],\n",
    "    activation=best_params['activation'],\n",
    "    depth=best_params['depth'],\n",
    "    l2_penalty=best_params['l2_penalty'],\n",
    ")\n",
    "best_model.fit(X, y, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1)\n",
    "\n",
    "display(best_params)\n",
    "display(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4681141331008797"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_model.predict(X)\n",
    "mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los mejores hiperparámetros han sido guardados en best_params.json.\n"
     ]
    }
   ],
   "source": [
    "# Obtener los mejores hiperparámetros\n",
    "best_params = bayes_search.cv_results_['params'][bayes_search.best_index_]\n",
    "\n",
    "# Guardar los mejores hiperparámetros en un archivo JSON\n",
    "with open('best_params.json', 'w') as file:\n",
    "    json.dump(best_params, file)\n",
    "\n",
    "print('Los mejores hiperparámetros han sido guardados en best_params.json.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Creating model with parameters: units=128, learning_rate=0.001, optimizer=sgd, dropout=0.1, activation=tanh, depth=2, l2_penalty=0.01'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/my_env/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 5.5248 - mean_squared_error: 1.2432\n",
      "Epoch 2/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 5.1021 - mean_squared_error: 0.8238\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.9799 - mean_squared_error: 0.7049\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.9951 - mean_squared_error: 0.7235\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.9216 - mean_squared_error: 0.6533\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 4.8556 - mean_squared_error: 0.5907\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 4.8449 - mean_squared_error: 0.5834\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 4.9349 - mean_squared_error: 0.6767\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.9110 - mean_squared_error: 0.6562\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.8489 - mean_squared_error: 0.5974\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.8770 - mean_squared_error: 0.6289\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.8636 - mean_squared_error: 0.6189\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.8884 - mean_squared_error: 0.6470\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.7952 - mean_squared_error: 0.5571\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 4.7482 - mean_squared_error: 0.5135\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.8958 - mean_squared_error: 0.6645\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.7886 - mean_squared_error: 0.5606\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.7981 - mean_squared_error: 0.5733\n",
      "Epoch 19/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.7922 - mean_squared_error: 0.5708\n",
      "Epoch 20/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.8011 - mean_squared_error: 0.5830\n",
      "Epoch 21/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.7818 - mean_squared_error: 0.5670\n",
      "Epoch 22/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.8479 - mean_squared_error: 0.6365\n",
      "Epoch 23/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.8129 - mean_squared_error: 0.6048\n",
      "Epoch 24/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.7281 - mean_squared_error: 0.5233\n",
      "Epoch 25/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.7284 - mean_squared_error: 0.5269\n",
      "Epoch 26/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.7106 - mean_squared_error: 0.5124\n",
      "Epoch 27/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.6671 - mean_squared_error: 0.4723\n",
      "Epoch 28/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 4.7303 - mean_squared_error: 0.5388\n",
      "Epoch 29/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.6940 - mean_squared_error: 0.5058\n",
      "Epoch 30/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.7548 - mean_squared_error: 0.5699\n",
      "Epoch 31/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.6973 - mean_squared_error: 0.5156\n",
      "Epoch 32/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 4.7411 - mean_squared_error: 0.5627\n",
      "Epoch 33/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.7083 - mean_squared_error: 0.5332\n",
      "Epoch 34/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.6982 - mean_squared_error: 0.5265\n",
      "Epoch 35/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.7318 - mean_squared_error: 0.5633\n",
      "Epoch 36/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.7410 - mean_squared_error: 0.5758\n",
      "Epoch 37/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.6922 - mean_squared_error: 0.5303\n",
      "Epoch 38/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 4.6359 - mean_squared_error: 0.4772\n",
      "Epoch 39/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 4.7068 - mean_squared_error: 0.5515\n",
      "Epoch 40/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.7196 - mean_squared_error: 0.5676\n",
      "Epoch 41/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.6870 - mean_squared_error: 0.5383\n",
      "Epoch 42/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.6746 - mean_squared_error: 0.5291\n",
      "Epoch 43/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.6498 - mean_squared_error: 0.5076\n",
      "Epoch 44/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.6628 - mean_squared_error: 0.5239\n",
      "Epoch 45/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 4.6168 - mean_squared_error: 0.4811\n",
      "Epoch 46/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.6431 - mean_squared_error: 0.5107\n",
      "Epoch 47/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.6648 - mean_squared_error: 0.5357\n",
      "Epoch 48/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.5956 - mean_squared_error: 0.4697\n",
      "Epoch 49/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.6442 - mean_squared_error: 0.5215\n",
      "Epoch 50/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.5936 - mean_squared_error: 0.4742\n",
      "Configuración del nuevo modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_756\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_756\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2486 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1730        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2487 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1730 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1731        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2488 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1731 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_756 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2486 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m71,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1730        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2487 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1730 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1731        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2488 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1731 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_756 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">335,491</span> (1.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m335,491\u001b[0m (1.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">334,977</span> (1.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m334,977\u001b[0m (1.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "with open('best_params.json', 'r') as file:\n",
    "    best_params = json.load(file)\n",
    "\n",
    "# Reconstruir el modelo con los mejores hiperparámetros\n",
    "mejor_modelo = create_model(units=best_params['units'], learning_rate=best_params['learning_rate'], optimizer=best_params['optimizer'], dropout=best_params['dropout'], activation=best_params['activation'], depth=best_params['depth'], l2_penalty=best_params['l2_penalty'])\n",
    "mejor_modelo.fit(X, y, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1)\n",
    "# Verificar la configuración del nuevo modelo\n",
    "print(\"Configuración del nuevo modelo:\")\n",
    "print(mejor_modelo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hago las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = BayesSearchCV.best_params_\n",
    "\n",
    "# best_units = best_params['build_fn__units']\n",
    "# best_dropout_rate = best_params['build_fn__dropout_rate']\n",
    "# best_optimizer = best_params['build_fn__optimizer']\n",
    "\n",
    "# best_model = create_model(units=best_units, dropout_rate=best_dropout_rate, optimizer=best_optimizer)\n",
    "# best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f, product_ids, predictions = prepare_data(scaled_data, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.5522946 ],\n",
       "       [-0.02378039],\n",
       "       [-0.8571388 ],\n",
       "       [-0.8028174 ],\n",
       "       [-1.1526424 ],\n",
       "       [-0.8424837 ],\n",
       "       [-1.1430153 ],\n",
       "       [-0.92409587],\n",
       "       [-0.4799639 ],\n",
       "       [-0.21263538],\n",
       "       [-0.32411158],\n",
       "       [-1.1567881 ],\n",
       "       [-1.1697465 ],\n",
       "       [-1.007281  ],\n",
       "       [-0.9369471 ],\n",
       "       [-0.5025943 ],\n",
       "       [-0.91128397],\n",
       "       [-0.83229166],\n",
       "       [-0.776789  ],\n",
       "       [-0.4455114 ],\n",
       "       [-0.27961433],\n",
       "       [-0.27254945],\n",
       "       [-0.76956034],\n",
       "       [-0.41575664],\n",
       "       [-0.35105467],\n",
       "       [-0.42303056],\n",
       "       [-1.2769738 ],\n",
       "       [-0.9180758 ],\n",
       "       [-0.8619456 ],\n",
       "       [-0.43105364],\n",
       "       [-0.4817462 ],\n",
       "       [-1.0778322 ],\n",
       "       [-0.27950776],\n",
       "       [-1.0575445 ],\n",
       "       [-0.549862  ],\n",
       "       [-0.24492672],\n",
       "       [-0.2829991 ],\n",
       "       [-0.5391534 ],\n",
       "       [-0.5314253 ],\n",
       "       [-0.75191194],\n",
       "       [-0.8885122 ],\n",
       "       [-0.8488881 ],\n",
       "       [-0.7904655 ],\n",
       "       [-0.9987295 ],\n",
       "       [-0.48027986],\n",
       "       [-1.0969629 ],\n",
       "       [-0.39811164],\n",
       "       [-0.5114534 ],\n",
       "       [-0.78024423],\n",
       "       [-1.0618914 ],\n",
       "       [-1.2282729 ],\n",
       "       [-0.93727726],\n",
       "       [-1.2807448 ],\n",
       "       [-1.2120043 ],\n",
       "       [-1.2143723 ],\n",
       "       [-0.95463705],\n",
       "       [-0.62277794],\n",
       "       [-1.1669822 ],\n",
       "       [-0.5551786 ],\n",
       "       [-0.5639812 ],\n",
       "       [-1.1035061 ],\n",
       "       [-0.07911017],\n",
       "       [-0.9545539 ],\n",
       "       [-0.08043619],\n",
       "       [-1.0029228 ],\n",
       "       [-0.4916042 ],\n",
       "       [-1.1251634 ],\n",
       "       [-0.78448427],\n",
       "       [-1.1170795 ],\n",
       "       [-0.8072808 ],\n",
       "       [-1.4586433 ],\n",
       "       [-1.222863  ],\n",
       "       [-0.07974188],\n",
       "       [-0.27288663],\n",
       "       [-0.26664078],\n",
       "       [-1.3033509 ],\n",
       "       [-1.109248  ],\n",
       "       [-0.7451096 ],\n",
       "       [-1.1435957 ],\n",
       "       [-0.0905356 ],\n",
       "       [-1.1919905 ],\n",
       "       [-0.08707811],\n",
       "       [-1.2227484 ],\n",
       "       [-0.95178276],\n",
       "       [-1.3565569 ],\n",
       "       [-0.6901834 ],\n",
       "       [-0.58545184],\n",
       "       [-1.3718455 ],\n",
       "       [-0.06606758],\n",
       "       [-0.7544027 ],\n",
       "       [-1.0063053 ],\n",
       "       [-0.09463543],\n",
       "       [-0.5016058 ],\n",
       "       [-0.87817335],\n",
       "       [-0.88943803],\n",
       "       [-0.3408721 ],\n",
       "       [-0.42619675],\n",
       "       [-1.185092  ],\n",
       "       [-0.4975742 ],\n",
       "       [-1.0039419 ],\n",
       "       [-0.83085454],\n",
       "       [-1.4307799 ],\n",
       "       [-0.11612751],\n",
       "       [-0.25387555],\n",
       "       [ 0.20093201],\n",
       "       [-0.06539796],\n",
       "       [-0.900529  ],\n",
       "       [-0.605458  ],\n",
       "       [-0.11836536],\n",
       "       [-0.23067568],\n",
       "       [-0.6610053 ],\n",
       "       [-0.9513303 ],\n",
       "       [-0.62012947],\n",
       "       [-0.5928317 ],\n",
       "       [-0.6791116 ],\n",
       "       [-0.8768028 ],\n",
       "       [-1.0087326 ],\n",
       "       [-0.5863248 ],\n",
       "       [-0.5780193 ],\n",
       "       [-0.9954736 ],\n",
       "       [-0.7110251 ],\n",
       "       [-0.9951285 ],\n",
       "       [-0.36538857],\n",
       "       [-0.8904104 ],\n",
       "       [-0.21939124],\n",
       "       [-0.6445834 ],\n",
       "       [-0.9145963 ],\n",
       "       [-1.3030534 ],\n",
       "       [-0.17378175],\n",
       "       [-0.36610824],\n",
       "       [-0.17520852],\n",
       "       [-0.55138594],\n",
       "       [-1.2003629 ],\n",
       "       [-0.7650532 ],\n",
       "       [-0.7032896 ],\n",
       "       [-0.55427223],\n",
       "       [ 0.38166112],\n",
       "       [-0.92461085],\n",
       "       [-0.37809658],\n",
       "       [-0.61282074],\n",
       "       [-1.1895268 ],\n",
       "       [-0.48884207],\n",
       "       [-1.0040845 ],\n",
       "       [-0.29972804],\n",
       "       [-0.23177804],\n",
       "       [-0.5165934 ],\n",
       "       [-0.29135442],\n",
       "       [-0.9944748 ],\n",
       "       [-0.8162435 ],\n",
       "       [-0.4467231 ],\n",
       "       [-1.5068934 ],\n",
       "       [-1.48627   ],\n",
       "       [-0.24006574],\n",
       "       [-1.1792153 ],\n",
       "       [-0.45037413],\n",
       "       [-0.15551654],\n",
       "       [-0.8565729 ],\n",
       "       [-1.0620018 ],\n",
       "       [-0.6476137 ],\n",
       "       [-0.78401136],\n",
       "       [-0.67400974],\n",
       "       [-0.5329109 ],\n",
       "       [-0.92989814],\n",
       "       [-0.5576128 ],\n",
       "       [-1.0134445 ],\n",
       "       [-0.6800217 ],\n",
       "       [-0.92768216],\n",
       "       [-1.0815939 ],\n",
       "       [-1.1127158 ],\n",
       "       [-1.0502685 ],\n",
       "       [-1.3618426 ],\n",
       "       [ 0.35957795],\n",
       "       [-0.52790844],\n",
       "       [-0.3186561 ],\n",
       "       [-0.6513362 ],\n",
       "       [-0.7969992 ],\n",
       "       [-0.2797206 ],\n",
       "       [-0.48275006],\n",
       "       [-0.91490614],\n",
       "       [-1.1941636 ],\n",
       "       [-0.43233728],\n",
       "       [-0.23251082],\n",
       "       [-0.45558304],\n",
       "       [ 0.07139845],\n",
       "       [-1.2985219 ],\n",
       "       [-0.2119605 ],\n",
       "       [-0.03778991],\n",
       "       [-0.29384243],\n",
       "       [-0.10405205],\n",
       "       [-1.0472513 ],\n",
       "       [-0.7018895 ],\n",
       "       [-1.2141703 ],\n",
       "       [-0.3323096 ],\n",
       "       [-1.2294472 ],\n",
       "       [-1.4835058 ],\n",
       "       [-0.44434476],\n",
       "       [-1.0566196 ],\n",
       "       [-1.1192786 ],\n",
       "       [-0.43993413],\n",
       "       [-1.081475  ],\n",
       "       [-1.1454153 ],\n",
       "       [-1.2470188 ],\n",
       "       [-0.55152   ],\n",
       "       [-0.5920937 ],\n",
       "       [-0.9805206 ],\n",
       "       [-1.272285  ],\n",
       "       [-0.6372344 ],\n",
       "       [-0.5572695 ],\n",
       "       [-0.9974871 ],\n",
       "       [-1.0645071 ],\n",
       "       [-1.1108882 ],\n",
       "       [-1.1086711 ],\n",
       "       [-1.0330755 ],\n",
       "       [-1.0086452 ],\n",
       "       [-0.27390766],\n",
       "       [-0.9255294 ],\n",
       "       [-0.70275366],\n",
       "       [-1.3654447 ],\n",
       "       [-0.43124777],\n",
       "       [-1.1452242 ],\n",
       "       [-1.0758227 ],\n",
       "       [-1.3086407 ],\n",
       "       [-1.495476  ],\n",
       "       [-1.4214687 ],\n",
       "       [-0.4308998 ],\n",
       "       [-0.94161636],\n",
       "       [-1.1204846 ],\n",
       "       [-1.060032  ],\n",
       "       [-1.5035902 ],\n",
       "       [-0.7036422 ],\n",
       "       [-0.94566923],\n",
       "       [-0.22257401],\n",
       "       [-0.2910279 ],\n",
       "       [-0.57824886],\n",
       "       [-0.9438285 ],\n",
       "       [-1.0159339 ],\n",
       "       [-1.29532   ],\n",
       "       [-1.088175  ],\n",
       "       [-1.2090203 ],\n",
       "       [-1.3002927 ],\n",
       "       [-0.369124  ],\n",
       "       [-0.95446444],\n",
       "       [-0.888522  ],\n",
       "       [-0.35259008],\n",
       "       [-0.4000802 ],\n",
       "       [ 0.32217616],\n",
       "       [-0.33761257],\n",
       "       [ 0.17791279],\n",
       "       [-0.19061653],\n",
       "       [-0.8638289 ],\n",
       "       [-0.6640855 ],\n",
       "       [-0.92792076],\n",
       "       [-0.33953756],\n",
       "       [-0.8772254 ],\n",
       "       [-0.8562871 ],\n",
       "       [-1.49652   ],\n",
       "       [-1.0260996 ],\n",
       "       [-0.60129625],\n",
       "       [-0.44919753],\n",
       "       [-0.68096495],\n",
       "       [-0.31222183],\n",
       "       [-0.8398917 ],\n",
       "       [-0.62435746],\n",
       "       [-0.8261113 ],\n",
       "       [-1.1810751 ],\n",
       "       [-1.0168277 ],\n",
       "       [-0.87684834],\n",
       "       [-1.5027883 ],\n",
       "       [-0.76195353],\n",
       "       [-0.8283699 ],\n",
       "       [-0.41931635],\n",
       "       [-1.1291738 ],\n",
       "       [-0.7256444 ],\n",
       "       [-0.801565  ],\n",
       "       [-1.0675224 ],\n",
       "       [ 0.16125679],\n",
       "       [-1.3068814 ],\n",
       "       [-0.7629614 ],\n",
       "       [-0.22166704],\n",
       "       [-0.60570824],\n",
       "       [-0.86034906],\n",
       "       [-0.27240074],\n",
       "       [-1.087013  ],\n",
       "       [-1.0972269 ],\n",
       "       [ 0.16793925],\n",
       "       [-0.12275492],\n",
       "       [-1.109073  ],\n",
       "       [-0.35827023],\n",
       "       [-0.9170485 ],\n",
       "       [-1.2233375 ],\n",
       "       [-0.72057724],\n",
       "       [-1.1532911 ],\n",
       "       [-1.2160437 ],\n",
       "       [-1.0954859 ],\n",
       "       [-0.29144913],\n",
       "       [-0.9078246 ],\n",
       "       [-1.0363764 ],\n",
       "       [-0.65123284],\n",
       "       [-0.6903872 ],\n",
       "       [-0.24157907],\n",
       "       [-1.0622181 ],\n",
       "       [-1.2337315 ],\n",
       "       [-0.7772424 ],\n",
       "       [-0.6139938 ],\n",
       "       [-1.0002004 ],\n",
       "       [-0.40270877],\n",
       "       [-0.18689021],\n",
       "       [-0.7011403 ],\n",
       "       [-0.46512234],\n",
       "       [-0.9279945 ],\n",
       "       [-1.3101486 ],\n",
       "       [-0.8953743 ],\n",
       "       [-0.88681626],\n",
       "       [-0.10688056],\n",
       "       [-1.5117238 ],\n",
       "       [-0.9716412 ],\n",
       "       [-0.4292196 ],\n",
       "       [-1.0359061 ],\n",
       "       [-1.4391677 ],\n",
       "       [ 0.11174293],\n",
       "       [-1.0090781 ],\n",
       "       [-0.86906445],\n",
       "       [-1.3034139 ],\n",
       "       [-1.137407  ],\n",
       "       [-1.3106692 ],\n",
       "       [ 0.209183  ],\n",
       "       [-0.06334688],\n",
       "       [-1.2950937 ],\n",
       "       [-1.2516369 ],\n",
       "       [-1.102613  ],\n",
       "       [-1.3119835 ],\n",
       "       [-1.2999249 ],\n",
       "       [-1.2439722 ],\n",
       "       [-0.26936653],\n",
       "       [-0.8266967 ],\n",
       "       [-0.7275334 ],\n",
       "       [-1.2125983 ],\n",
       "       [-0.72064435],\n",
       "       [-1.2913841 ],\n",
       "       [-1.110081  ],\n",
       "       [ 0.18782444],\n",
       "       [-0.798382  ],\n",
       "       [-0.82854426],\n",
       "       [ 0.03302898],\n",
       "       [-0.3259116 ],\n",
       "       [-0.87173784],\n",
       "       [-0.7630952 ],\n",
       "       [-1.1309073 ],\n",
       "       [-0.53394246],\n",
       "       [-0.870731  ],\n",
       "       [-0.7189783 ],\n",
       "       [-0.8595001 ],\n",
       "       [-0.754902  ],\n",
       "       [-1.2208207 ],\n",
       "       [-0.60936886],\n",
       "       [-0.52398694],\n",
       "       [-0.36034346],\n",
       "       [-1.2539171 ],\n",
       "       [-1.3244472 ],\n",
       "       [-1.2969897 ],\n",
       "       [-0.3076712 ],\n",
       "       [-0.7624255 ],\n",
       "       [-0.83175814],\n",
       "       [ 0.2319402 ],\n",
       "       [-0.32015753],\n",
       "       [-1.2666919 ],\n",
       "       [-1.2362839 ],\n",
       "       [-0.85661834],\n",
       "       [-1.302719  ],\n",
       "       [-0.65908337],\n",
       "       [-0.36718917],\n",
       "       [-1.1323187 ],\n",
       "       [-1.0622609 ],\n",
       "       [-0.8650696 ],\n",
       "       [-0.9652654 ],\n",
       "       [-1.0001345 ],\n",
       "       [-0.46754843],\n",
       "       [-1.1504331 ],\n",
       "       [-0.9360846 ],\n",
       "       [-0.65870875],\n",
       "       [-0.48837125],\n",
       "       [-0.6811598 ],\n",
       "       [-1.507367  ],\n",
       "       [-0.43264067],\n",
       "       [-0.11212315],\n",
       "       [-0.38525134],\n",
       "       [-0.03991081],\n",
       "       [-0.539143  ],\n",
       "       [-0.35994697],\n",
       "       [-1.0794399 ],\n",
       "       [-1.4121172 ],\n",
       "       [-0.67736965],\n",
       "       [-0.5809767 ],\n",
       "       [-1.3020331 ],\n",
       "       [ 0.06227846],\n",
       "       [-1.2455807 ],\n",
       "       [-1.0157493 ],\n",
       "       [-1.113     ],\n",
       "       [ 0.26739365],\n",
       "       [-0.13856329],\n",
       "       [-0.7351564 ],\n",
       "       [-0.9616826 ],\n",
       "       [-0.45382828],\n",
       "       [ 0.20969503],\n",
       "       [-0.77019584],\n",
       "       [-0.75109583],\n",
       "       [-1.1889452 ],\n",
       "       [ 0.14520277],\n",
       "       [-1.3011262 ],\n",
       "       [-1.2085785 ],\n",
       "       [-0.7571942 ],\n",
       "       [-0.5890692 ],\n",
       "       [-1.3019217 ],\n",
       "       [-0.71475923],\n",
       "       [-0.1730742 ],\n",
       "       [-1.3037105 ],\n",
       "       [-1.3122506 ],\n",
       "       [ 0.26449585],\n",
       "       [ 0.12460171],\n",
       "       [-0.68976504],\n",
       "       [-1.0180249 ],\n",
       "       [-0.8411758 ],\n",
       "       [ 0.1506542 ],\n",
       "       [-1.4311124 ],\n",
       "       [-1.4253738 ],\n",
       "       [-0.35322613],\n",
       "       [-0.22203709],\n",
       "       [-0.32661843],\n",
       "       [-0.7389245 ],\n",
       "       [-0.9618572 ],\n",
       "       [-1.3082052 ],\n",
       "       [-0.09970436],\n",
       "       [ 0.03627141],\n",
       "       [ 0.18174522],\n",
       "       [-0.6137064 ],\n",
       "       [-1.3478317 ],\n",
       "       [-0.40584934],\n",
       "       [-1.1377491 ],\n",
       "       [-0.19234242],\n",
       "       [-1.3309965 ],\n",
       "       [-0.33588904],\n",
       "       [-0.586195  ],\n",
       "       [-1.0413425 ],\n",
       "       [-0.83736503],\n",
       "       [-0.623146  ],\n",
       "       [-0.95687175],\n",
       "       [-0.7394973 ],\n",
       "       [-1.3604267 ],\n",
       "       [-0.610361  ],\n",
       "       [-1.3055658 ],\n",
       "       [-1.4044981 ],\n",
       "       [-1.2007595 ],\n",
       "       [-1.07339   ],\n",
       "       [-1.2211666 ],\n",
       "       [-0.18857041],\n",
       "       [-1.0914313 ],\n",
       "       [-1.3127668 ],\n",
       "       [-1.3167257 ],\n",
       "       [ 0.27604222],\n",
       "       [-0.5135351 ],\n",
       "       [-0.8571841 ],\n",
       "       [-1.0639048 ],\n",
       "       [-1.2937007 ],\n",
       "       [-0.6228416 ],\n",
       "       [-0.5186492 ],\n",
       "       [-0.6450628 ],\n",
       "       [ 0.048474  ],\n",
       "       [-0.16299255],\n",
       "       [-0.4050749 ],\n",
       "       [-0.8813653 ],\n",
       "       [ 0.21658276],\n",
       "       [-0.2394043 ],\n",
       "       [-0.76083905],\n",
       "       [-0.5516266 ],\n",
       "       [-1.4161396 ],\n",
       "       [-1.3428187 ],\n",
       "       [-0.9128431 ],\n",
       "       [-1.2358971 ],\n",
       "       [-1.353095  ],\n",
       "       [-1.0635103 ],\n",
       "       [-0.20597912],\n",
       "       [-1.1818695 ],\n",
       "       [-0.20242134],\n",
       "       [-0.9501881 ],\n",
       "       [-0.8091509 ],\n",
       "       [-0.9667942 ],\n",
       "       [ 0.1399126 ],\n",
       "       [-0.72709477],\n",
       "       [-0.13015904],\n",
       "       [-1.0672269 ],\n",
       "       [-0.81918716],\n",
       "       [-0.21408671],\n",
       "       [ 0.61455286],\n",
       "       [-1.3930069 ],\n",
       "       [-0.15205024],\n",
       "       [-1.3128624 ],\n",
       "       [-0.34024405],\n",
       "       [-1.3311136 ],\n",
       "       [-1.3169653 ],\n",
       "       [-0.37100476],\n",
       "       [-0.615173  ],\n",
       "       [-1.6010025 ],\n",
       "       [-0.687162  ],\n",
       "       [-0.21038072],\n",
       "       [-0.23263721],\n",
       "       [-0.91952455],\n",
       "       [ 0.49726856],\n",
       "       [-1.4060936 ],\n",
       "       [-0.31384104],\n",
       "       [-0.1847875 ],\n",
       "       [-1.0334514 ],\n",
       "       [-0.5352376 ],\n",
       "       [-0.5061761 ],\n",
       "       [-0.22185712],\n",
       "       [-0.6302807 ],\n",
       "       [-1.6356006 ],\n",
       "       [-0.71865004],\n",
       "       [-0.1411344 ],\n",
       "       [-0.19639686],\n",
       "       [-0.7869948 ],\n",
       "       [-0.86398184],\n",
       "       [-1.376148  ],\n",
       "       [-0.88064903],\n",
       "       [ 0.5051167 ],\n",
       "       [-0.64309907],\n",
       "       [-0.8178296 ],\n",
       "       [-0.93344927],\n",
       "       [-1.3310661 ],\n",
       "       [-1.6441708 ],\n",
       "       [-1.3584301 ],\n",
       "       [-0.8282002 ],\n",
       "       [-1.3643092 ],\n",
       "       [-0.78191125],\n",
       "       [-1.2625815 ],\n",
       "       [-0.40525544],\n",
       "       [-1.3304741 ],\n",
       "       [-0.16656184],\n",
       "       [-0.5050245 ],\n",
       "       [ 0.05999897],\n",
       "       [-1.2662487 ],\n",
       "       [-0.1857108 ],\n",
       "       [-0.7882279 ],\n",
       "       [-0.32106346],\n",
       "       [-0.0556622 ],\n",
       "       [-0.3543297 ],\n",
       "       [-0.13574247],\n",
       "       [-0.08254446],\n",
       "       [-0.32917804],\n",
       "       [-0.652517  ],\n",
       "       [-0.08134137],\n",
       "       [-0.54329056],\n",
       "       [-0.5692564 ],\n",
       "       [-0.90123045],\n",
       "       [-0.84530395],\n",
       "       [-0.7297277 ],\n",
       "       [-1.367348  ],\n",
       "       [-0.764568  ],\n",
       "       [-1.3628547 ],\n",
       "       [-0.3956318 ],\n",
       "       [-1.06191   ],\n",
       "       [-0.9238381 ],\n",
       "       [-1.6391501 ],\n",
       "       [-1.4060609 ],\n",
       "       [-0.16873924],\n",
       "       [-0.93430626],\n",
       "       [-0.07423367],\n",
       "       [-0.04184422],\n",
       "       [-0.23151533],\n",
       "       [-0.65869755],\n",
       "       [-0.5685234 ],\n",
       "       [-1.6405541 ],\n",
       "       [-0.28261292],\n",
       "       [-1.3979731 ],\n",
       "       [-0.04640935],\n",
       "       [-0.11716412],\n",
       "       [-1.3006527 ],\n",
       "       [-0.30468923],\n",
       "       [-1.3916143 ],\n",
       "       [-0.68528426],\n",
       "       [-1.3885474 ],\n",
       "       [-0.09824493],\n",
       "       [-0.19372706],\n",
       "       [-1.3513725 ],\n",
       "       [-1.3362525 ],\n",
       "       [-0.0207461 ],\n",
       "       [-0.26175407],\n",
       "       [-1.404315  ],\n",
       "       [-0.10315914],\n",
       "       [-1.3211578 ],\n",
       "       [-0.0923055 ],\n",
       "       [-1.0642651 ],\n",
       "       [-0.31721961],\n",
       "       [-0.35794264],\n",
       "       [-0.2632594 ],\n",
       "       [ 0.12749493],\n",
       "       [-0.73426795],\n",
       "       [-0.27519715],\n",
       "       [-0.8883879 ],\n",
       "       [-1.4054654 ],\n",
       "       [-0.99268794],\n",
       "       [-0.38491833],\n",
       "       [-1.3911697 ],\n",
       "       [-0.8721273 ],\n",
       "       [-1.1355817 ],\n",
       "       [-0.56296855],\n",
       "       [-0.2811655 ],\n",
       "       [-0.9542961 ],\n",
       "       [-0.99103725],\n",
       "       [-0.27812707],\n",
       "       [-0.98331   ],\n",
       "       [-1.305914  ],\n",
       "       [-1.0386944 ],\n",
       "       [-0.5183892 ],\n",
       "       [-0.5210225 ],\n",
       "       [-0.8453673 ],\n",
       "       [-0.9831475 ],\n",
       "       [-0.5545058 ],\n",
       "       [-0.95530415],\n",
       "       [-0.984933  ],\n",
       "       [-0.5193951 ],\n",
       "       [-1.0403593 ],\n",
       "       [-0.9449617 ],\n",
       "       [-0.8506415 ],\n",
       "       [-0.5123627 ],\n",
       "       [-0.77516305],\n",
       "       [-0.7298074 ],\n",
       "       [-0.7291563 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_predictions = mejor_modelo.predict(X_f)\n",
    "display(scaled_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5522946 , -0.02378039, -0.8571388 , -0.8028174 , -1.1526424 ,\n",
       "       -0.8424837 , -1.1430153 , -0.92409587, -0.4799639 , -0.21263538,\n",
       "       -0.32411158, -1.1567881 , -1.1697465 , -1.007281  , -0.9369471 ,\n",
       "       -0.5025943 , -0.91128397, -0.83229166, -0.776789  , -0.4455114 ,\n",
       "       -0.27961433, -0.27254945, -0.76956034, -0.41575664, -0.35105467,\n",
       "       -0.42303056, -1.2769738 , -0.9180758 , -0.8619456 , -0.43105364,\n",
       "       -0.4817462 , -1.0778322 , -0.27950776, -1.0575445 , -0.549862  ,\n",
       "       -0.24492672, -0.2829991 , -0.5391534 , -0.5314253 , -0.75191194,\n",
       "       -0.8885122 , -0.8488881 , -0.7904655 , -0.9987295 , -0.48027986,\n",
       "       -1.0969629 , -0.39811164, -0.5114534 , -0.78024423, -1.0618914 ,\n",
       "       -1.2282729 , -0.93727726, -1.2807448 , -1.2120043 , -1.2143723 ,\n",
       "       -0.95463705, -0.62277794, -1.1669822 , -0.5551786 , -0.5639812 ,\n",
       "       -1.1035061 , -0.07911017, -0.9545539 , -0.08043619, -1.0029228 ,\n",
       "       -0.4916042 , -1.1251634 , -0.78448427, -1.1170795 , -0.8072808 ,\n",
       "       -1.4586433 , -1.222863  , -0.07974188, -0.27288663, -0.26664078,\n",
       "       -1.3033509 , -1.109248  , -0.7451096 , -1.1435957 , -0.0905356 ,\n",
       "       -1.1919905 , -0.08707811, -1.2227484 , -0.95178276, -1.3565569 ,\n",
       "       -0.6901834 , -0.58545184, -1.3718455 , -0.06606758, -0.7544027 ,\n",
       "       -1.0063053 , -0.09463543, -0.5016058 , -0.87817335, -0.88943803,\n",
       "       -0.3408721 , -0.42619675, -1.185092  , -0.4975742 , -1.0039419 ,\n",
       "       -0.83085454, -1.4307799 , -0.11612751, -0.25387555,  0.20093201,\n",
       "       -0.06539796, -0.900529  , -0.605458  , -0.11836536, -0.23067568,\n",
       "       -0.6610053 , -0.9513303 , -0.62012947, -0.5928317 , -0.6791116 ,\n",
       "       -0.8768028 , -1.0087326 , -0.5863248 , -0.5780193 , -0.9954736 ,\n",
       "       -0.7110251 , -0.9951285 , -0.36538857, -0.8904104 , -0.21939124,\n",
       "       -0.6445834 , -0.9145963 , -1.3030534 , -0.17378175, -0.36610824,\n",
       "       -0.17520852, -0.55138594, -1.2003629 , -0.7650532 , -0.7032896 ,\n",
       "       -0.55427223,  0.38166112, -0.92461085, -0.37809658, -0.61282074,\n",
       "       -1.1895268 , -0.48884207, -1.0040845 , -0.29972804, -0.23177804,\n",
       "       -0.5165934 , -0.29135442, -0.9944748 , -0.8162435 , -0.4467231 ,\n",
       "       -1.5068934 , -1.48627   , -0.24006574, -1.1792153 , -0.45037413,\n",
       "       -0.15551654, -0.8565729 , -1.0620018 , -0.6476137 , -0.78401136,\n",
       "       -0.67400974, -0.5329109 , -0.92989814, -0.5576128 , -1.0134445 ,\n",
       "       -0.6800217 , -0.92768216, -1.0815939 , -1.1127158 , -1.0502685 ,\n",
       "       -1.3618426 ,  0.35957795, -0.52790844, -0.3186561 , -0.6513362 ,\n",
       "       -0.7969992 , -0.2797206 , -0.48275006, -0.91490614, -1.1941636 ,\n",
       "       -0.43233728, -0.23251082, -0.45558304,  0.07139845, -1.2985219 ,\n",
       "       -0.2119605 , -0.03778991, -0.29384243, -0.10405205, -1.0472513 ,\n",
       "       -0.7018895 , -1.2141703 , -0.3323096 , -1.2294472 , -1.4835058 ,\n",
       "       -0.44434476, -1.0566196 , -1.1192786 , -0.43993413, -1.081475  ,\n",
       "       -1.1454153 , -1.2470188 , -0.55152   , -0.5920937 , -0.9805206 ,\n",
       "       -1.272285  , -0.6372344 , -0.5572695 , -0.9974871 , -1.0645071 ,\n",
       "       -1.1108882 , -1.1086711 , -1.0330755 , -1.0086452 , -0.27390766,\n",
       "       -0.9255294 , -0.70275366, -1.3654447 , -0.43124777, -1.1452242 ,\n",
       "       -1.0758227 , -1.3086407 , -1.495476  , -1.4214687 , -0.4308998 ,\n",
       "       -0.94161636, -1.1204846 , -1.060032  , -1.5035902 , -0.7036422 ,\n",
       "       -0.94566923, -0.22257401, -0.2910279 , -0.57824886, -0.9438285 ,\n",
       "       -1.0159339 , -1.29532   , -1.088175  , -1.2090203 , -1.3002927 ,\n",
       "       -0.369124  , -0.95446444, -0.888522  , -0.35259008, -0.4000802 ,\n",
       "        0.32217616, -0.33761257,  0.17791279, -0.19061653, -0.8638289 ,\n",
       "       -0.6640855 , -0.92792076, -0.33953756, -0.8772254 , -0.8562871 ,\n",
       "       -1.49652   , -1.0260996 , -0.60129625, -0.44919753, -0.68096495,\n",
       "       -0.31222183, -0.8398917 , -0.62435746, -0.8261113 , -1.1810751 ,\n",
       "       -1.0168277 , -0.87684834, -1.5027883 , -0.76195353, -0.8283699 ,\n",
       "       -0.41931635, -1.1291738 , -0.7256444 , -0.801565  , -1.0675224 ,\n",
       "        0.16125679, -1.3068814 , -0.7629614 , -0.22166704, -0.60570824,\n",
       "       -0.86034906, -0.27240074, -1.087013  , -1.0972269 ,  0.16793925,\n",
       "       -0.12275492, -1.109073  , -0.35827023, -0.9170485 , -1.2233375 ,\n",
       "       -0.72057724, -1.1532911 , -1.2160437 , -1.0954859 , -0.29144913,\n",
       "       -0.9078246 , -1.0363764 , -0.65123284, -0.6903872 , -0.24157907,\n",
       "       -1.0622181 , -1.2337315 , -0.7772424 , -0.6139938 , -1.0002004 ,\n",
       "       -0.40270877, -0.18689021, -0.7011403 , -0.46512234, -0.9279945 ,\n",
       "       -1.3101486 , -0.8953743 , -0.88681626, -0.10688056, -1.5117238 ,\n",
       "       -0.9716412 , -0.4292196 , -1.0359061 , -1.4391677 ,  0.11174293,\n",
       "       -1.0090781 , -0.86906445, -1.3034139 , -1.137407  , -1.3106692 ,\n",
       "        0.209183  , -0.06334688, -1.2950937 , -1.2516369 , -1.102613  ,\n",
       "       -1.3119835 , -1.2999249 , -1.2439722 , -0.26936653, -0.8266967 ,\n",
       "       -0.7275334 , -1.2125983 , -0.72064435, -1.2913841 , -1.110081  ,\n",
       "        0.18782444, -0.798382  , -0.82854426,  0.03302898, -0.3259116 ,\n",
       "       -0.87173784, -0.7630952 , -1.1309073 , -0.53394246, -0.870731  ,\n",
       "       -0.7189783 , -0.8595001 , -0.754902  , -1.2208207 , -0.60936886,\n",
       "       -0.52398694, -0.36034346, -1.2539171 , -1.3244472 , -1.2969897 ,\n",
       "       -0.3076712 , -0.7624255 , -0.83175814,  0.2319402 , -0.32015753,\n",
       "       -1.2666919 , -1.2362839 , -0.85661834, -1.302719  , -0.65908337,\n",
       "       -0.36718917, -1.1323187 , -1.0622609 , -0.8650696 , -0.9652654 ,\n",
       "       -1.0001345 , -0.46754843, -1.1504331 , -0.9360846 , -0.65870875,\n",
       "       -0.48837125, -0.6811598 , -1.507367  , -0.43264067, -0.11212315,\n",
       "       -0.38525134, -0.03991081, -0.539143  , -0.35994697, -1.0794399 ,\n",
       "       -1.4121172 , -0.67736965, -0.5809767 , -1.3020331 ,  0.06227846,\n",
       "       -1.2455807 , -1.0157493 , -1.113     ,  0.26739365, -0.13856329,\n",
       "       -0.7351564 , -0.9616826 , -0.45382828,  0.20969503, -0.77019584,\n",
       "       -0.75109583, -1.1889452 ,  0.14520277, -1.3011262 , -1.2085785 ,\n",
       "       -0.7571942 , -0.5890692 , -1.3019217 , -0.71475923, -0.1730742 ,\n",
       "       -1.3037105 , -1.3122506 ,  0.26449585,  0.12460171, -0.68976504,\n",
       "       -1.0180249 , -0.8411758 ,  0.1506542 , -1.4311124 , -1.4253738 ,\n",
       "       -0.35322613, -0.22203709, -0.32661843, -0.7389245 , -0.9618572 ,\n",
       "       -1.3082052 , -0.09970436,  0.03627141,  0.18174522, -0.6137064 ,\n",
       "       -1.3478317 , -0.40584934, -1.1377491 , -0.19234242, -1.3309965 ,\n",
       "       -0.33588904, -0.586195  , -1.0413425 , -0.83736503, -0.623146  ,\n",
       "       -0.95687175, -0.7394973 , -1.3604267 , -0.610361  , -1.3055658 ,\n",
       "       -1.4044981 , -1.2007595 , -1.07339   , -1.2211666 , -0.18857041,\n",
       "       -1.0914313 , -1.3127668 , -1.3167257 ,  0.27604222, -0.5135351 ,\n",
       "       -0.8571841 , -1.0639048 , -1.2937007 , -0.6228416 , -0.5186492 ,\n",
       "       -0.6450628 ,  0.048474  , -0.16299255, -0.4050749 , -0.8813653 ,\n",
       "        0.21658276, -0.2394043 , -0.76083905, -0.5516266 , -1.4161396 ,\n",
       "       -1.3428187 , -0.9128431 , -1.2358971 , -1.353095  , -1.0635103 ,\n",
       "       -0.20597912, -1.1818695 , -0.20242134, -0.9501881 , -0.8091509 ,\n",
       "       -0.9667942 ,  0.1399126 , -0.72709477, -0.13015904, -1.0672269 ,\n",
       "       -0.81918716, -0.21408671,  0.61455286, -1.3930069 , -0.15205024,\n",
       "       -1.3128624 , -0.34024405, -1.3311136 , -1.3169653 , -0.37100476,\n",
       "       -0.615173  , -1.6010025 , -0.687162  , -0.21038072, -0.23263721,\n",
       "       -0.91952455,  0.49726856, -1.4060936 , -0.31384104, -0.1847875 ,\n",
       "       -1.0334514 , -0.5352376 , -0.5061761 , -0.22185712, -0.6302807 ,\n",
       "       -1.6356006 , -0.71865004, -0.1411344 , -0.19639686, -0.7869948 ,\n",
       "       -0.86398184, -1.376148  , -0.88064903,  0.5051167 , -0.64309907,\n",
       "       -0.8178296 , -0.93344927, -1.3310661 , -1.6441708 , -1.3584301 ,\n",
       "       -0.8282002 , -1.3643092 , -0.78191125, -1.2625815 , -0.40525544,\n",
       "       -1.3304741 , -0.16656184, -0.5050245 ,  0.05999897, -1.2662487 ,\n",
       "       -0.1857108 , -0.7882279 , -0.32106346, -0.0556622 , -0.3543297 ,\n",
       "       -0.13574247, -0.08254446, -0.32917804, -0.652517  , -0.08134137,\n",
       "       -0.54329056, -0.5692564 , -0.90123045, -0.84530395, -0.7297277 ,\n",
       "       -1.367348  , -0.764568  , -1.3628547 , -0.3956318 , -1.06191   ,\n",
       "       -0.9238381 , -1.6391501 , -1.4060609 , -0.16873924, -0.93430626,\n",
       "       -0.07423367, -0.04184422, -0.23151533, -0.65869755, -0.5685234 ,\n",
       "       -1.6405541 , -0.28261292, -1.3979731 , -0.04640935, -0.11716412,\n",
       "       -1.3006527 , -0.30468923, -1.3916143 , -0.68528426, -1.3885474 ,\n",
       "       -0.09824493, -0.19372706, -1.3513725 , -1.3362525 , -0.0207461 ,\n",
       "       -0.26175407, -1.404315  , -0.10315914, -1.3211578 , -0.0923055 ,\n",
       "       -1.0642651 , -0.31721961, -0.35794264, -0.2632594 ,  0.12749493,\n",
       "       -0.73426795, -0.27519715, -0.8883879 , -1.4054654 , -0.99268794,\n",
       "       -0.38491833, -1.3911697 , -0.8721273 , -1.1355817 , -0.56296855,\n",
       "       -0.2811655 , -0.9542961 , -0.99103725, -0.27812707, -0.98331   ,\n",
       "       -1.305914  , -1.0386944 , -0.5183892 , -0.5210225 , -0.8453673 ,\n",
       "       -0.9831475 , -0.5545058 , -0.95530415, -0.984933  , -0.5193951 ,\n",
       "       -1.0403593 , -0.9449617 , -0.8506415 , -0.5123627 , -0.77516305,\n",
       "       -0.7298074 , -0.7291563 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_predictions_1d =  scaled_predictions.reshape(-1)\n",
    "display(scaled_predictions_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ls/f33jscqd6sb6bd857yb2j2s00000gp/T/ipykernel_42682/3047987798.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1246.0181176060473' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  predictions_df.at[index, 'predicted_y'] = inverse_scaled_prediction\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "    'product_id': product_ids,\n",
    "    'predicted_y': scaled_predictions_1d\n",
    "})\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame predictions_df\n",
    "for index, row in predictions_df.iterrows():\n",
    "    # Obtener el ID del producto y la predicción escalada para este producto\n",
    "    product_id = row['product_id']\n",
    "    scaled_prediction = row['predicted_y']\n",
    "    \n",
    "    # Obtener el escalador correspondiente a 'predicted_y' para este producto\n",
    "    scaler = scalers['y'][(product_id)]\n",
    "    \n",
    "    # Aplicar la inversa del escalador a la predicción 'predicted_y' para este producto\n",
    "    inverse_scaled_prediction = scaler.inverse_transform([[scaled_prediction]])[0][0]\n",
    "    \n",
    "    # Reemplazar la predicción escalada con la predicción invertida en el DataFrame final\n",
    "    predictions_df.at[index, 'predicted_y'] = inverse_scaled_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las predicciones han sido generadas y guardadas en predictions.csv después de aplicar la inversa de los scalers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(780, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction_list = []\n",
    "for product_id, pronostico in predictions.items():\n",
    "    prediction_list.append({'product_id': product_id, 'predicted_y': pronostico})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "predictions_df = pd.concat([predictions_df, pd.DataFrame(prediction_list)], ignore_index=True)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print('Todas las predicciones han sido generadas y guardadas en predictions.csv después de aplicar la inversa de los scalers.')\n",
    "display(predictions_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
