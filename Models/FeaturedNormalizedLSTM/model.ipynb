{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea de esta variante, es predecir solamente los productos que tengan mas de 12 meses de datos (usando los ultimos 12 solamente), y aquellos con menos datos, predecir la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from skopt import BayesSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.metrics import MeanSquaredError\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization\n",
    "from skopt.space import Categorical\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.read_csv('../../Datasets/final_dataset.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['plan_precios_cuidados', 'cust_request_qty', 'cust_request_tn', 'close_quarter', 'cat1', 'cat2', 'cat3', 'close_quarter', 'y']\n",
    "non_scalable_columns = ['cat1', 'cat2', 'cat3', 'plan_precios_cuidados', 'close_quarter']\n",
    "n_features = len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['cat1', 'cat2', 'cat3']\n",
    "\n",
    "# Transformar las columnas categóricas en numéricas\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    final_dataset[col] = le.fit_transform(final_dataset[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = final_dataset.groupby(['product_id', 'cat1', 'cat2', 'cat3'])\n",
    "display(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {col: {} for col in columns}\n",
    "scaled_data_list = []\n",
    "\n",
    "for (product_id, _, _, _ ), group in grouped:\n",
    "    scaled_group = group.copy()\n",
    "    for col in columns:\n",
    "        if col not in non_scalable_columns:\n",
    "            scaler = StandardScaler()\n",
    "            scaled_group[col] = scaler.fit_transform(group[[col]])\n",
    "            scalers[col][product_id] = scaler\n",
    "    scaled_data_list.append(scaled_group)\n",
    "\n",
    "# Combinar todos los datos escalados en un solo DataFrame\n",
    "scaled_data = pd.concat(scaled_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(scaled_data[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_data[scaled_data['cat1'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion para preparar los datos y crear el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es predecir 2 dias en el futuro, por lo que la idea es re-armar el dataset. Donde el valor de X sera el conjunto de datos hasta N-2 e Y va a ser N (siendo N la cantidad de ventas para ese producto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data,validation=False):\n",
    "    X, y = [], []\n",
    "    unique_product_ids = data['product_id'].unique()\n",
    "    predicciones = {}\n",
    "\n",
    "    for product_id in unique_product_ids:\n",
    "        product_data = data[data['product_id'] == product_id].copy()\n",
    "        product_values = product_data[columns].values\n",
    "        \n",
    "        if len(product_values) < 14:\n",
    "            if validation:\n",
    "                predicciones[product_id] = np.mean(product_values)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if validation:\n",
    "            X.append(product_values[-12:])\n",
    "            y.append(product_id)\n",
    "        else:\n",
    "            # Todas las observaciones menos las últimas dos. Como despues necesito agregar esos 2 registros\n",
    "            # para predecir el future, le agrego un pad left extra de 2 para no romper el shape de la red\n",
    "            X.append(product_values[-14:-2])\n",
    "            y.append(product_values[-1, -1])      # Última observación\n",
    "    \n",
    "    if validation:\n",
    "        return np.array(X), np.array(y), predicciones\n",
    "    else:\n",
    "        return np.array(X), np.array(y), predicciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la funcion para crear el modelo LSTM, sobre este se ejecutara la optimizacion bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2  # número de pasos de tiempo\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scaled_data[columns].values\n",
    "X, y, _ = prepare_data(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(656, 12, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(656,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X.shape)\n",
    "display(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisamos que la funcion genere registros coherentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestro todos los registros del ultimo producto\n",
    "unique_product_ids = scaled_data['product_id'].unique()\n",
    "product_data = scaled_data[scaled_data['product_id'] == unique_product_ids[0]] #<= cambiar el indice entre 0 y -1 para ver la diferencia agregada por el padleft\n",
    "product_values = product_data[columns].values\n",
    "display(product_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X[0]) #<= cambiar el indice entre 0 y -1 para ver la diferencia agregada por el padleft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y[0]) #<= cambiar el indice entre 0 y -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "max_seq_length = 12 #cantidad de mese a usar por producto\n",
    "\n",
    "def create_model(units, learning_rate, optimizer='adam', dropout=0.1, activation=\"tanh\", depth=2, l2_penalty=1e-6):\n",
    "    display(f\"Creating model with parameters: units={units}, learning_rate={learning_rate}, \"\n",
    "                f\"optimizer={optimizer}, dropout={dropout}, activation={activation}, \"\n",
    "                f\"depth={depth}, l2_penalty={l2_penalty}\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(depth):\n",
    "        if i == 0:\n",
    "            model.add(LSTM(units=units, return_sequences=True, input_shape=(max_seq_length, n_features), activation=activation, kernel_regularizer=l2(l2_penalty)))\n",
    "            model.add(BatchNormalization())\n",
    "        else:\n",
    "            model.add(LSTM(units=units, return_sequences=True, activation=activation, kernel_regularizer=l2(l2_penalty)))\n",
    "            model.add(Dropout(dropout))\n",
    "            model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LSTM(units=units, return_sequences=False, activation=activation, kernel_regularizer=l2(l2_penalty)))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    # Usamos el error cuadratico medio, porque penaliza errores grandes. Como tenemos ciertos\n",
    "    # productos \"estrella\", para los cuales hay mas ventas, y tener un error en lo mismos\n",
    "    # puede implicar una gran diferencia de las estimaciones, decidimos probar con esta funcion de perdida.\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armado de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'depth': [1, 2, 3, 4],#, 5, 6],\n",
    "    'activation': ['relu', 'tanh'], #'selu', 'swish'\n",
    "    'units': [64, 128, 256, 512],\n",
    "    'dropout': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': Categorical(categories=(0.0001, 0.001), prior=None),#0.01\n",
    "    'epochs': [10, 20, 30, 50, 100],\n",
    "    'batch_size': Categorical([32, 128], prior=None),#[32, 64, 128],\n",
    "    'optimizer': ['adam', 'rmsprop', 'sgd'],\n",
    "    'l2_penalty': [1e-6, 1e-2, 1e-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5) mean_squared_error\n",
    "early_stopping = EarlyStopping(monitor='mean_squared_error', patience=5)\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "model = KerasRegressor(\n",
    "    build_fn=create_model,\n",
    "    verbose=1,\n",
    "    units=64,\n",
    "    learning_rate=0.01,\n",
    "    dropout=0.1,\n",
    "    activation=\"tanh\",\n",
    "    depth=1,\n",
    "    l2_penalty=1e-6,\n",
    "    callbacks = callbacks\n",
    ")\n",
    "\n",
    "# Como ahora cada observacion, representa la serie de un producto, no hace falta usar \n",
    "# un cv especifico de time series, con el cv normal deberia ser suficiente.\n",
    "# cv = TimeSeriesSplit(n_splits=5).split(X)\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    # n_iter=50,\n",
    "    cv=10,\n",
    "    verbose=1,\n",
    "    # n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_search.fit(X, y, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardo los mejores hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('activation', 'relu'),\n",
       "             ('batch_size', 32),\n",
       "             ('depth', 1),\n",
       "             ('dropout', 0.2),\n",
       "             ('epochs', 30),\n",
       "             ('l2_penalty', 1e-06),\n",
       "             ('learning_rate', 0.001),\n",
       "             ('optimizer', 'sgd'),\n",
       "             ('units', 128)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Creating model with parameters: units=128, learning_rate=0.001, optimizer=sgd, dropout=0.2, activation=relu, depth=1, l2_penalty=1e-06'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/my_env/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.9706 - mean_squared_error: 0.9704\n",
      "Epoch 2/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8031 - mean_squared_error: 0.8029\n",
      "Epoch 3/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7816 - mean_squared_error: 0.7814\n",
      "Epoch 4/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7327 - mean_squared_error: 0.7324\n",
      "Epoch 5/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6785 - mean_squared_error: 0.6782\n",
      "Epoch 6/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6841 - mean_squared_error: 0.6838\n",
      "Epoch 7/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6973 - mean_squared_error: 0.6970\n",
      "Epoch 8/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7076 - mean_squared_error: 0.7074\n",
      "Epoch 9/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6311 - mean_squared_error: 0.6308\n",
      "Epoch 10/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6159 - mean_squared_error: 0.6157\n",
      "Epoch 11/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6402 - mean_squared_error: 0.6400\n",
      "Epoch 12/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6363 - mean_squared_error: 0.6360\n",
      "Epoch 13/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6239 - mean_squared_error: 0.6237\n",
      "Epoch 14/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.7086 - mean_squared_error: 0.7083\n",
      "Epoch 15/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6734 - mean_squared_error: 0.6732\n",
      "Epoch 16/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6096 - mean_squared_error: 0.6094\n",
      "Epoch 17/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6092 - mean_squared_error: 0.6089\n",
      "Epoch 18/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5621 - mean_squared_error: 0.5619\n",
      "Epoch 19/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6029 - mean_squared_error: 0.6027\n",
      "Epoch 20/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6522 - mean_squared_error: 0.6520\n",
      "Epoch 21/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6737 - mean_squared_error: 0.6734\n",
      "Epoch 22/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5625 - mean_squared_error: 0.5623\n",
      "Epoch 23/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6784 - mean_squared_error: 0.6782\n",
      "Epoch 24/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5653 - mean_squared_error: 0.5651\n",
      "Epoch 25/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5679 - mean_squared_error: 0.5677\n",
      "Epoch 26/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5326 - mean_squared_error: 0.5323\n",
      "Epoch 27/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5910 - mean_squared_error: 0.5908\n",
      "Epoch 28/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5880 - mean_squared_error: 0.5878\n",
      "Epoch 29/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6672 - mean_squared_error: 0.6670\n",
      "Epoch 30/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5840 - mean_squared_error: 0.5837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('activation', 'relu'),\n",
       "             ('batch_size', 32),\n",
       "             ('depth', 1),\n",
       "             ('dropout', 0.2),\n",
       "             ('epochs', 30),\n",
       "             ('l2_penalty', 1e-06),\n",
       "             ('learning_rate', 0.001),\n",
       "             ('optimizer', 'sgd'),\n",
       "             ('units', 128)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_502, built=True>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = bayes_search.cv_results_['params'][bayes_search.best_index_]\n",
    "display(best_params)\n",
    "\n",
    "best_model = create_model(\n",
    "    units=best_params['units'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    optimizer=best_params['optimizer'],\n",
    "    dropout=best_params['dropout'],\n",
    "    activation=best_params['activation'],\n",
    "    depth=best_params['depth'],\n",
    "    l2_penalty=best_params['l2_penalty'],\n",
    ")\n",
    "best_model.fit(X, y, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1)\n",
    "\n",
    "display(best_params)\n",
    "display(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.534394194642544"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_model.predict(X)\n",
    "mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los mejores hiperparámetros han sido guardados en best_params.json.\n"
     ]
    }
   ],
   "source": [
    "# Obtener los mejores hiperparámetros\n",
    "best_params = bayes_search.cv_results_['params'][bayes_search.best_index_]\n",
    "\n",
    "# Guardar los mejores hiperparámetros en un archivo JSON\n",
    "with open('best_params.json', 'w') as file:\n",
    "    json.dump(best_params, file)\n",
    "\n",
    "print('Los mejores hiperparámetros han sido guardados en best_params.json.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_params.json', 'r') as file:\n",
    "    best_params = json.load(file)\n",
    "\n",
    "# Reconstruir el modelo con los mejores hiperparámetros\n",
    "mejor_modelo = create_model(units=best_params['units'], learning_rate=best_params['learning_rate'], optimizer=best_params['optimizer'], dropout=best_params['dropout'], activation=best_params['activation'], depth=best_params['depth'], l2_penalty=best_params['l2_penalty'])\n",
    "mejor_modelo.fit(X, y, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1)\n",
    "# Verificar la configuración del nuevo modelo\n",
    "print(\"Configuración del nuevo modelo:\")\n",
    "print(mejor_modelo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hago las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = BayesSearchCV.best_params_\n",
    "\n",
    "# best_units = best_params['build_fn__units']\n",
    "# best_dropout_rate = best_params['build_fn__dropout_rate']\n",
    "# best_optimizer = best_params['build_fn__optimizer']\n",
    "\n",
    "# best_model = create_model(units=best_units, dropout_rate=best_dropout_rate, optimizer=best_optimizer)\n",
    "# best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f, product_ids, predictions = prepare_data(scaled_data, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.35179213],\n",
       "       [-0.2227672 ],\n",
       "       [-1.0607201 ],\n",
       "       [-0.96052676],\n",
       "       [-0.8090567 ],\n",
       "       [-1.0285374 ],\n",
       "       [-1.0385243 ],\n",
       "       [-0.92248243],\n",
       "       [-0.21984027],\n",
       "       [-0.680777  ],\n",
       "       [-0.6719221 ],\n",
       "       [-1.0366627 ],\n",
       "       [-0.77319735],\n",
       "       [-0.9706285 ],\n",
       "       [-0.63779473],\n",
       "       [-0.84340256],\n",
       "       [-0.85607857],\n",
       "       [-1.0615926 ],\n",
       "       [-1.1376735 ],\n",
       "       [-0.698301  ],\n",
       "       [-0.74939156],\n",
       "       [-0.57719004],\n",
       "       [-1.022449  ],\n",
       "       [-0.7247625 ],\n",
       "       [-0.7168679 ],\n",
       "       [-0.5362008 ],\n",
       "       [-0.79473823],\n",
       "       [-0.7446399 ],\n",
       "       [-1.0455142 ],\n",
       "       [-0.9270563 ],\n",
       "       [-0.73228973],\n",
       "       [-1.3063878 ],\n",
       "       [-0.7479686 ],\n",
       "       [-0.8976931 ],\n",
       "       [-0.66842604],\n",
       "       [-0.68114775],\n",
       "       [-0.77996063],\n",
       "       [-0.31360522],\n",
       "       [-0.78650814],\n",
       "       [-0.7304057 ],\n",
       "       [-0.65408367],\n",
       "       [-1.0531667 ],\n",
       "       [-0.83315915],\n",
       "       [-0.91870177],\n",
       "       [-0.72341293],\n",
       "       [-0.8913319 ],\n",
       "       [-1.0244622 ],\n",
       "       [-0.703538  ],\n",
       "       [-0.6758891 ],\n",
       "       [-0.83636814],\n",
       "       [-0.7162055 ],\n",
       "       [-0.8179849 ],\n",
       "       [-0.4935185 ],\n",
       "       [-0.612861  ],\n",
       "       [-0.62354654],\n",
       "       [-0.8598087 ],\n",
       "       [-0.48593384],\n",
       "       [-0.7391318 ],\n",
       "       [-0.658394  ],\n",
       "       [-0.7206544 ],\n",
       "       [-0.8274422 ],\n",
       "       [-0.6251976 ],\n",
       "       [-0.6586997 ],\n",
       "       [-0.59166414],\n",
       "       [-0.9253865 ],\n",
       "       [-0.10145919],\n",
       "       [-0.9417461 ],\n",
       "       [-0.67686576],\n",
       "       [-0.7177919 ],\n",
       "       [-0.9424361 ],\n",
       "       [-1.0719031 ],\n",
       "       [-0.72800404],\n",
       "       [-0.45391628],\n",
       "       [-0.65677214],\n",
       "       [-0.518525  ],\n",
       "       [-0.2661356 ],\n",
       "       [-0.91242677],\n",
       "       [-0.8907407 ],\n",
       "       [-0.25616136],\n",
       "       [-1.1716839 ],\n",
       "       [-0.6043011 ],\n",
       "       [-0.8352674 ],\n",
       "       [-0.42261696],\n",
       "       [-0.75162923],\n",
       "       [-0.9904768 ],\n",
       "       [-0.9044296 ],\n",
       "       [-0.79246944],\n",
       "       [-0.8419797 ],\n",
       "       [-1.1113124 ],\n",
       "       [-0.41314116],\n",
       "       [-0.7628154 ],\n",
       "       [-0.7776925 ],\n",
       "       [-0.42684287],\n",
       "       [-0.90592796],\n",
       "       [-1.1014558 ],\n",
       "       [-1.1516095 ],\n",
       "       [-0.55266565],\n",
       "       [ 0.01231697],\n",
       "       [-0.82231456],\n",
       "       [-0.4740185 ],\n",
       "       [-0.9673156 ],\n",
       "       [-1.2555274 ],\n",
       "       [-0.96505874],\n",
       "       [-0.62959045],\n",
       "       [-0.6187198 ],\n",
       "       [-0.3329316 ],\n",
       "       [-0.4101971 ],\n",
       "       [-1.0408769 ],\n",
       "       [-0.29616585],\n",
       "       [-0.35096323],\n",
       "       [-0.6797252 ],\n",
       "       [-0.52030325],\n",
       "       [-0.66972524],\n",
       "       [-0.31799653],\n",
       "       [-0.31665733],\n",
       "       [-0.47292313],\n",
       "       [-0.77209336],\n",
       "       [-1.0046266 ],\n",
       "       [-0.23297301],\n",
       "       [-0.24421766],\n",
       "       [-0.8403618 ],\n",
       "       [-0.6298102 ],\n",
       "       [-0.7868783 ],\n",
       "       [-0.3671335 ],\n",
       "       [-1.1044205 ],\n",
       "       [-0.20156801],\n",
       "       [-0.33637503],\n",
       "       [-0.8418767 ],\n",
       "       [-0.78140527],\n",
       "       [-0.48058745],\n",
       "       [-0.29160658],\n",
       "       [-0.4619379 ],\n",
       "       [-0.6093908 ],\n",
       "       [-0.7097036 ],\n",
       "       [-0.74105304],\n",
       "       [-0.9296479 ],\n",
       "       [-0.05589272],\n",
       "       [-0.3023704 ],\n",
       "       [-0.7250026 ],\n",
       "       [-0.44973865],\n",
       "       [-0.93313056],\n",
       "       [-0.55756384],\n",
       "       [-1.196396  ],\n",
       "       [-0.7762583 ],\n",
       "       [-0.7585415 ],\n",
       "       [-0.69055283],\n",
       "       [-0.5200657 ],\n",
       "       [-0.7445604 ],\n",
       "       [-0.779914  ],\n",
       "       [-0.9080987 ],\n",
       "       [-0.82654107],\n",
       "       [-0.9844237 ],\n",
       "       [-0.84565634],\n",
       "       [-0.5201163 ],\n",
       "       [-0.7156796 ],\n",
       "       [-0.8177061 ],\n",
       "       [-0.29216638],\n",
       "       [-0.8863141 ],\n",
       "       [-0.71464443],\n",
       "       [-0.68329835],\n",
       "       [-0.8264158 ],\n",
       "       [-0.6394059 ],\n",
       "       [-0.15902734],\n",
       "       [-0.7455012 ],\n",
       "       [-0.83681184],\n",
       "       [-1.3977674 ],\n",
       "       [-0.7424086 ],\n",
       "       [-0.77706665],\n",
       "       [-1.4865735 ],\n",
       "       [-0.4248748 ],\n",
       "       [-0.7342016 ],\n",
       "       [-0.9112072 ],\n",
       "       [-0.42563665],\n",
       "       [-0.77097845],\n",
       "       [-0.8053504 ],\n",
       "       [-0.68960035],\n",
       "       [-0.69287205],\n",
       "       [-0.66292375],\n",
       "       [-0.9860305 ],\n",
       "       [-0.2724319 ],\n",
       "       [-1.1221999 ],\n",
       "       [-0.7409062 ],\n",
       "       [-0.7914072 ],\n",
       "       [-0.39962584],\n",
       "       [-0.2662454 ],\n",
       "       [-0.88405365],\n",
       "       [ 0.21627963],\n",
       "       [-0.6100699 ],\n",
       "       [-0.7429396 ],\n",
       "       [-0.54387414],\n",
       "       [-0.90155405],\n",
       "       [-0.7964045 ],\n",
       "       [-1.5739161 ],\n",
       "       [-0.6843706 ],\n",
       "       [-0.8040218 ],\n",
       "       [-1.2299913 ],\n",
       "       [-0.8381814 ],\n",
       "       [-0.8390141 ],\n",
       "       [-0.66124016],\n",
       "       [-0.52781326],\n",
       "       [-0.5980662 ],\n",
       "       [-0.660717  ],\n",
       "       [-0.88562   ],\n",
       "       [-0.3727143 ],\n",
       "       [-0.33803412],\n",
       "       [-1.3155496 ],\n",
       "       [-0.84035116],\n",
       "       [-0.5500109 ],\n",
       "       [-0.25035644],\n",
       "       [-0.7476158 ],\n",
       "       [-0.97474205],\n",
       "       [-0.9998979 ],\n",
       "       [-1.089789  ],\n",
       "       [-0.5380921 ],\n",
       "       [-0.8111724 ],\n",
       "       [-0.6158482 ],\n",
       "       [-0.39192483],\n",
       "       [-0.7637808 ],\n",
       "       [-1.150544  ],\n",
       "       [-0.5977442 ],\n",
       "       [-0.63942266],\n",
       "       [-0.6308636 ],\n",
       "       [-0.36212435],\n",
       "       [-0.8742023 ],\n",
       "       [-1.0760329 ],\n",
       "       [-0.617304  ],\n",
       "       [-1.0705674 ],\n",
       "       [-0.52657235],\n",
       "       [-0.72099435],\n",
       "       [-1.0488222 ],\n",
       "       [-0.82131356],\n",
       "       [-0.4238151 ],\n",
       "       [-0.5580591 ],\n",
       "       [-0.642262  ],\n",
       "       [-0.91131717],\n",
       "       [-0.41363224],\n",
       "       [-0.8575003 ],\n",
       "       [-0.88340825],\n",
       "       [-0.59287983],\n",
       "       [-0.9129594 ],\n",
       "       [-0.8895013 ],\n",
       "       [-0.09727694],\n",
       "       [-0.39986056],\n",
       "       [-0.80142224],\n",
       "       [-0.70933694],\n",
       "       [-0.5797265 ],\n",
       "       [-0.21872345],\n",
       "       [-0.69122314],\n",
       "       [-0.46007523],\n",
       "       [ 0.19854179],\n",
       "       [-0.84584576],\n",
       "       [-0.8395058 ],\n",
       "       [-0.3937901 ],\n",
       "       [ 0.09333187],\n",
       "       [-1.4221331 ],\n",
       "       [-0.56810856],\n",
       "       [-0.7780184 ],\n",
       "       [-1.0262449 ],\n",
       "       [-0.67232406],\n",
       "       [-0.8295781 ],\n",
       "       [-1.0685837 ],\n",
       "       [-0.8251476 ],\n",
       "       [-0.71018744],\n",
       "       [-0.5172811 ],\n",
       "       [-0.7143638 ],\n",
       "       [-0.7625991 ],\n",
       "       [-0.83147424],\n",
       "       [-0.51708597],\n",
       "       [-0.8137821 ],\n",
       "       [-0.41176286],\n",
       "       [-0.8785504 ],\n",
       "       [-0.639279  ],\n",
       "       [-0.5454801 ],\n",
       "       [-0.86579823],\n",
       "       [-0.8264683 ],\n",
       "       [-0.80662256],\n",
       "       [-0.4786599 ],\n",
       "       [-0.89814436],\n",
       "       [-0.6821736 ],\n",
       "       [-0.48458722],\n",
       "       [-0.9100278 ],\n",
       "       [-0.30019805],\n",
       "       [-0.65923905],\n",
       "       [-0.6468771 ],\n",
       "       [-0.9231928 ],\n",
       "       [-0.44439295],\n",
       "       [-0.20353806],\n",
       "       [-0.658573  ],\n",
       "       [-0.37244037],\n",
       "       [-0.8221947 ],\n",
       "       [-0.86629575],\n",
       "       [-0.48390195],\n",
       "       [-0.639708  ],\n",
       "       [-1.0505048 ],\n",
       "       [-1.6295289 ],\n",
       "       [-0.63726336],\n",
       "       [-0.5945564 ],\n",
       "       [-1.4370247 ],\n",
       "       [-0.5364685 ],\n",
       "       [ 0.43279275],\n",
       "       [-0.7505235 ],\n",
       "       [-0.8790103 ],\n",
       "       [-1.2358013 ],\n",
       "       [-0.9305677 ],\n",
       "       [-0.36970016],\n",
       "       [-0.85119474],\n",
       "       [-0.61668074],\n",
       "       [-0.40676898],\n",
       "       [-0.88417494],\n",
       "       [ 0.0709134 ],\n",
       "       [-1.191211  ],\n",
       "       [-0.91096336],\n",
       "       [-0.8010637 ],\n",
       "       [-0.80305934],\n",
       "       [-0.52499855],\n",
       "       [-0.83289117],\n",
       "       [-0.84706205],\n",
       "       [-0.6847196 ],\n",
       "       [-0.52064073],\n",
       "       [-0.66973823],\n",
       "       [-1.1041802 ],\n",
       "       [-0.5382307 ],\n",
       "       [-0.5205512 ],\n",
       "       [-0.9610644 ],\n",
       "       [-0.90327114],\n",
       "       [-0.5465269 ],\n",
       "       [-0.91280466],\n",
       "       [-0.4338638 ],\n",
       "       [-0.5364035 ],\n",
       "       [-0.87297195],\n",
       "       [-0.5117384 ],\n",
       "       [-0.81808007],\n",
       "       [-0.9275692 ],\n",
       "       [-0.89256483],\n",
       "       [-0.5042462 ],\n",
       "       [-0.6081348 ],\n",
       "       [-0.69624865],\n",
       "       [-0.050006  ],\n",
       "       [-1.0348833 ],\n",
       "       [-0.9319777 ],\n",
       "       [-0.8799514 ],\n",
       "       [-0.6539625 ],\n",
       "       [-0.42870188],\n",
       "       [-0.8798414 ],\n",
       "       [-0.93791837],\n",
       "       [-0.6258895 ],\n",
       "       [-0.10047294],\n",
       "       [-0.88218504],\n",
       "       [-0.92651635],\n",
       "       [-0.82399905],\n",
       "       [-0.45646575],\n",
       "       [-0.8156809 ],\n",
       "       [-0.5594004 ],\n",
       "       [ 0.03204415],\n",
       "       [-0.6380582 ],\n",
       "       [-0.94021785],\n",
       "       [-0.4737899 ],\n",
       "       [-1.1386532 ],\n",
       "       [-0.3736995 ],\n",
       "       [-0.8377281 ],\n",
       "       [-0.7435212 ],\n",
       "       [-0.50962174],\n",
       "       [-0.37725273],\n",
       "       [-0.89401525],\n",
       "       [-0.7234186 ],\n",
       "       [-0.55275863],\n",
       "       [-0.7702361 ],\n",
       "       [-0.19211538],\n",
       "       [-0.8341917 ],\n",
       "       [-0.7034468 ],\n",
       "       [-0.474611  ],\n",
       "       [-0.9397699 ],\n",
       "       [-0.9135108 ],\n",
       "       [-0.5563436 ],\n",
       "       [-0.7499629 ],\n",
       "       [-0.44943005],\n",
       "       [-0.85971785],\n",
       "       [-1.056432  ],\n",
       "       [-0.7193317 ],\n",
       "       [-0.80093676],\n",
       "       [-0.83699286],\n",
       "       [-0.96463996],\n",
       "       [-1.0310998 ],\n",
       "       [-0.45853946],\n",
       "       [-0.21061285],\n",
       "       [-0.48997885],\n",
       "       [-0.91313845],\n",
       "       [-0.76122457],\n",
       "       [-0.49336353],\n",
       "       [-0.82059896],\n",
       "       [-0.96322364],\n",
       "       [-0.16180266],\n",
       "       [-1.1024368 ],\n",
       "       [-0.54524606],\n",
       "       [-1.028992  ],\n",
       "       [-1.0435519 ],\n",
       "       [-0.8252134 ],\n",
       "       [-0.7697989 ],\n",
       "       [-0.907776  ],\n",
       "       [-0.8829667 ],\n",
       "       [-0.32950813],\n",
       "       [-0.8361546 ],\n",
       "       [-0.9054194 ],\n",
       "       [-0.41027537],\n",
       "       [-0.24644527],\n",
       "       [-0.17954352],\n",
       "       [-0.556157  ],\n",
       "       [-0.9078055 ],\n",
       "       [-0.36080226],\n",
       "       [-0.41073832],\n",
       "       [-0.9120338 ],\n",
       "       [-0.9779798 ],\n",
       "       [-0.678922  ],\n",
       "       [-0.46228537],\n",
       "       [-0.3257853 ],\n",
       "       [-0.8909451 ],\n",
       "       [-0.85570514],\n",
       "       [-0.61080694],\n",
       "       [-0.9721619 ],\n",
       "       [-0.8994147 ],\n",
       "       [-0.5666526 ],\n",
       "       [-0.6945231 ],\n",
       "       [-0.8751384 ],\n",
       "       [-0.96256316],\n",
       "       [-0.32441637],\n",
       "       [-0.4018972 ],\n",
       "       [-0.92307454],\n",
       "       [-0.92732745],\n",
       "       [-0.48979896],\n",
       "       [-0.33761856],\n",
       "       [-1.1310502 ],\n",
       "       [-1.2140938 ],\n",
       "       [-0.6199098 ],\n",
       "       [-0.7097464 ],\n",
       "       [-0.29057685],\n",
       "       [-0.7120251 ],\n",
       "       [-0.972975  ],\n",
       "       [-0.9353625 ],\n",
       "       [-0.86931616],\n",
       "       [-0.65852433],\n",
       "       [-0.4907389 ],\n",
       "       [-0.39333135],\n",
       "       [-0.80468243],\n",
       "       [-0.9797285 ],\n",
       "       [-0.68876386],\n",
       "       [-0.562692  ],\n",
       "       [-0.6621063 ],\n",
       "       [-1.1016778 ],\n",
       "       [-0.6276712 ],\n",
       "       [-0.6037097 ],\n",
       "       [-0.59141856],\n",
       "       [-0.5813346 ],\n",
       "       [-0.9913916 ],\n",
       "       [-0.66795105],\n",
       "       [-0.5284173 ],\n",
       "       [-0.97376204],\n",
       "       [-0.2665581 ],\n",
       "       [-0.9106918 ],\n",
       "       [-1.0178696 ],\n",
       "       [-0.7572572 ],\n",
       "       [-0.236952  ],\n",
       "       [-0.7648385 ],\n",
       "       [-0.6307163 ],\n",
       "       [-0.5041304 ],\n",
       "       [-1.0089253 ],\n",
       "       [-0.93205607],\n",
       "       [-0.12357388],\n",
       "       [-0.35689518],\n",
       "       [-0.523624  ],\n",
       "       [-1.6508666 ],\n",
       "       [-0.878345  ],\n",
       "       [-0.853677  ],\n",
       "       [-0.22301304],\n",
       "       [-0.37666592],\n",
       "       [-0.87728447],\n",
       "       [-0.32693753],\n",
       "       [-0.34601766],\n",
       "       [-0.52518207],\n",
       "       [-0.7223349 ],\n",
       "       [-0.6321415 ],\n",
       "       [-0.35009712],\n",
       "       [-0.23263715],\n",
       "       [-0.41534528],\n",
       "       [-1.0082681 ],\n",
       "       [-0.1745691 ],\n",
       "       [-1.0849297 ],\n",
       "       [-0.9379319 ],\n",
       "       [-0.7471184 ],\n",
       "       [-0.8042172 ],\n",
       "       [-0.96993834],\n",
       "       [-0.817149  ],\n",
       "       [-0.6816768 ],\n",
       "       [-0.5187609 ],\n",
       "       [-0.66519433],\n",
       "       [-0.72593653],\n",
       "       [-0.45280528],\n",
       "       [-1.0256989 ],\n",
       "       [-0.42143252],\n",
       "       [-1.0374255 ],\n",
       "       [-0.47239968],\n",
       "       [-0.69183296],\n",
       "       [-0.4301637 ],\n",
       "       [-0.76358634],\n",
       "       [-0.06041807],\n",
       "       [-0.9626094 ],\n",
       "       [-0.52128553],\n",
       "       [-0.9362781 ],\n",
       "       [-0.58654755],\n",
       "       [-1.0303704 ],\n",
       "       [-0.89682114],\n",
       "       [-0.43255576],\n",
       "       [-0.72606903],\n",
       "       [-1.2356989 ],\n",
       "       [-0.42835507],\n",
       "       [-0.30980384],\n",
       "       [-0.7431721 ],\n",
       "       [-0.8611159 ],\n",
       "       [-0.00293067],\n",
       "       [-1.1751078 ],\n",
       "       [-0.35583282],\n",
       "       [-0.72234446],\n",
       "       [-0.9368732 ],\n",
       "       [-0.49442366],\n",
       "       [-0.34146276],\n",
       "       [-0.7312467 ],\n",
       "       [-0.43074057],\n",
       "       [-1.3723435 ],\n",
       "       [-0.84387386],\n",
       "       [-0.4902321 ],\n",
       "       [-0.54342836],\n",
       "       [-0.5977506 ],\n",
       "       [-1.0200111 ],\n",
       "       [-0.62150097],\n",
       "       [-0.9808493 ],\n",
       "       [-0.67559147],\n",
       "       [ 0.00974765],\n",
       "       [-0.81587154],\n",
       "       [-0.85880846],\n",
       "       [-0.54705316],\n",
       "       [-0.6920032 ],\n",
       "       [-0.55458283],\n",
       "       [-1.3553277 ],\n",
       "       [-0.9899035 ],\n",
       "       [-0.5341107 ],\n",
       "       [-0.94047374],\n",
       "       [-0.58968467],\n",
       "       [-0.74080986],\n",
       "       [-0.2323895 ],\n",
       "       [-0.64695174],\n",
       "       [-0.4947934 ],\n",
       "       [-0.23671111],\n",
       "       [-0.51583475],\n",
       "       [-0.85875463],\n",
       "       [-0.65528786],\n",
       "       [-0.7519211 ],\n",
       "       [-0.253279  ],\n",
       "       [-0.5395918 ],\n",
       "       [-0.34095678],\n",
       "       [-0.48646674],\n",
       "       [-0.70577604],\n",
       "       [-0.5485084 ],\n",
       "       [-0.6789243 ],\n",
       "       [-0.5613231 ],\n",
       "       [-0.55186975],\n",
       "       [-0.5863704 ],\n",
       "       [-0.77600706],\n",
       "       [-0.4556745 ],\n",
       "       [-0.7112817 ],\n",
       "       [-0.31558385],\n",
       "       [-0.9553955 ],\n",
       "       [-0.69957215],\n",
       "       [-1.0438184 ],\n",
       "       [-0.44828865],\n",
       "       [-0.94311446],\n",
       "       [-0.2455399 ],\n",
       "       [-1.3389143 ],\n",
       "       [-1.0456699 ],\n",
       "       [-0.62990147],\n",
       "       [-0.26646295],\n",
       "       [-0.55241466],\n",
       "       [-0.382221  ],\n",
       "       [-0.7028565 ],\n",
       "       [-0.54466194],\n",
       "       [-0.60438335],\n",
       "       [-1.3828908 ],\n",
       "       [-0.3900769 ],\n",
       "       [ 0.2288467 ],\n",
       "       [-0.5049493 ],\n",
       "       [-0.46422228],\n",
       "       [-0.3457646 ],\n",
       "       [-0.9005889 ],\n",
       "       [-0.63850355],\n",
       "       [-0.7410851 ],\n",
       "       [-0.7302346 ],\n",
       "       [-0.37744352],\n",
       "       [-0.78847766],\n",
       "       [-0.68666095],\n",
       "       [-0.55786055],\n",
       "       [-0.9855405 ],\n",
       "       [-0.36967456],\n",
       "       [-0.9429521 ],\n",
       "       [-0.12929301],\n",
       "       [-0.29826564],\n",
       "       [-1.0377086 ],\n",
       "       [-0.7088651 ],\n",
       "       [-0.38461015],\n",
       "       [-0.9160726 ],\n",
       "       [-0.71456647],\n",
       "       [-0.98184526],\n",
       "       [-0.63635087],\n",
       "       [-0.50422585],\n",
       "       [-0.3573824 ],\n",
       "       [-0.26066393],\n",
       "       [-0.46541968],\n",
       "       [-0.9457374 ],\n",
       "       [-0.40827182],\n",
       "       [-0.4418467 ],\n",
       "       [-1.0170201 ],\n",
       "       [-0.59549624],\n",
       "       [-0.95706826],\n",
       "       [-0.75561595],\n",
       "       [-0.01122013],\n",
       "       [-0.9688298 ],\n",
       "       [-0.41327396],\n",
       "       [-0.7296391 ],\n",
       "       [-0.37271717],\n",
       "       [-0.67487913],\n",
       "       [-0.8159863 ],\n",
       "       [-0.23429431],\n",
       "       [-0.65943694],\n",
       "       [-0.8108286 ],\n",
       "       [-0.8861069 ],\n",
       "       [-0.953564  ],\n",
       "       [-0.44864315],\n",
       "       [-0.39927056],\n",
       "       [-0.5951136 ],\n",
       "       [-0.76065093],\n",
       "       [-0.48804963],\n",
       "       [-0.4682955 ],\n",
       "       [-0.31601733],\n",
       "       [-0.685492  ],\n",
       "       [-0.4204578 ],\n",
       "       [-0.9315062 ],\n",
       "       [-0.26142043],\n",
       "       [-0.60272694],\n",
       "       [-0.4393886 ],\n",
       "       [-0.41474494],\n",
       "       [-0.3862864 ],\n",
       "       [-0.79524577],\n",
       "       [-0.40475222],\n",
       "       [-0.75861233],\n",
       "       [-0.8080662 ],\n",
       "       [-0.7602519 ],\n",
       "       [-0.79767114],\n",
       "       [-0.7992301 ],\n",
       "       [-0.79488164]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_predictions = mejor_modelo.predict(X_f)\n",
    "display(scaled_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.35179213, -0.2227672 , -1.0607201 , -0.96052676, -0.8090567 ,\n",
       "       -1.0285374 , -1.0385243 , -0.92248243, -0.21984027, -0.680777  ,\n",
       "       -0.6719221 , -1.0366627 , -0.77319735, -0.9706285 , -0.63779473,\n",
       "       -0.84340256, -0.85607857, -1.0615926 , -1.1376735 , -0.698301  ,\n",
       "       -0.74939156, -0.57719004, -1.022449  , -0.7247625 , -0.7168679 ,\n",
       "       -0.5362008 , -0.79473823, -0.7446399 , -1.0455142 , -0.9270563 ,\n",
       "       -0.73228973, -1.3063878 , -0.7479686 , -0.8976931 , -0.66842604,\n",
       "       -0.68114775, -0.77996063, -0.31360522, -0.78650814, -0.7304057 ,\n",
       "       -0.65408367, -1.0531667 , -0.83315915, -0.91870177, -0.72341293,\n",
       "       -0.8913319 , -1.0244622 , -0.703538  , -0.6758891 , -0.83636814,\n",
       "       -0.7162055 , -0.8179849 , -0.4935185 , -0.612861  , -0.62354654,\n",
       "       -0.8598087 , -0.48593384, -0.7391318 , -0.658394  , -0.7206544 ,\n",
       "       -0.8274422 , -0.6251976 , -0.6586997 , -0.59166414, -0.9253865 ,\n",
       "       -0.10145919, -0.9417461 , -0.67686576, -0.7177919 , -0.9424361 ,\n",
       "       -1.0719031 , -0.72800404, -0.45391628, -0.65677214, -0.518525  ,\n",
       "       -0.2661356 , -0.91242677, -0.8907407 , -0.25616136, -1.1716839 ,\n",
       "       -0.6043011 , -0.8352674 , -0.42261696, -0.75162923, -0.9904768 ,\n",
       "       -0.9044296 , -0.79246944, -0.8419797 , -1.1113124 , -0.41314116,\n",
       "       -0.7628154 , -0.7776925 , -0.42684287, -0.90592796, -1.1014558 ,\n",
       "       -1.1516095 , -0.55266565,  0.01231697, -0.82231456, -0.4740185 ,\n",
       "       -0.9673156 , -1.2555274 , -0.96505874, -0.62959045, -0.6187198 ,\n",
       "       -0.3329316 , -0.4101971 , -1.0408769 , -0.29616585, -0.35096323,\n",
       "       -0.6797252 , -0.52030325, -0.66972524, -0.31799653, -0.31665733,\n",
       "       -0.47292313, -0.77209336, -1.0046266 , -0.23297301, -0.24421766,\n",
       "       -0.8403618 , -0.6298102 , -0.7868783 , -0.3671335 , -1.1044205 ,\n",
       "       -0.20156801, -0.33637503, -0.8418767 , -0.78140527, -0.48058745,\n",
       "       -0.29160658, -0.4619379 , -0.6093908 , -0.7097036 , -0.74105304,\n",
       "       -0.9296479 , -0.05589272, -0.3023704 , -0.7250026 , -0.44973865,\n",
       "       -0.93313056, -0.55756384, -1.196396  , -0.7762583 , -0.7585415 ,\n",
       "       -0.69055283, -0.5200657 , -0.7445604 , -0.779914  , -0.9080987 ,\n",
       "       -0.82654107, -0.9844237 , -0.84565634, -0.5201163 , -0.7156796 ,\n",
       "       -0.8177061 , -0.29216638, -0.8863141 , -0.71464443, -0.68329835,\n",
       "       -0.8264158 , -0.6394059 , -0.15902734, -0.7455012 , -0.83681184,\n",
       "       -1.3977674 , -0.7424086 , -0.77706665, -1.4865735 , -0.4248748 ,\n",
       "       -0.7342016 , -0.9112072 , -0.42563665, -0.77097845, -0.8053504 ,\n",
       "       -0.68960035, -0.69287205, -0.66292375, -0.9860305 , -0.2724319 ,\n",
       "       -1.1221999 , -0.7409062 , -0.7914072 , -0.39962584, -0.2662454 ,\n",
       "       -0.88405365,  0.21627963, -0.6100699 , -0.7429396 , -0.54387414,\n",
       "       -0.90155405, -0.7964045 , -1.5739161 , -0.6843706 , -0.8040218 ,\n",
       "       -1.2299913 , -0.8381814 , -0.8390141 , -0.66124016, -0.52781326,\n",
       "       -0.5980662 , -0.660717  , -0.88562   , -0.3727143 , -0.33803412,\n",
       "       -1.3155496 , -0.84035116, -0.5500109 , -0.25035644, -0.7476158 ,\n",
       "       -0.97474205, -0.9998979 , -1.089789  , -0.5380921 , -0.8111724 ,\n",
       "       -0.6158482 , -0.39192483, -0.7637808 , -1.150544  , -0.5977442 ,\n",
       "       -0.63942266, -0.6308636 , -0.36212435, -0.8742023 , -1.0760329 ,\n",
       "       -0.617304  , -1.0705674 , -0.52657235, -0.72099435, -1.0488222 ,\n",
       "       -0.82131356, -0.4238151 , -0.5580591 , -0.642262  , -0.91131717,\n",
       "       -0.41363224, -0.8575003 , -0.88340825, -0.59287983, -0.9129594 ,\n",
       "       -0.8895013 , -0.09727694, -0.39986056, -0.80142224, -0.70933694,\n",
       "       -0.5797265 , -0.21872345, -0.69122314, -0.46007523,  0.19854179,\n",
       "       -0.84584576, -0.8395058 , -0.3937901 ,  0.09333187, -1.4221331 ,\n",
       "       -0.56810856, -0.7780184 , -1.0262449 , -0.67232406, -0.8295781 ,\n",
       "       -1.0685837 , -0.8251476 , -0.71018744, -0.5172811 , -0.7143638 ,\n",
       "       -0.7625991 , -0.83147424, -0.51708597, -0.8137821 , -0.41176286,\n",
       "       -0.8785504 , -0.639279  , -0.5454801 , -0.86579823, -0.8264683 ,\n",
       "       -0.80662256, -0.4786599 , -0.89814436, -0.6821736 , -0.48458722,\n",
       "       -0.9100278 , -0.30019805, -0.65923905, -0.6468771 , -0.9231928 ,\n",
       "       -0.44439295, -0.20353806, -0.658573  , -0.37244037, -0.8221947 ,\n",
       "       -0.86629575, -0.48390195, -0.639708  , -1.0505048 , -1.6295289 ,\n",
       "       -0.63726336, -0.5945564 , -1.4370247 , -0.5364685 ,  0.43279275,\n",
       "       -0.7505235 , -0.8790103 , -1.2358013 , -0.9305677 , -0.36970016,\n",
       "       -0.85119474, -0.61668074, -0.40676898, -0.88417494,  0.0709134 ,\n",
       "       -1.191211  , -0.91096336, -0.8010637 , -0.80305934, -0.52499855,\n",
       "       -0.83289117, -0.84706205, -0.6847196 , -0.52064073, -0.66973823,\n",
       "       -1.1041802 , -0.5382307 , -0.5205512 , -0.9610644 , -0.90327114,\n",
       "       -0.5465269 , -0.91280466, -0.4338638 , -0.5364035 , -0.87297195,\n",
       "       -0.5117384 , -0.81808007, -0.9275692 , -0.89256483, -0.5042462 ,\n",
       "       -0.6081348 , -0.69624865, -0.050006  , -1.0348833 , -0.9319777 ,\n",
       "       -0.8799514 , -0.6539625 , -0.42870188, -0.8798414 , -0.93791837,\n",
       "       -0.6258895 , -0.10047294, -0.88218504, -0.92651635, -0.82399905,\n",
       "       -0.45646575, -0.8156809 , -0.5594004 ,  0.03204415, -0.6380582 ,\n",
       "       -0.94021785, -0.4737899 , -1.1386532 , -0.3736995 , -0.8377281 ,\n",
       "       -0.7435212 , -0.50962174, -0.37725273, -0.89401525, -0.7234186 ,\n",
       "       -0.55275863, -0.7702361 , -0.19211538, -0.8341917 , -0.7034468 ,\n",
       "       -0.474611  , -0.9397699 , -0.9135108 , -0.5563436 , -0.7499629 ,\n",
       "       -0.44943005, -0.85971785, -1.056432  , -0.7193317 , -0.80093676,\n",
       "       -0.83699286, -0.96463996, -1.0310998 , -0.45853946, -0.21061285,\n",
       "       -0.48997885, -0.91313845, -0.76122457, -0.49336353, -0.82059896,\n",
       "       -0.96322364, -0.16180266, -1.1024368 , -0.54524606, -1.028992  ,\n",
       "       -1.0435519 , -0.8252134 , -0.7697989 , -0.907776  , -0.8829667 ,\n",
       "       -0.32950813, -0.8361546 , -0.9054194 , -0.41027537, -0.24644527,\n",
       "       -0.17954352, -0.556157  , -0.9078055 , -0.36080226, -0.41073832,\n",
       "       -0.9120338 , -0.9779798 , -0.678922  , -0.46228537, -0.3257853 ,\n",
       "       -0.8909451 , -0.85570514, -0.61080694, -0.9721619 , -0.8994147 ,\n",
       "       -0.5666526 , -0.6945231 , -0.8751384 , -0.96256316, -0.32441637,\n",
       "       -0.4018972 , -0.92307454, -0.92732745, -0.48979896, -0.33761856,\n",
       "       -1.1310502 , -1.2140938 , -0.6199098 , -0.7097464 , -0.29057685,\n",
       "       -0.7120251 , -0.972975  , -0.9353625 , -0.86931616, -0.65852433,\n",
       "       -0.4907389 , -0.39333135, -0.80468243, -0.9797285 , -0.68876386,\n",
       "       -0.562692  , -0.6621063 , -1.1016778 , -0.6276712 , -0.6037097 ,\n",
       "       -0.59141856, -0.5813346 , -0.9913916 , -0.66795105, -0.5284173 ,\n",
       "       -0.97376204, -0.2665581 , -0.9106918 , -1.0178696 , -0.7572572 ,\n",
       "       -0.236952  , -0.7648385 , -0.6307163 , -0.5041304 , -1.0089253 ,\n",
       "       -0.93205607, -0.12357388, -0.35689518, -0.523624  , -1.6508666 ,\n",
       "       -0.878345  , -0.853677  , -0.22301304, -0.37666592, -0.87728447,\n",
       "       -0.32693753, -0.34601766, -0.52518207, -0.7223349 , -0.6321415 ,\n",
       "       -0.35009712, -0.23263715, -0.41534528, -1.0082681 , -0.1745691 ,\n",
       "       -1.0849297 , -0.9379319 , -0.7471184 , -0.8042172 , -0.96993834,\n",
       "       -0.817149  , -0.6816768 , -0.5187609 , -0.66519433, -0.72593653,\n",
       "       -0.45280528, -1.0256989 , -0.42143252, -1.0374255 , -0.47239968,\n",
       "       -0.69183296, -0.4301637 , -0.76358634, -0.06041807, -0.9626094 ,\n",
       "       -0.52128553, -0.9362781 , -0.58654755, -1.0303704 , -0.89682114,\n",
       "       -0.43255576, -0.72606903, -1.2356989 , -0.42835507, -0.30980384,\n",
       "       -0.7431721 , -0.8611159 , -0.00293067, -1.1751078 , -0.35583282,\n",
       "       -0.72234446, -0.9368732 , -0.49442366, -0.34146276, -0.7312467 ,\n",
       "       -0.43074057, -1.3723435 , -0.84387386, -0.4902321 , -0.54342836,\n",
       "       -0.5977506 , -1.0200111 , -0.62150097, -0.9808493 , -0.67559147,\n",
       "        0.00974765, -0.81587154, -0.85880846, -0.54705316, -0.6920032 ,\n",
       "       -0.55458283, -1.3553277 , -0.9899035 , -0.5341107 , -0.94047374,\n",
       "       -0.58968467, -0.74080986, -0.2323895 , -0.64695174, -0.4947934 ,\n",
       "       -0.23671111, -0.51583475, -0.85875463, -0.65528786, -0.7519211 ,\n",
       "       -0.253279  , -0.5395918 , -0.34095678, -0.48646674, -0.70577604,\n",
       "       -0.5485084 , -0.6789243 , -0.5613231 , -0.55186975, -0.5863704 ,\n",
       "       -0.77600706, -0.4556745 , -0.7112817 , -0.31558385, -0.9553955 ,\n",
       "       -0.69957215, -1.0438184 , -0.44828865, -0.94311446, -0.2455399 ,\n",
       "       -1.3389143 , -1.0456699 , -0.62990147, -0.26646295, -0.55241466,\n",
       "       -0.382221  , -0.7028565 , -0.54466194, -0.60438335, -1.3828908 ,\n",
       "       -0.3900769 ,  0.2288467 , -0.5049493 , -0.46422228, -0.3457646 ,\n",
       "       -0.9005889 , -0.63850355, -0.7410851 , -0.7302346 , -0.37744352,\n",
       "       -0.78847766, -0.68666095, -0.55786055, -0.9855405 , -0.36967456,\n",
       "       -0.9429521 , -0.12929301, -0.29826564, -1.0377086 , -0.7088651 ,\n",
       "       -0.38461015, -0.9160726 , -0.71456647, -0.98184526, -0.63635087,\n",
       "       -0.50422585, -0.3573824 , -0.26066393, -0.46541968, -0.9457374 ,\n",
       "       -0.40827182, -0.4418467 , -1.0170201 , -0.59549624, -0.95706826,\n",
       "       -0.75561595, -0.01122013, -0.9688298 , -0.41327396, -0.7296391 ,\n",
       "       -0.37271717, -0.67487913, -0.8159863 , -0.23429431, -0.65943694,\n",
       "       -0.8108286 , -0.8861069 , -0.953564  , -0.44864315, -0.39927056,\n",
       "       -0.5951136 , -0.76065093, -0.48804963, -0.4682955 , -0.31601733,\n",
       "       -0.685492  , -0.4204578 , -0.9315062 , -0.26142043, -0.60272694,\n",
       "       -0.4393886 , -0.41474494, -0.3862864 , -0.79524577, -0.40475222,\n",
       "       -0.75861233, -0.8080662 , -0.7602519 , -0.79767114, -0.7992301 ,\n",
       "       -0.79488164], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_predictions_1d =  scaled_predictions.reshape(-1)\n",
    "display(scaled_predictions_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ls/f33jscqd6sb6bd857yb2j2s00000gp/T/ipykernel_42682/3047987798.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1294.9260945789943' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  predictions_df.at[index, 'predicted_y'] = inverse_scaled_prediction\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "    'product_id': product_ids,\n",
    "    'predicted_y': scaled_predictions_1d\n",
    "})\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame predictions_df\n",
    "for index, row in predictions_df.iterrows():\n",
    "    # Obtener el ID del producto y la predicción escalada para este producto\n",
    "    product_id = row['product_id']\n",
    "    scaled_prediction = row['predicted_y']\n",
    "    \n",
    "    # Obtener el escalador correspondiente a 'predicted_y' para este producto\n",
    "    scaler = scalers['y'][(product_id)]\n",
    "    \n",
    "    # Aplicar la inversa del escalador a la predicción 'predicted_y' para este producto\n",
    "    inverse_scaled_prediction = scaler.inverse_transform([[scaled_prediction]])[0][0]\n",
    "    \n",
    "    # Reemplazar la predicción escalada con la predicción invertida en el DataFrame final\n",
    "    predictions_df.at[index, 'predicted_y'] = inverse_scaled_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las predicciones han sido generadas y guardadas en predictions.csv después de aplicar la inversa de los scalers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(780, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction_list = []\n",
    "for product_id, pronostico in predictions.items():\n",
    "    prediction_list.append({'product_id': product_id, 'predicted_y': pronostico})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "predictions_df = pd.concat([predictions_df, pd.DataFrame(prediction_list)], ignore_index=True)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print('Todas las predicciones han sido generadas y guardadas en predictions.csv después de aplicar la inversa de los scalers.')\n",
    "display(predictions_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
