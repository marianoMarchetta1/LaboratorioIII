{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Promediar las vtas de agosto 2019 (201908) como las de julio (201907) y septiembre (201909) para todas las observaciones\n",
    "- Buscar los 'product_id' que tengan poca hitoria (agrupandolos por product_id y periodo y validar que tengan menos registros que training_trashold), eliminarlos del conjunto, y agregarlos el un dataframe \"Predicciones\", poniendo product_id junto con una columna \"prediccion\", que sea la media de las ventas de los periodos\n",
    "- Aplicar LabelEncoder a las columnas categoricas\n",
    "- Agrupar los restantes las ventas por periodo, cat1, cat2, cat3, marca y descripcion\n",
    "- Calcular para estos el ratio de ventas por product_id (para cada grupo de cat1, cat2, cat3, marca y descripcion), guardando esto en un diccionario: cat1, cat2, cat3, marca, descripcion, product_id y ratio\n",
    "\n",
    "----\n",
    "- Agrupar las ventas por periodo, cat1, cat2, cat3, marca, descripcion y customer_id. Sumarizando los valores de las columnas cust_request_qty, cust_request_tn y tn.\n",
    "- Aplicar escalers por columna a cada grupo (guardando estos scalers en un diccionario)\n",
    "- Armar un modelo LSTM para predecir las ventas de cada uno de estos grupos (usando todas las observaciones menos las ultimas 2 para predecir la ultima )\n",
    "----\n",
    "\n",
    "- Luego, para cada grupo, hacer las predicciones con su modelo correspondiente (usando todas las observaciones menos las primeras 2). Guardando estas predicciones en un dataframe con la estructura cat1, cat2, cat3, marca, descripcion\n",
    "- sumarizar las predicciones por cat1, cat2, cat3, marca, descripcion\n",
    "- para cada cat1, cat2, cat3, marca, descripcion, buscar los product_id en el diccionario de ratios, aplicarlo sobre las predicciones sumarizadas, y armar un dataframe product_id y prediccion\n",
    "- unificar este dataframe con el \"Predicciones\"\n",
    "- guardar este df en un csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Datasets/final_dataset_corto.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>close_quarter</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>99.43861</td>\n",
       "      <td>99.43861</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201701</td>\n",
       "      <td>10002</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>38.68301</td>\n",
       "      <td>35.72806</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201701</td>\n",
       "      <td>10003</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>143.49426</td>\n",
       "      <td>143.49426</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201701</td>\n",
       "      <td>10004</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>184.72927</td>\n",
       "      <td>184.72927</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201701</td>\n",
       "      <td>10005</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>19.08407</td>\n",
       "      <td>19.08407</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty   \n",
       "0   201701        10001       20001                      0                11  \\\n",
       "1   201701        10002       20001                      0                17   \n",
       "2   201701        10003       20001                      0                17   \n",
       "3   201701        10004       20001                      0                 9   \n",
       "4   201701        10005       20001                      0                23   \n",
       "\n",
       "   cust_request_tn         tn cat1         cat2     cat3  brand  sku_size   \n",
       "0         99.43861   99.43861   HC  ROPA LAVADO  Liquido  ARIEL      3000  \\\n",
       "1         38.68301   35.72806   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "2        143.49426  143.49426   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "3        184.72927  184.72927   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "4         19.08407   19.08407   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "\n",
       "  descripcion quarter  month  close_quarter  age  \n",
       "0      genoma      Q1      1              0    0  \n",
       "1      genoma      Q1      1              0    0  \n",
       "2      genoma      Q1      1              0    0  \n",
       "3      genoma      Q1      1              0    0  \n",
       "4      genoma      Q1      1              0    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 2: Promediar las ventas de agosto 2019 (201908) con julio (201907) y septiembre (201909)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>close_quarter</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>10001</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>99.43861</td>\n",
       "      <td>99.43861</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>10002</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>38.68301</td>\n",
       "      <td>35.72806</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>10003</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>143.49426</td>\n",
       "      <td>143.49426</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>10004</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>184.72927</td>\n",
       "      <td>184.72927</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>10005</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>19.08407</td>\n",
       "      <td>19.08407</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938365</th>\n",
       "      <td>20854</td>\n",
       "      <td>10373</td>\n",
       "      <td>201912</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03604</td>\n",
       "      <td>0.03604</td>\n",
       "      <td>HC</td>\n",
       "      <td>PROFESIONAL</td>\n",
       "      <td>SUAVIZANTE</td>\n",
       "      <td>INDUSTRIAL</td>\n",
       "      <td>5000</td>\n",
       "      <td>Suavizante</td>\n",
       "      <td>Q4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938366</th>\n",
       "      <td>20854</td>\n",
       "      <td>10380</td>\n",
       "      <td>201912</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01802</td>\n",
       "      <td>0.01802</td>\n",
       "      <td>HC</td>\n",
       "      <td>PROFESIONAL</td>\n",
       "      <td>SUAVIZANTE</td>\n",
       "      <td>INDUSTRIAL</td>\n",
       "      <td>5000</td>\n",
       "      <td>Suavizante</td>\n",
       "      <td>Q4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938367</th>\n",
       "      <td>20854</td>\n",
       "      <td>10465</td>\n",
       "      <td>201912</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03604</td>\n",
       "      <td>0.03604</td>\n",
       "      <td>HC</td>\n",
       "      <td>PROFESIONAL</td>\n",
       "      <td>SUAVIZANTE</td>\n",
       "      <td>INDUSTRIAL</td>\n",
       "      <td>5000</td>\n",
       "      <td>Suavizante</td>\n",
       "      <td>Q4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938368</th>\n",
       "      <td>20854</td>\n",
       "      <td>10468</td>\n",
       "      <td>201912</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16216</td>\n",
       "      <td>0.16216</td>\n",
       "      <td>HC</td>\n",
       "      <td>PROFESIONAL</td>\n",
       "      <td>SUAVIZANTE</td>\n",
       "      <td>INDUSTRIAL</td>\n",
       "      <td>5000</td>\n",
       "      <td>Suavizante</td>\n",
       "      <td>Q4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938369</th>\n",
       "      <td>20854</td>\n",
       "      <td>10499</td>\n",
       "      <td>201912</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01802</td>\n",
       "      <td>0.01802</td>\n",
       "      <td>HC</td>\n",
       "      <td>PROFESIONAL</td>\n",
       "      <td>SUAVIZANTE</td>\n",
       "      <td>INDUSTRIAL</td>\n",
       "      <td>5000</td>\n",
       "      <td>Suavizante</td>\n",
       "      <td>Q4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2938370 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         product_id  customer_id periodo  plan_precios_cuidados   \n",
       "0             20001        10001  201701                      0  \\\n",
       "1             20001        10002  201701                      0   \n",
       "2             20001        10003  201701                      0   \n",
       "3             20001        10004  201701                      0   \n",
       "4             20001        10005  201701                      0   \n",
       "...             ...          ...     ...                    ...   \n",
       "2938365       20854        10373  201912                      0   \n",
       "2938366       20854        10380  201912                      0   \n",
       "2938367       20854        10465  201912                      0   \n",
       "2938368       20854        10468  201912                      0   \n",
       "2938369       20854        10499  201912                      0   \n",
       "\n",
       "         cust_request_qty  cust_request_tn         tn cat1         cat2   \n",
       "0                      11         99.43861   99.43861   HC  ROPA LAVADO  \\\n",
       "1                      17         38.68301   35.72806   HC  ROPA LAVADO   \n",
       "2                      17        143.49426  143.49426   HC  ROPA LAVADO   \n",
       "3                       9        184.72927  184.72927   HC  ROPA LAVADO   \n",
       "4                      23         19.08407   19.08407   HC  ROPA LAVADO   \n",
       "...                   ...              ...        ...  ...          ...   \n",
       "2938365                 1          0.03604    0.03604   HC  PROFESIONAL   \n",
       "2938366                 1          0.01802    0.01802   HC  PROFESIONAL   \n",
       "2938367                 1          0.03604    0.03604   HC  PROFESIONAL   \n",
       "2938368                 1          0.16216    0.16216   HC  PROFESIONAL   \n",
       "2938369                 1          0.01802    0.01802   HC  PROFESIONAL   \n",
       "\n",
       "               cat3       brand  sku_size descripcion quarter  month   \n",
       "0           Liquido       ARIEL      3000      genoma      Q1      1  \\\n",
       "1           Liquido       ARIEL      3000      genoma      Q1      1   \n",
       "2           Liquido       ARIEL      3000      genoma      Q1      1   \n",
       "3           Liquido       ARIEL      3000      genoma      Q1      1   \n",
       "4           Liquido       ARIEL      3000      genoma      Q1      1   \n",
       "...             ...         ...       ...         ...     ...    ...   \n",
       "2938365  SUAVIZANTE  INDUSTRIAL      5000  Suavizante      Q4     12   \n",
       "2938366  SUAVIZANTE  INDUSTRIAL      5000  Suavizante      Q4     12   \n",
       "2938367  SUAVIZANTE  INDUSTRIAL      5000  Suavizante      Q4     12   \n",
       "2938368  SUAVIZANTE  INDUSTRIAL      5000  Suavizante      Q4     12   \n",
       "2938369  SUAVIZANTE  INDUSTRIAL      5000  Suavizante      Q4     12   \n",
       "\n",
       "         close_quarter  age  \n",
       "0                    0    0  \n",
       "1                    0    0  \n",
       "2                    0    0  \n",
       "3                    0    0  \n",
       "4                    0    0  \n",
       "...                ...  ...  \n",
       "2938365              1    0  \n",
       "2938366              1    0  \n",
       "2938367              1    0  \n",
       "2938368              1    0  \n",
       "2938369              1    0  \n",
       "\n",
       "[2938370 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['periodo'] = df['periodo'].astype(str).str.strip()\n",
    "\n",
    "# Filtrar los datos por los periodos 201907, 201908 y 201909\n",
    "df_filtered = df[df['periodo'].isin(['201907', '201908', '201909'])]\n",
    "\n",
    "# # Pivotear los datos para tener columnas separadas para cada periodo\n",
    "pivoted_sales = df_filtered.pivot_table(index=['product_id', 'customer_id'], columns='periodo', values='tn').reset_index()\n",
    "\n",
    "# # Asegurar que las columnas 201907 y 201909 existen en el DataFrame\n",
    "pivoted_sales = pivoted_sales.reindex(columns=['product_id', 'customer_id', '201907', '201908', '201909'])\n",
    "\n",
    "# # Calcular el promedio de julio y septiembre\n",
    "pivoted_sales['201908'] = pivoted_sales[['201907', '201909']].mean(axis=1)\n",
    "\n",
    "# # Convertir de nuevo al formato largo\n",
    "updated_sales = pivoted_sales.melt(id_vars=['product_id', 'customer_id'], value_vars=['201907', '201908', '201909'], \n",
    "                                   var_name='periodo', value_name='tn')\n",
    "\n",
    "# # Unir con el dataframe original\n",
    "df.set_index(['product_id', 'customer_id', 'periodo'], inplace=True)\n",
    "df.update(updated_sales.set_index(['product_id', 'customer_id', 'periodo']))\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame filtrado\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 3: Filtrar y eliminar productos con poca historia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_threshold = 12\n",
    "\n",
    "# Contar el número de registros por product_id y periodo\n",
    "product_history = df.groupby(['product_id', 'periodo']).size().reset_index(name='counts')\n",
    "\n",
    "# Filtrar productos con menos registros que el threshold\n",
    "products_to_keep = product_history[product_history['counts'] >= training_threshold]['product_id'].unique()\n",
    "df_filtered = df[df['product_id'].isin(products_to_keep)]\n",
    "\n",
    "# Crear el DataFrame \"Predicciones\" para productos con poca historia\n",
    "products_to_predict = product_history[product_history['counts'] < training_threshold]['product_id'].unique()\n",
    "predicciones = df[df['product_id'].isin(products_to_predict)].groupby('product_id')['tn'].mean().reset_index()\n",
    "predicciones.rename(columns={'tn': 'prediccion'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 4: Aplicar LabelEncoder a las columnas categóricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_15264\\3135655988.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[col] = le.fit_transform(df_filtered[col])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_15264\\3135655988.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[col] = le.fit_transform(df_filtered[col])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_15264\\3135655988.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[col] = le.fit_transform(df_filtered[col])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_15264\\3135655988.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[col] = le.fit_transform(df_filtered[col])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_15264\\3135655988.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[col] = le.fit_transform(df_filtered[col])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_15264\\3135655988.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[col] = le.fit_transform(df_filtered[col])\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['cat1', 'cat2', 'cat3', 'brand', 'descripcion', 'quarter']\n",
    "\n",
    "# Aplicar LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_filtered[col] = le.fit_transform(df_filtered[col])\n",
    "    label_encoders[col] = le\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 5: Agrupar y calcular el ratio de ventas por product_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por las columnas relevantes\n",
    "grouped_sales = df_filtered.groupby(['periodo', 'cat1', 'cat2', 'cat3', 'brand', 'product_id'])['tn'].sum().reset_index()\n",
    "\n",
    "# Calcular el total de ventas por grupo\n",
    "group_totals = grouped_sales.groupby(['periodo', 'cat1', 'cat2', 'cat3', 'brand'])['tn'].sum().reset_index()\n",
    "\n",
    "# Unir para calcular el ratio\n",
    "ratios = pd.merge(grouped_sales, group_totals, on=['periodo', 'cat1', 'cat2', 'cat3', 'brand'], suffixes=('', '_total'))\n",
    "\n",
    "# Calcular el ratio\n",
    "ratios['ratio'] = ratios['tn'] / ratios['tn_total']\n",
    "\n",
    "# Crear un diccionario de ratios\n",
    "ratio_dict = ratios.set_index(['cat1', 'cat2', 'cat3', 'brand', 'product_id'])['ratio'].to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 6: Agrupar ventas por periodo, cat1, cat2, cat3, brand, descripcion y customer_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar y sumarizar\n",
    "grouped_df = df_filtered.groupby(['periodo', 'cat1', 'cat2', 'cat3', 'brand', 'customer_id', 'quarter', 'month']).agg({\n",
    "    'cust_request_qty': 'sum',\n",
    "    'cust_request_tn': 'sum',\n",
    "    'tn': 'sum'\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>10001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.29877</td>\n",
       "      <td>0.29877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>10002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.71810</td>\n",
       "      <td>0.71810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>10003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.47699</td>\n",
       "      <td>0.47699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>10004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.49795</td>\n",
       "      <td>0.49795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>10005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00524</td>\n",
       "      <td>0.00524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722518</th>\n",
       "      <td>201912</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>33</td>\n",
       "      <td>10004</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00946</td>\n",
       "      <td>0.00946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722519</th>\n",
       "      <td>201912</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>33</td>\n",
       "      <td>10018</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00219</td>\n",
       "      <td>0.00219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722520</th>\n",
       "      <td>201912</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>33</td>\n",
       "      <td>10110</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00073</td>\n",
       "      <td>0.00073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722521</th>\n",
       "      <td>201912</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>33</td>\n",
       "      <td>10159</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>0.00146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722522</th>\n",
       "      <td>201912</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>33</td>\n",
       "      <td>10253</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>0.00146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>722523 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       periodo  cat1  cat2  cat3  brand  customer_id  quarter  month   \n",
       "0       201701     0     0     4     23        10001        0      1  \\\n",
       "1       201701     0     0     4     23        10002        0      1   \n",
       "2       201701     0     0     4     23        10003        0      1   \n",
       "3       201701     0     0     4     23        10004        0      1   \n",
       "4       201701     0     0     4     23        10005        0      1   \n",
       "...        ...   ...   ...   ...    ...          ...      ...    ...   \n",
       "722518  201912     3    13    88     33        10004        3     12   \n",
       "722519  201912     3    13    88     33        10018        3     12   \n",
       "722520  201912     3    13    88     33        10110        3     12   \n",
       "722521  201912     3    13    88     33        10159        3     12   \n",
       "722522  201912     3    13    88     33        10253        3     12   \n",
       "\n",
       "        cust_request_qty  cust_request_tn       tn  \n",
       "0                      5          0.29877  0.29877  \n",
       "1                     25          0.71810  0.71810  \n",
       "2                      6          0.47699  0.47699  \n",
       "3                     11          0.49795  0.49795  \n",
       "4                      1          0.00524  0.00524  \n",
       "...                  ...              ...      ...  \n",
       "722518                 1          0.00946  0.00946  \n",
       "722519                 2          0.00219  0.00219  \n",
       "722520                 1          0.00073  0.00073  \n",
       "722521                 1          0.00146  0.00146  \n",
       "722522                 2          0.00146  0.00146  \n",
       "\n",
       "[722523 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 7: Aplicar escalers por columna a cada grupo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scalers.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un diccionario para almacenar los scalers\n",
    "scalers = {}\n",
    "scaled_df = grouped_df.copy()\n",
    "\n",
    "# Aplicar StandardScaler a cada columna de interés\n",
    "for col in ['cust_request_qty', 'cust_request_tn', 'tn']:\n",
    "    scaler = StandardScaler()\n",
    "    scaled_df[col] = scaler.fit_transform(scaled_df[[col]])\n",
    "    scalers[col] = scaler\n",
    "\n",
    "# Guardar los scalers para su uso posterior\n",
    "joblib.dump(scalers, 'scalers.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 8: Armar un modelo LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, GRU\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, activation='tanh', kernel_regularizer=l2(0.7), return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(256, activation='tanh', kernel_regularizer=l2(0.7), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(512, activation='tanh', kernel_regularizer=l2(0.7), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(512, activation='tanh', kernel_regularizer=l2(0.7), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(512, activation='tanh', kernel_regularizer=l2(0.7), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(256, activation='tanh', kernel_regularizer=l2(0.7), return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(128, activation='relu', kernel_regularizer=l2(0.7)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 9: Entrenar y predecir con el modelo LSTM para cada grupo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/my_env/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "80/80 - 12s - 153ms/step - loss: 282.4401\n",
      "Epoch 2/50\n",
      "80/80 - 4s - 49ms/step - loss: 1.8134\n",
      "Epoch 3/50\n",
      "80/80 - 3s - 41ms/step - loss: 0.0343\n",
      "Epoch 4/50\n",
      "80/80 - 3s - 42ms/step - loss: 0.0274\n",
      "Epoch 5/50\n",
      "80/80 - 4s - 45ms/step - loss: 0.0274\n",
      "Epoch 6/50\n",
      "80/80 - 3s - 41ms/step - loss: 0.0275\n",
      "Epoch 7/50\n",
      "80/80 - 3s - 42ms/step - loss: 0.0274\n",
      "Epoch 8/50\n",
      "80/80 - 4s - 48ms/step - loss: 0.0274\n",
      "Epoch 9/50\n",
      "80/80 - 4s - 48ms/step - loss: 0.0274\n",
      "Epoch 10/50\n",
      "80/80 - 4s - 44ms/step - loss: 0.0275\n",
      "Epoch 11/50\n",
      "80/80 - 4s - 48ms/step - loss: 0.0274\n",
      "Epoch 12/50\n",
      "80/80 - 4s - 45ms/step - loss: 0.0274\n",
      "Epoch 13/50\n",
      "80/80 - 4s - 46ms/step - loss: 0.0274\n",
      "Epoch 14/50\n",
      "80/80 - 4s - 47ms/step - loss: 0.0275\n",
      "Epoch 15/50\n",
      "80/80 - 4s - 49ms/step - loss: 0.0274\n",
      "Epoch 16/50\n",
      "80/80 - 3s - 41ms/step - loss: 0.0274\n",
      "Epoch 17/50\n",
      "80/80 - 3s - 39ms/step - loss: 0.0275\n",
      "Epoch 18/50\n",
      "80/80 - 3s - 39ms/step - loss: 0.0275\n",
      "Epoch 19/50\n",
      "80/80 - 4s - 45ms/step - loss: 0.0274\n",
      "Epoch 20/50\n",
      "80/80 - 4s - 50ms/step - loss: 0.0274\n",
      "Epoch 21/50\n",
      "80/80 - 4s - 52ms/step - loss: 0.0274\n",
      "Epoch 22/50\n",
      "80/80 - 3s - 43ms/step - loss: 0.0275\n",
      "Epoch 23/50\n",
      "80/80 - 4s - 53ms/step - loss: 0.0274\n",
      "Epoch 24/50\n",
      "80/80 - 5s - 56ms/step - loss: 0.0275\n",
      "Epoch 25/50\n",
      "80/80 - 4s - 47ms/step - loss: 0.0275\n",
      "Epoch 26/50\n",
      "80/80 - 4s - 49ms/step - loss: 0.0274\n",
      "Epoch 27/50\n",
      "80/80 - 3s - 40ms/step - loss: 0.0274\n",
      "Epoch 28/50\n",
      "80/80 - 3s - 43ms/step - loss: 0.0275\n",
      "Epoch 29/50\n",
      "80/80 - 4s - 45ms/step - loss: 0.0275\n",
      "Epoch 30/50\n",
      "80/80 - 4s - 47ms/step - loss: 0.0275\n",
      "Epoch 31/50\n",
      "80/80 - 4s - 46ms/step - loss: 0.0274\n",
      "Epoch 32/50\n",
      "80/80 - 4s - 44ms/step - loss: 0.0275\n",
      "Epoch 33/50\n",
      "80/80 - 4s - 46ms/step - loss: 0.0275\n",
      "Epoch 34/50\n",
      "80/80 - 4s - 50ms/step - loss: 0.0274\n",
      "Epoch 35/50\n",
      "80/80 - 4s - 48ms/step - loss: 0.0274\n",
      "Epoch 36/50\n",
      "80/80 - 4s - 45ms/step - loss: 0.0274\n",
      "Epoch 37/50\n",
      "80/80 - 4s - 47ms/step - loss: 0.0275\n",
      "Epoch 38/50\n",
      "80/80 - 3s - 43ms/step - loss: 0.0275\n",
      "Epoch 39/50\n",
      "80/80 - 3s - 42ms/step - loss: 0.0274\n",
      "Epoch 40/50\n",
      "80/80 - 4s - 50ms/step - loss: 0.0274\n",
      "Epoch 41/50\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por las columnas relevantes\n",
    "grouped_df['periodo'] = pd.to_datetime(grouped_df['periodo'], format='%Y%m')\n",
    "\n",
    "# Crear un diccionario para almacenar los modelos por grupo\n",
    "models = {}\n",
    "predictions = []\n",
    "\n",
    "for (cat1, cat2, cat3, brand, customer_id), group_data in grouped_df.groupby(['cat1', 'cat2', 'cat3', 'brand','customer_id']):\n",
    "    # Ordenar por periodo\n",
    "    group_data = group_data.sort_values(by='periodo')\n",
    "    \n",
    "    # Transformar los datos para LSTM\n",
    "    n_steps = 2  # Por ejemplo\n",
    "    X, y = [], []\n",
    "    \n",
    "    X = group_data[['cust_request_qty', 'cust_request_tn', 'cat1', 'cat2', 'cat3', 'brand', 'customer_id', 'quarter', 'month', 'tn']]\n",
    "    y = group_data['tn']\n",
    "    \n",
    "    X = np.reshape(X, (X.shape[0], 1, X.shape[1]))  # (número de muestras, timesteps, características)\n",
    "    \n",
    "    # Construir y entrenar el modelo\n",
    "    model = build_lstm_model((X.shape[1], X.shape[2]))\n",
    "    model.fit(X[:-n_steps], y[n_steps:], epochs=50, verbose=2)\n",
    "    models[(cat1, cat2, cat3, brand, customer_id)] = model\n",
    "    \n",
    "    # Hacer predicciones\n",
    "    X_pred = group_data[['cust_request_qty', 'cust_request_tn', 'cat1', 'cat2', 'cat3', 'brand', 'customer_id', 'quarter', 'month', 'tn']].values[-n_steps:]  # Tomar los últimos n_steps\n",
    "    X_pred = np.reshape(X_pred, (1, X_pred.shape[0], X_pred.shape[1]))  # Asegurar la forma correcta para la predicción\n",
    "    pred = model.predict(X_pred, verbose=2)\n",
    "    predictions.append([cat1, cat2, cat3, brand, customer_id, pred[0][0]])\n",
    "    display(f\"Prediccion {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 10: Sumarizar las predicciones y aplicar ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las predicciones a un DataFrame\n",
    "pred_df = pd.DataFrame(predictions, columns=['cat1', 'cat2', 'cat3', 'brand', 'prediccion', 'customer_id'])\n",
    "\n",
    "# Sumarizar las predicciones por grupo\n",
    "summarized_preds = pred_df.groupby(['cat1', 'cat2', 'cat3', 'brand'])['prediccion'].sum().reset_index()\n",
    "\n",
    "# Aplicar los ratios para obtener las predicciones finales por product_id\n",
    "final_predictions = []\n",
    "for _, row in summarized_preds.iterrows():\n",
    "    key = (row['cat1'], row['cat2'], row['cat3'], row['brand'])\n",
    "    for (cat1, cat2, cat3, brand, product_id), ratio in ratio_dict.items():\n",
    "        if (cat1, cat2, cat3, brand) == key:\n",
    "            final_predictions.append([product_id, row['prediccion'] * ratio])\n",
    "\n",
    "# Convertir las predicciones finales a un DataFrame\n",
    "final_predictions_df = pd.DataFrame(final_predictions, columns=['product_id', 'prediccion'])\n",
    "\n",
    "# Paso 11: Desescalar las predicciones finales\n",
    "# Cargar los scalers guardados\n",
    "scalers = joblib.load('scalers.pkl')\n",
    "\n",
    "# Desescalar las predicciones finales\n",
    "final_predictions_df['prediccion'] = scalers['tn'].inverse_transform(final_predictions_df[['prediccion']])\n",
    "\n",
    "# Unificar con el DataFrame \"Predicciones\"\n",
    "final_df = pd.concat([final_predictions_df, predicciones])\n",
    "\n",
    "# Guardar el resultado en un archivo CSV\n",
    "final_df.to_csv('predicciones_finales.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
