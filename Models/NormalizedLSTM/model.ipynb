{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.read_csv('../../Datasets/final_dataset.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>y</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>stock_final</th>\n",
       "      <th>close_quarter</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>479</td>\n",
       "      <td>937.72717</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201702</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>833.72187</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201703</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>509</td>\n",
       "      <td>1330.74697</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201704</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>1132.94430</td>\n",
       "      <td>1069.96130</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201705</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>701</td>\n",
       "      <td>1550.68936</td>\n",
       "      <td>1502.20132</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   periodo  product_id  plan_precios_cuidados  cust_request_qty  \\\n",
       "0   201701       20001                      0               479   \n",
       "1   201702       20001                      0               432   \n",
       "2   201703       20001                      0               509   \n",
       "3   201704       20001                      0               279   \n",
       "4   201705       20001                      0               701   \n",
       "\n",
       "   cust_request_tn           y cat1         cat2     cat3  brand  sku_size  \\\n",
       "0        937.72717   934.77222   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "1        833.72187   798.01620   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "2       1330.74697  1303.35771   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "3       1132.94430  1069.96130   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "4       1550.68936  1502.20132   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "\n",
       "   stock_final  close_quarter  age  \n",
       "0          NaN              0    0  \n",
       "1          NaN              0    1  \n",
       "2          NaN              1    2  \n",
       "3          NaN              0    3  \n",
       "4          NaN              0    4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['plan_precios_cuidados', 'cust_request_qty', 'cust_request_tn', 'close_quarter', 'age', 'y']\n",
    "columns = ['plan_precios_cuidados', 'cust_request_qty', 'cust_request_tn', 'close_quarter','y']\n",
    "n_features = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fb41026c310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped = final_dataset.groupby('product_id')\n",
    "display(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {col: {} for col in columns}\n",
    "scaled_data_list = []\n",
    "\n",
    "for product_id, group in grouped:\n",
    "    scaled_group = group.copy()\n",
    "    for col in columns:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_group[col] = scaler.fit_transform(group[[col]])\n",
    "        scalers[col][product_id] = scaler\n",
    "    scaled_data_list.append(scaled_group)\n",
    "\n",
    "# Combinar todos los datos escalados en un solo DataFrame\n",
    "scaled_data = pd.concat(scaled_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>close_quarter</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461891</td>\n",
       "      <td>-1.704215</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-1.576908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.046911</td>\n",
       "      <td>-2.039835</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-2.042103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786658</td>\n",
       "      <td>-0.435961</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>-0.323111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.703222</td>\n",
       "      <td>-1.074260</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-1.117043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.865166</td>\n",
       "      <td>0.273781</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.353285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21615</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.652507</td>\n",
       "      <td>-0.792584</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.792584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.268679</td>\n",
       "      <td>-0.649760</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.649760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21617</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115148</td>\n",
       "      <td>-0.595870</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.595870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21618</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012794</td>\n",
       "      <td>-0.290890</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.290890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21619</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.036335</td>\n",
       "      <td>-0.882724</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.882724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22349 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       plan_precios_cuidados  cust_request_qty  cust_request_tn  \\\n",
       "0                        0.0          0.461891        -1.704215   \n",
       "1                        0.0         -0.046911        -2.039835   \n",
       "2                        0.0          0.786658        -0.435961   \n",
       "3                        0.0         -1.703222        -1.074260   \n",
       "4                        0.0          2.865166         0.273781   \n",
       "...                      ...               ...              ...   \n",
       "21615                    0.0         -0.652507        -0.792584   \n",
       "21616                    0.0         -0.268679        -0.649760   \n",
       "21617                    0.0          0.115148        -0.595870   \n",
       "21618                    0.0         -0.012794        -0.290890   \n",
       "21619                    0.0         -1.036335        -0.882724   \n",
       "\n",
       "       close_quarter         y  \n",
       "0          -0.707107 -1.576908  \n",
       "1          -0.707107 -2.042103  \n",
       "2           1.414214 -0.323111  \n",
       "3          -0.707107 -1.117043  \n",
       "4          -0.707107  0.353285  \n",
       "...              ...       ...  \n",
       "21615      -0.816497 -0.792584  \n",
       "21616       1.224745 -0.649760  \n",
       "21617      -0.816497 -0.595870  \n",
       "21618      -0.816497 -0.290890  \n",
       "21619       1.224745 -0.882724  \n",
       "\n",
       "[22349 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(scaled_data[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion para preparar los datos y crear el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es predecir 2 dias en el futuro, por lo que la idea es re-armar el dataset. Donde el valor de X sera el conjunto de datos hasta N-2 e Y va a ser N (siendo N la cantidad de ventas para ese producto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data,validation=False):\n",
    "    X, y = [], []\n",
    "    unique_product_ids = data['product_id'].unique()\n",
    "    \n",
    "    max_seq_length = 0\n",
    "    \n",
    "    for product_id in unique_product_ids:\n",
    "        product_data = data[data['product_id'] == product_id].copy()\n",
    "        product_values = product_data[columns].values\n",
    "        \n",
    "        max_seq_length = max(max_seq_length, len(product_values))\n",
    "    \n",
    "    for product_id in unique_product_ids:\n",
    "        product_data = data[data['product_id'] == product_id].copy()\n",
    "        product_values = product_data[columns].values\n",
    "        \n",
    "        pad_length = max_seq_length - len(product_values)\n",
    "        \n",
    "        # Aplicar padding con ceros a la izquierda para igualar la longitud\n",
    "        padded_product_values = np.pad(product_values[:, :-1], ((pad_length, 0), (0, 0)), mode='constant')\n",
    "        \n",
    "        if validation:\n",
    "            X.append(padded_product_values[2:]) #<= TODO: Cambiar por X.append(padded_product_values[:-2]). Para esto hay que agregar 2 registros con 0s extra en caso\n",
    "                                                #         de NO validacion, sino no va a matchear el tamaño de la entrada a la red neuronal.\n",
    "            \n",
    "            y.append(product_id)\n",
    "        else:\n",
    "            X.append(padded_product_values[:-2])  # Todas las observaciones menos las últimas dos\n",
    "            y.append(product_values[-1, -1])      # Última observación\n",
    "    \n",
    "    if validation:\n",
    "        return np.array(X), np.array(y), max_seq_length\n",
    "    else:\n",
    "        return np.array(X), np.array(y), max_seq_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la funcion para crear el modelo LSTM, sobre este se ejecutara la optimizacion bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2  # número de pasos de tiempo\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scaled_data[columns].values\n",
    "X, y, max_seq_length = prepare_data(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisamos que la funcion genere registros coherentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.46189074, -1.70421544, -0.70710678, -1.57690786],\n",
       "       [ 0.        , -0.04691078, -2.0398351 , -0.70710678, -2.04210334],\n",
       "       [ 0.        ,  0.78665767, -0.43596114,  1.41421356, -0.32311076],\n",
       "       [ 0.        , -1.7032221 , -1.07425999, -0.70710678, -1.11704256],\n",
       "       [ 0.        ,  2.865166  ,  0.27378143, -0.70710678,  0.35328467],\n",
       "       [ 0.        ,  1.44701708,  0.35490544,  1.41421356,  0.4140519 ],\n",
       "       [ 0.        , -0.59901455, -1.22422686, -0.70710678, -1.25068433],\n",
       "       [ 0.        ,  2.23728327, -0.5685186 , -0.70710678, -0.44544444],\n",
       "       [ 0.        , -0.59901455, -0.35136974,  1.41421356, -0.27688808],\n",
       "       [ 0.        , -1.76817549, -0.07823625, -0.70710678,  0.14086658],\n",
       "       [ 0.        ,  0.89491331,  0.39077184, -0.70710678,  0.6195406 ],\n",
       "       [ 0.        , -0.01443409, -1.18431507,  1.41421356, -1.18702359],\n",
       "       [ 0.        ,  0.00721704, -0.67712904, -0.70710678, -0.77989182],\n",
       "       [ 0.        , -1.45423413, -1.01800077, -0.70710678, -1.20615411],\n",
       "       [ 0.        ,  1.67435393,  1.40999356,  1.41421356,  1.55962382],\n",
       "       [ 0.        , -0.56653786, -0.57996109, -0.70710678, -0.50024494],\n",
       "       [ 0.        ,  0.21290276, -0.52349429, -0.70710678, -0.35528975],\n",
       "       [ 0.        ,  0.6567509 , -0.8627105 ,  1.41421356, -0.84208625],\n",
       "       [ 0.        ,  0.23455389,  0.20248022, -0.70710678,  0.24514218],\n",
       "       [ 0.        ,  1.06812234,  1.27153863, -0.70710678,  1.36956145],\n",
       "       [ 0.        , -0.38250327,  0.5277091 ,  1.41421356,  0.13718913],\n",
       "       [ 0.        , -0.20929424,  3.09096946, -0.70710678,  3.0507792 ],\n",
       "       [ 0.        ,  0.11547269,  1.54894286, -0.70710678,  1.41056294],\n",
       "       [ 0.        ,  0.18042607,  0.31121506,  1.41421356,  0.3005094 ],\n",
       "       [ 0.        , -0.71809576, -0.30360036, -0.70710678, -0.41694243],\n",
       "       [ 0.        , -0.75057245, -0.39321254, -0.70710678, -0.47368146],\n",
       "       [ 0.        ,  0.19125163,  0.45609868,  1.41421356,  0.24598048],\n",
       "       [ 0.        ,  0.45106518,  0.94189948, -0.70710678,  0.8480103 ],\n",
       "       [ 0.        , -1.38928074,  0.73751536, -0.70710678,  0.78727002],\n",
       "       [ 0.        , -0.43663109, -0.65930222,  1.41421356, -0.98105707],\n",
       "       [ 0.        , -0.04691078,  1.02283623, -0.70710678,  0.95466787],\n",
       "       [ 0.        , -0.77222358, -0.65413297, -0.70710678, -0.46602211],\n",
       "       [ 0.        , -0.47993335,  0.86609599,  1.41421356,  0.89007889],\n",
       "       [ 0.        , -0.75057245,  0.39377835, -0.70710678,  0.55501652],\n",
       "       [ 0.        , -0.47993335, -0.06379056, -0.70710678, -0.00330644],\n",
       "       [ 0.        , -0.31754988,  0.59574087,  1.41421356,  0.36174538]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Muestro todos los registros del ultimo producto\n",
    "unique_product_ids = scaled_data['product_id'].unique()\n",
    "product_data = scaled_data[scaled_data['product_id'] == unique_product_ids[0]] #<= cambiar el indice entre 0 y -1 para ver la diferencia agregada por el padleft\n",
    "product_values = product_data[columns].values\n",
    "display(product_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.46189074, -1.70421544, -0.70710678],\n",
       "       [ 0.        , -0.04691078, -2.0398351 , -0.70710678],\n",
       "       [ 0.        ,  0.78665767, -0.43596114,  1.41421356],\n",
       "       [ 0.        , -1.7032221 , -1.07425999, -0.70710678],\n",
       "       [ 0.        ,  2.865166  ,  0.27378143, -0.70710678],\n",
       "       [ 0.        ,  1.44701708,  0.35490544,  1.41421356],\n",
       "       [ 0.        , -0.59901455, -1.22422686, -0.70710678],\n",
       "       [ 0.        ,  2.23728327, -0.5685186 , -0.70710678],\n",
       "       [ 0.        , -0.59901455, -0.35136974,  1.41421356],\n",
       "       [ 0.        , -1.76817549, -0.07823625, -0.70710678],\n",
       "       [ 0.        ,  0.89491331,  0.39077184, -0.70710678],\n",
       "       [ 0.        , -0.01443409, -1.18431507,  1.41421356],\n",
       "       [ 0.        ,  0.00721704, -0.67712904, -0.70710678],\n",
       "       [ 0.        , -1.45423413, -1.01800077, -0.70710678],\n",
       "       [ 0.        ,  1.67435393,  1.40999356,  1.41421356],\n",
       "       [ 0.        , -0.56653786, -0.57996109, -0.70710678],\n",
       "       [ 0.        ,  0.21290276, -0.52349429, -0.70710678],\n",
       "       [ 0.        ,  0.6567509 , -0.8627105 ,  1.41421356],\n",
       "       [ 0.        ,  0.23455389,  0.20248022, -0.70710678],\n",
       "       [ 0.        ,  1.06812234,  1.27153863, -0.70710678],\n",
       "       [ 0.        , -0.38250327,  0.5277091 ,  1.41421356],\n",
       "       [ 0.        , -0.20929424,  3.09096946, -0.70710678],\n",
       "       [ 0.        ,  0.11547269,  1.54894286, -0.70710678],\n",
       "       [ 0.        ,  0.18042607,  0.31121506,  1.41421356],\n",
       "       [ 0.        , -0.71809576, -0.30360036, -0.70710678],\n",
       "       [ 0.        , -0.75057245, -0.39321254, -0.70710678],\n",
       "       [ 0.        ,  0.19125163,  0.45609868,  1.41421356],\n",
       "       [ 0.        ,  0.45106518,  0.94189948, -0.70710678],\n",
       "       [ 0.        , -1.38928074,  0.73751536, -0.70710678],\n",
       "       [ 0.        , -0.43663109, -0.65930222,  1.41421356],\n",
       "       [ 0.        , -0.04691078,  1.02283623, -0.70710678],\n",
       "       [ 0.        , -0.77222358, -0.65413297, -0.70710678],\n",
       "       [ 0.        , -0.47993335,  0.86609599,  1.41421356],\n",
       "       [ 0.        , -0.75057245,  0.39377835, -0.70710678]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X[0]) #<= cambiar el indice entre 0 y -1 para ver la diferencia agregada por el padleft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3617453793178112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y[0]) #<= cambiar el indice entre 0 y -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import MeanAbsoluteError\n",
    "\n",
    "def create_model(units, learning_rate, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(max_seq_length - n_steps, n_features)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=units, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[MeanAbsoluteError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armado de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    # 'depth': [2, 3, 4, 5, 6],\n",
    "    # 'activation': ['relu', 'tanh', 'swish', 'selu'],\n",
    "    'units': [64, 128, 256, 512],\n",
    "    # 'dropout_rate': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'epochs': [10, 20, 30, 50, 100],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'optimizer': ['adam', 'rmsprop', 'sgd'],\n",
    "    # 'l2_penalty': [0.001, 0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(\n",
    "    build_fn=create_model,\n",
    "    verbose=1,\n",
    "    units=64,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "# cv = TimeSeriesSplit(n_splits=5).split(X)\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    n_iter=50,\n",
    "    # cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 17s 3s/step - loss: 0.3721 - mean_absolute_error: 0.4634\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.4075 - mean_absolute_error: 0.4798\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3721 - mean_absolute_error: 0.4641\n",
      "3/5 [=================>............] - ETA: 7s - loss: 0.3906 - mean_absolute_error: 0.4675 Epoch 15/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3801 - mean_absolute_error: 0.4745\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3914 - mean_absolute_error: 0.4702\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3575 - mean_absolute_error: 0.4545\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.4004 - mean_absolute_error: 0.4739\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3789 - mean_absolute_error: 0.4666\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3829 - mean_absolute_error: 0.4656\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3696 - mean_absolute_error: 0.4667\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3494 - mean_absolute_error: 0.4499\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.3946 - mean_absolute_error: 0.4683\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3539 - mean_absolute_error: 0.4460\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3709 - mean_absolute_error: 0.4567\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3615 - mean_absolute_error: 0.4608\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3405 - mean_absolute_error: 0.4431\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3493 - mean_absolute_error: 0.4440\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3847 - mean_absolute_error: 0.4618\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3559 - mean_absolute_error: 0.4591\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3707 - mean_absolute_error: 0.4563\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3401 - mean_absolute_error: 0.4466\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3445 - mean_absolute_error: 0.4421\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3785 - mean_absolute_error: 0.4621\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3678 - mean_absolute_error: 0.4542\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3542 - mean_absolute_error: 0.4568\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3468 - mean_absolute_error: 0.4577\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3403 - mean_absolute_error: 0.4439\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3854 - mean_absolute_error: 0.4657\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3474 - mean_absolute_error: 0.4560\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3563 - mean_absolute_error: 0.4484\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3300 - mean_absolute_error: 0.4399\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3454 - mean_absolute_error: 0.4465\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3617 - mean_absolute_error: 0.4506\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 7s 897ms/stepss: 0.3161 - mean_absolute_error: 0.42\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3591 - mean_absolute_error: 0.4541\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3389 - mean_absolute_error: 0.4499\n",
      "2/2 [==============================] - 6s 627ms/steps: 0.3521 - mean_absolute_error: 0.450\n",
      "2/2 [==============================] - 5s 847ms/steps: 0.4028 - mean_absolute_error: 0.47\n",
      "2/2 [==============================] - 5s 767ms/step\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.3674 - mean_absolute_error: 0.4579\n",
      "2/2 [==============================] - 3s 567ms/step\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 17:23:53.550790: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 17:23:53.552511: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 17:23:53.584922: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 17:23:53.609247: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 17:23:53.663461: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "20/20 [==============================] - 39s 1s/step - loss: 0.8973 - mean_absolute_error: 0.7727\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.9365 - mean_absolute_error: 0.7924\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.8685 - mean_absolute_error: 0.7648\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.9167 - mean_absolute_error: 0.7884\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.8747 - mean_absolute_error: 0.7609\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.5569 - mean_absolute_error: 0.5831\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.5507 - mean_absolute_error: 0.5796\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.5341 - mean_absolute_error: 0.5619\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.6348 - mean_absolute_error: 0.6219\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.5726 - mean_absolute_error: 0.5812\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.4330 - mean_absolute_error: 0.5010\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.4266 - mean_absolute_error: 0.5050\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.4723 - mean_absolute_error: 0.5287\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.5272 - mean_absolute_error: 0.5538\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 44s 2s/step - loss: 0.4706 - mean_absolute_error: 0.5132\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 44s 2s/step - loss: 0.4012 - mean_absolute_error: 0.4833\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 44s 2s/step - loss: 0.3821 - mean_absolute_error: 0.4781\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.4559 - mean_absolute_error: 0.5031\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 45s 2s/step - loss: 0.4359 - mean_absolute_error: 0.5008\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 47s 2s/step - loss: 0.4134 - mean_absolute_error: 0.4785\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.3778 - mean_absolute_error: 0.4768\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.3715 - mean_absolute_error: 0.4676\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.4215 - mean_absolute_error: 0.4812\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.3916 - mean_absolute_error: 0.4687\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 44s 2s/step - loss: 0.3972 - mean_absolute_error: 0.4781\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.3547 - mean_absolute_error: 0.4614\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.3585 - mean_absolute_error: 0.4609\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.4136 - mean_absolute_error: 0.4876\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.3775 - mean_absolute_error: 0.4695\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.3709 - mean_absolute_error: 0.4567\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.3296 - mean_absolute_error: 0.4373\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.3380 - mean_absolute_error: 0.4490\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.4010 - mean_absolute_error: 0.4760\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.3773 - mean_absolute_error: 0.4701\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 43s 2s/step - loss: 0.3583 - mean_absolute_error: 0.4493\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.3537 - mean_absolute_error: 0.4687\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.3711 - mean_absolute_error: 0.4582\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.3217 - mean_absolute_error: 0.4404\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.3328 - mean_absolute_error: 0.4357\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 43s 2s/step - loss: 0.3658 - mean_absolute_error: 0.4561\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.3150 - mean_absolute_error: 0.4304\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.3531 - mean_absolute_error: 0.4463\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.3208 - mean_absolute_error: 0.4442\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 44s 2s/step - loss: 0.3155 - mean_absolute_error: 0.4252\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.3174 - mean_absolute_error: 0.4223\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 34s 2s/step - loss: 0.3014 - mean_absolute_error: 0.4243\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.3077 - mean_absolute_error: 0.4246\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.3350 - mean_absolute_error: 0.4359\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.3191 - mean_absolute_error: 0.4333\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.3317 - mean_absolute_error: 0.4368\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 34s 2s/step - loss: 0.3195 - mean_absolute_error: 0.4428\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2993 - mean_absolute_error: 0.4224\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.3225 - mean_absolute_error: 0.4315\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.3167 - mean_absolute_error: 0.4318\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.2993 - mean_absolute_error: 0.4234\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.3014 - mean_absolute_error: 0.4108\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.2747 - mean_absolute_error: 0.4010\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.3224 - mean_absolute_error: 0.4265\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.2870 - mean_absolute_error: 0.4090\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.2848 - mean_absolute_error: 0.4113\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.2847 - mean_absolute_error: 0.3989\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.2707 - mean_absolute_error: 0.3999\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.3051 - mean_absolute_error: 0.4149\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.2853 - mean_absolute_error: 0.4021\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.2707 - mean_absolute_error: 0.4005\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.2907 - mean_absolute_error: 0.4126\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.2836 - mean_absolute_error: 0.4169\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.3186 - mean_absolute_error: 0.4272\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2644 - mean_absolute_error: 0.3926\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2715 - mean_absolute_error: 0.4044\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.2903 - mean_absolute_error: 0.4110\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.2610 - mean_absolute_error: 0.3929\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.3011 - mean_absolute_error: 0.4122\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.2635 - mean_absolute_error: 0.3815\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2745 - mean_absolute_error: 0.4011\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.2949 - mean_absolute_error: 0.4204\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2901 - mean_absolute_error: 0.4219\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.2503 - mean_absolute_error: 0.3743\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.3177 - mean_absolute_error: 0.4316\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.2677 - mean_absolute_error: 0.3982\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.3090 - mean_absolute_error: 0.4268\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2756 - mean_absolute_error: 0.4062\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2830 - mean_absolute_error: 0.4029\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.3091 - mean_absolute_error: 0.4176\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.2865 - mean_absolute_error: 0.4174\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.2746 - mean_absolute_error: 0.3959\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.2570 - mean_absolute_error: 0.3916\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.3004 - mean_absolute_error: 0.4272\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 43s 2s/step - loss: 0.2763 - mean_absolute_error: 0.3945\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.2866 - mean_absolute_error: 0.4164\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2603 - mean_absolute_error: 0.3769\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.2707 - mean_absolute_error: 0.4029\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.2671 - mean_absolute_error: 0.3983\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.2691 - mean_absolute_error: 0.3907\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.2630 - mean_absolute_error: 0.3914\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.2589 - mean_absolute_error: 0.3816\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.3135 - mean_absolute_error: 0.4361\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.2327 - mean_absolute_error: 0.3587\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.2663 - mean_absolute_error: 0.3885\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.2660 - mean_absolute_error: 0.3943\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2497 - mean_absolute_error: 0.3717\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2829 - mean_absolute_error: 0.4133\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.2351 - mean_absolute_error: 0.3591\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.2643 - mean_absolute_error: 0.3860\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.2852 - mean_absolute_error: 0.4226\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.2584 - mean_absolute_error: 0.3832\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.2524 - mean_absolute_error: 0.3877\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.2397 - mean_absolute_error: 0.3671\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.2789 - mean_absolute_error: 0.3985\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2488 - mean_absolute_error: 0.3689\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2872 - mean_absolute_error: 0.4161\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2578 - mean_absolute_error: 0.3894\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.2532 - mean_absolute_error: 0.3847\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.2661 - mean_absolute_error: 0.3843\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.2463 - mean_absolute_error: 0.3813\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.3068 - mean_absolute_error: 0.4280\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.2479 - mean_absolute_error: 0.3828\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 32s 2s/step - loss: 0.2551 - mean_absolute_error: 0.3765\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.2254 - mean_absolute_error: 0.3516\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.2347 - mean_absolute_error: 0.3695\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.2994 - mean_absolute_error: 0.4171\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 43s 2s/step - loss: 0.2419 - mean_absolute_error: 0.3764\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.2500 - mean_absolute_error: 0.3738\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.2352 - mean_absolute_error: 0.3653\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2346 - mean_absolute_error: 0.3729\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.2471 - mean_absolute_error: 0.3731\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.2414 - mean_absolute_error: 0.3717\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 33s 2s/step - loss: 0.2326 - mean_absolute_error: 0.3666\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.2691 - mean_absolute_error: 0.3989\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.2436 - mean_absolute_error: 0.3757\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.2653 - mean_absolute_error: 0.3851\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.2474 - mean_absolute_error: 0.3794\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.2235 - mean_absolute_error: 0.3592\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 43s 2s/step - loss: 0.2644 - mean_absolute_error: 0.3900\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2760 - mean_absolute_error: 0.4153\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.2381 - mean_absolute_error: 0.3729\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.2269 - mean_absolute_error: 0.3595\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 46s 2s/step - loss: 0.2614 - mean_absolute_error: 0.3913\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 46s 2s/step - loss: 0.2472 - mean_absolute_error: 0.3714\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.2400 - mean_absolute_error: 0.3712\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 35s 2s/step - loss: 0.2422 - mean_absolute_error: 0.3748\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 39s 2s/step - loss: 0.2276 - mean_absolute_error: 0.3588\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 46s 2s/step - loss: 0.2757 - mean_absolute_error: 0.3972\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2256 - mean_absolute_error: 0.3609\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.2490 - mean_absolute_error: 0.3757\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 34s 2s/step - loss: 0.2599 - mean_absolute_error: 0.3864\n",
      "5/5 [==============================] - 8s 780ms/steploss: 0.2577 - mean_absolute_error: 0.36\n",
      "5/5 [==============================] - 9s 768ms/steploss: 0.2504 - mean_absolute_error: 0.35\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.2151 - mean_absolute_error: 0.3421\n",
      "5/5 [==============================] - 6s 595ms/steploss: 0.2589 - mean_absolute_error: 0.37\n",
      "20/20 [==============================] - 34s 2s/step - loss: 0.2358 - mean_absolute_error: 0.3582\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 30s 1s/step - loss: 0.2546 - mean_absolute_error: 0.3793\n",
      "5/5 [==============================] - 5s 573ms/steposs: 0.2576 - mean_absolute_error: 0.38\n",
      "20/20 [==============================] - 21s 1s/step - loss: 0.2393 - mean_absolute_error: 0.3713\n",
      "5/5 [==============================] - 4s 417ms/step\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "20/20 [==============================] - 11s 54ms/step - loss: 0.8052 - mean_absolute_error: 0.7168\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 11s 59ms/step - loss: 0.7702 - mean_absolute_error: 0.7027\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 11s 63ms/step - loss: 0.8030 - mean_absolute_error: 0.7082\n",
      "16/20 [=======================>......] - ETA: 0s - loss: 0.9092 - mean_absolute_error: 0.7682Epoch 2/20\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.5475 - mean_absolute_error: 0.5568\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 11s 75ms/step - loss: 0.8765 - mean_absolute_error: 0.7496\n",
      " 6/20 [========>.....................] - ETA: 0s - loss: 0.4620 - mean_absolute_error: 0.5398Epoch 2/20\n",
      "20/20 [==============================] - 11s 81ms/step - loss: 0.7263 - mean_absolute_error: 0.6653\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.5331 - mean_absolute_error: 0.5550\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.6091 - mean_absolute_error: 0.5846\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.4723 - mean_absolute_error: 0.5239\n",
      " 6/20 [========>.....................] - ETA: 0s - loss: 0.4354 - mean_absolute_error: 0.4966Epoch 4/20\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.6214 - mean_absolute_error: 0.5981\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.5123 - mean_absolute_error: 0.5537\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.4450 - mean_absolute_error: 0.5105\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.5180 - mean_absolute_error: 0.5370\n",
      " 7/20 [=========>....................] - ETA: 0s - loss: 0.4260 - mean_absolute_error: 0.4961Epoch 4/20\n",
      "20/20 [==============================] - 1s 71ms/step - loss: 0.3976 - mean_absolute_error: 0.4758\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.5032 - mean_absolute_error: 0.5306\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 0.4122 - mean_absolute_error: 0.4941\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.4348 - mean_absolute_error: 0.5056\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.4421 - mean_absolute_error: 0.4933\n",
      " 7/20 [=========>....................] - ETA: 0s - loss: 0.4196 - mean_absolute_error: 0.4993Epoch 5/20\n",
      "20/20 [==============================] - 1s 70ms/step - loss: 0.3655 - mean_absolute_error: 0.4572\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.3964 - mean_absolute_error: 0.4829\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.4358 - mean_absolute_error: 0.4975\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 1s 69ms/step - loss: 0.4119 - mean_absolute_error: 0.4809\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 2s 91ms/step - loss: 0.4008 - mean_absolute_error: 0.4887\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.3566 - mean_absolute_error: 0.4587\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.3346 - mean_absolute_error: 0.4344\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.4499 - mean_absolute_error: 0.5077\n",
      "12/20 [=================>............] - ETA: 0s - loss: 0.3589 - mean_absolute_error: 0.4653Epoch 6/20\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.3779 - mean_absolute_error: 0.4584\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.3502 - mean_absolute_error: 0.4584\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.3769 - mean_absolute_error: 0.4742\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.3819 - mean_absolute_error: 0.4822\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 1s 64ms/step - loss: 0.3490 - mean_absolute_error: 0.4419\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 0.3836 - mean_absolute_error: 0.4629\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.3204 - mean_absolute_error: 0.4353\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.3447 - mean_absolute_error: 0.4474\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.3383 - mean_absolute_error: 0.4472\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.3556 - mean_absolute_error: 0.4525\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.3214 - mean_absolute_error: 0.4404\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.3762 - mean_absolute_error: 0.4595\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.3008 - mean_absolute_error: 0.4166\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.3344 - mean_absolute_error: 0.4319\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.2940 - mean_absolute_error: 0.4197\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 0.3388 - mean_absolute_error: 0.4421\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.3477 - mean_absolute_error: 0.4398\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.2812 - mean_absolute_error: 0.4110\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 1s 66ms/step - loss: 0.3183 - mean_absolute_error: 0.4242\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.2855 - mean_absolute_error: 0.4107\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.3566 - mean_absolute_error: 0.4695\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.3413 - mean_absolute_error: 0.4440\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.2597 - mean_absolute_error: 0.3875\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.2762 - mean_absolute_error: 0.3924\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.3175 - mean_absolute_error: 0.4231\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.3434 - mean_absolute_error: 0.4576\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.2493 - mean_absolute_error: 0.3796\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 2s 92ms/step - loss: 0.3225 - mean_absolute_error: 0.4277\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.2577 - mean_absolute_error: 0.3817\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.3146 - mean_absolute_error: 0.4244\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 1s 69ms/step - loss: 0.2599 - mean_absolute_error: 0.3921\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.3052 - mean_absolute_error: 0.4226\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.2642 - mean_absolute_error: 0.3973\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.2838 - mean_absolute_error: 0.3944\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.3727 - mean_absolute_error: 0.4764\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.2454 - mean_absolute_error: 0.3773\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.2588 - mean_absolute_error: 0.3840\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.2818 - mean_absolute_error: 0.4011\n",
      "17/20 [========================>.....] - ETA: 0s - loss: 0.3128 - mean_absolute_error: 0.4353Epoch 15/20\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.3055 - mean_absolute_error: 0.4308\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.3434 - mean_absolute_error: 0.4520\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.2302 - mean_absolute_error: 0.3682\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.2602 - mean_absolute_error: 0.3853\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.2781 - mean_absolute_error: 0.3995\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 1s 70ms/step - loss: 0.2178 - mean_absolute_error: 0.3577\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 2s 91ms/step - loss: 0.2987 - mean_absolute_error: 0.4088\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.2841 - mean_absolute_error: 0.4070\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.2502 - mean_absolute_error: 0.3809\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.2995 - mean_absolute_error: 0.4195\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.2347 - mean_absolute_error: 0.3678\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 2s 88ms/step - loss: 0.3151 - mean_absolute_error: 0.4314\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.2792 - mean_absolute_error: 0.4022\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.2489 - mean_absolute_error: 0.3833\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.2692 - mean_absolute_error: 0.3910\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.2205 - mean_absolute_error: 0.3558\n",
      " 4/20 [=====>........................] - ETA: 1s - loss: 0.3043 - mean_absolute_error: 0.4392Epoch 20/20\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.3017 - mean_absolute_error: 0.4188\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.2573 - mean_absolute_error: 0.3846\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.2656 - mean_absolute_error: 0.3971\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.2644 - mean_absolute_error: 0.3933\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.2184 - mean_absolute_error: 0.3599\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.3035 - mean_absolute_error: 0.4221\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.2539 - mean_absolute_error: 0.3852\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.2511 - mean_absolute_error: 0.3731\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.2856 - mean_absolute_error: 0.4189\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.2787 - mean_absolute_error: 0.4005\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.2224 - mean_absolute_error: 0.3538\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.2416 - mean_absolute_error: 0.3670\n",
      "5/5 [==============================] - 3s 24ms/steploss: 0.2528 - mean_absolute_error: 0.3834\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.2494 - mean_absolute_error: 0.3807\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.2647 - mean_absolute_error: 0.3891\n",
      " 5/20 [======>.......................] - ETA: 1s - loss: 0.2410 - mean_absolute_error: 0.3804Epoch 19/20\n",
      "5/5 [==============================] - 2s 32ms/steploss: 0.2702 - mean_absolute_error: 0.406\n",
      "5/5 [==============================] - 2s 34ms/step\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.2679 - mean_absolute_error: 0.4016\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 1s 69ms/step - loss: 0.2674 - mean_absolute_error: 0.3881\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 1s 65ms/step - loss: 0.3385 - mean_absolute_error: 0.4494\n",
      "20/20 [==============================] - 2s 88ms/step - loss: 0.2508 - mean_absolute_error: 0.3849\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 1s 71ms/step - loss: 0.2390 - mean_absolute_error: 0.3718\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 2s 34ms/steploss: 0.2287 - mean_absolute_error: 0.3737\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.2380 - mean_absolute_error: 0.3675\n",
      "5/5 [==============================] - 2s 25ms/step\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 17:45:07.290766: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 17:45:07.314804: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 17:45:07.315102: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 17:45:07.322494: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/10 [=====>........................] - ETA: 8s - loss: 1.0668 - mean_absolute_error: 0.8922  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/10 [===========>..................] - ETA: 6s - loss: 1.0377 - mean_absolute_error: 0.8646Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 20s 1s/step - loss: 1.0069 - mean_absolute_error: 0.8436\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.7828 - mean_absolute_error: 0.6876\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 29s 2s/step - loss: 0.9595 - mean_absolute_error: 0.8205\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 29s 2s/step - loss: 0.9942 - mean_absolute_error: 0.8484\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 29s 2s/step - loss: 1.0601 - mean_absolute_error: 0.8710\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 29s 2s/step - loss: 1.0201 - mean_absolute_error: 0.8562\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.7578 - mean_absolute_error: 0.6799\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.7243 - mean_absolute_error: 0.6644\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.6766 - mean_absolute_error: 0.6355\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.7654 - mean_absolute_error: 0.6876\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.8045 - mean_absolute_error: 0.7098\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.5851 - mean_absolute_error: 0.5935\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.5993 - mean_absolute_error: 0.6100\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.6160 - mean_absolute_error: 0.6192\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.5572 - mean_absolute_error: 0.5722\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.6864 - mean_absolute_error: 0.6463\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.4704 - mean_absolute_error: 0.5214\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.4943 - mean_absolute_error: 0.5465\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.4939 - mean_absolute_error: 0.5502\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.4894 - mean_absolute_error: 0.5271\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.5573 - mean_absolute_error: 0.5749\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.4408 - mean_absolute_error: 0.5194\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.4331 - mean_absolute_error: 0.4922\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.4943 - mean_absolute_error: 0.5296\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.4466 - mean_absolute_error: 0.5151\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.4517 - mean_absolute_error: 0.4999\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.4175 - mean_absolute_error: 0.5013\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.4724 - mean_absolute_error: 0.5207\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.4140 - mean_absolute_error: 0.4813\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.4061 - mean_absolute_error: 0.4838\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.4064 - mean_absolute_error: 0.4860\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.3955 - mean_absolute_error: 0.4877\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.4494 - mean_absolute_error: 0.5072\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.3923 - mean_absolute_error: 0.4675\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.3915 - mean_absolute_error: 0.4746\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.3925 - mean_absolute_error: 0.4820\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.3902 - mean_absolute_error: 0.4869\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.3846 - mean_absolute_error: 0.4705\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.4262 - mean_absolute_error: 0.4888\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.4049 - mean_absolute_error: 0.4864\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.3729 - mean_absolute_error: 0.4663\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.3738 - mean_absolute_error: 0.4718\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.3718 - mean_absolute_error: 0.4591\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.4186 - mean_absolute_error: 0.4824\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.3565 - mean_absolute_error: 0.4501\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3561 - mean_absolute_error: 0.4569\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.3562 - mean_absolute_error: 0.4538\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3624 - mean_absolute_error: 0.4641\n",
      "Epoch 12/100\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.4044 - mean_absolute_error: 0.4767\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.3503 - mean_absolute_error: 0.4512\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.3745 - mean_absolute_error: 0.4821\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.3434 - mean_absolute_error: 0.4411\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.3451 - mean_absolute_error: 0.4521\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3817 - mean_absolute_error: 0.4597\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3750 - mean_absolute_error: 0.4759\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.4120 - mean_absolute_error: 0.4990\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.3376 - mean_absolute_error: 0.4323\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.3472 - mean_absolute_error: 0.4553\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3730 - mean_absolute_error: 0.4606\n",
      " 8/10 [=======================>......] - ETA: 4s - loss: 0.4089 - mean_absolute_error: 0.4967Epoch 13/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.3548 - mean_absolute_error: 0.4558\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3852 - mean_absolute_error: 0.4868\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.3404 - mean_absolute_error: 0.4374\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.3519 - mean_absolute_error: 0.4698\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3725 - mean_absolute_error: 0.4547\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.3438 - mean_absolute_error: 0.4444\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.3180 - mean_absolute_error: 0.4212\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3578 - mean_absolute_error: 0.4644\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.3629 - mean_absolute_error: 0.4711\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.3183 - mean_absolute_error: 0.4303\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.3754 - mean_absolute_error: 0.4722\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.3544 - mean_absolute_error: 0.4602\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3356 - mean_absolute_error: 0.4431\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.3435 - mean_absolute_error: 0.4451\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.3416 - mean_absolute_error: 0.4582\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.3529 - mean_absolute_error: 0.4434\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.3423 - mean_absolute_error: 0.4513\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.3401 - mean_absolute_error: 0.4480\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.3206 - mean_absolute_error: 0.4249\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.3154 - mean_absolute_error: 0.4374\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.3401 - mean_absolute_error: 0.4404\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.3295 - mean_absolute_error: 0.4433\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.3040 - mean_absolute_error: 0.4126\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.3109 - mean_absolute_error: 0.4208\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.3288 - mean_absolute_error: 0.4295\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.3013 - mean_absolute_error: 0.4280\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3142 - mean_absolute_error: 0.4282\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2997 - mean_absolute_error: 0.4185\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.2965 - mean_absolute_error: 0.4129\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2811 - mean_absolute_error: 0.3953\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.3277 - mean_absolute_error: 0.4303\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.3067 - mean_absolute_error: 0.4301\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2994 - mean_absolute_error: 0.4206\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.2946 - mean_absolute_error: 0.4122\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2970 - mean_absolute_error: 0.4150\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.3000 - mean_absolute_error: 0.4204\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2930 - mean_absolute_error: 0.4159\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.3208 - mean_absolute_error: 0.4243\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2708 - mean_absolute_error: 0.3866\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.2981 - mean_absolute_error: 0.4104\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2907 - mean_absolute_error: 0.4177\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2947 - mean_absolute_error: 0.4142\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3150 - mean_absolute_error: 0.4253\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2650 - mean_absolute_error: 0.3811\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.2937 - mean_absolute_error: 0.4098\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2838 - mean_absolute_error: 0.4086\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2835 - mean_absolute_error: 0.4090\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3131 - mean_absolute_error: 0.4215\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.2606 - mean_absolute_error: 0.3797\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2757 - mean_absolute_error: 0.4049\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2768 - mean_absolute_error: 0.3969\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2600 - mean_absolute_error: 0.3783\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2985 - mean_absolute_error: 0.4293\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3274 - mean_absolute_error: 0.4415\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2617 - mean_absolute_error: 0.3869\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2726 - mean_absolute_error: 0.4036\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2950 - mean_absolute_error: 0.4242\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.3124 - mean_absolute_error: 0.4229\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.2789 - mean_absolute_error: 0.3945\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2677 - mean_absolute_error: 0.3960\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2895 - mean_absolute_error: 0.4214\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2733 - mean_absolute_error: 0.4037\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2878 - mean_absolute_error: 0.3982\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2763 - mean_absolute_error: 0.3958\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2577 - mean_absolute_error: 0.3783\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2719 - mean_absolute_error: 0.4018\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2789 - mean_absolute_error: 0.4115\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2871 - mean_absolute_error: 0.3973\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2629 - mean_absolute_error: 0.3820\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2490 - mean_absolute_error: 0.3746\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2642 - mean_absolute_error: 0.3906\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2694 - mean_absolute_error: 0.4041\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2926 - mean_absolute_error: 0.4050\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2725 - mean_absolute_error: 0.3982\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2607 - mean_absolute_error: 0.3892\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2610 - mean_absolute_error: 0.3899\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2601 - mean_absolute_error: 0.3901\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2825 - mean_absolute_error: 0.3991\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2718 - mean_absolute_error: 0.3911\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2620 - mean_absolute_error: 0.3828\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2568 - mean_absolute_error: 0.3906\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2599 - mean_absolute_error: 0.3897\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2500 - mean_absolute_error: 0.3729\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2832 - mean_absolute_error: 0.3969\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2603 - mean_absolute_error: 0.3878\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2534 - mean_absolute_error: 0.3867\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2401 - mean_absolute_error: 0.3621\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2808 - mean_absolute_error: 0.3997\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2645 - mean_absolute_error: 0.4000\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2478 - mean_absolute_error: 0.3698\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2606 - mean_absolute_error: 0.3938\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2439 - mean_absolute_error: 0.3676\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2675 - mean_absolute_error: 0.3854\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2534 - mean_absolute_error: 0.3874\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2459 - mean_absolute_error: 0.3700\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2433 - mean_absolute_error: 0.3688\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2515 - mean_absolute_error: 0.3831\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2485 - mean_absolute_error: 0.3792\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2650 - mean_absolute_error: 0.3846\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2393 - mean_absolute_error: 0.3621\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2329 - mean_absolute_error: 0.3558\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2534 - mean_absolute_error: 0.3824\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2542 - mean_absolute_error: 0.3897\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2809 - mean_absolute_error: 0.4035\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2319 - mean_absolute_error: 0.3578\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2303 - mean_absolute_error: 0.3531\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2441 - mean_absolute_error: 0.3765\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2505 - mean_absolute_error: 0.3858\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2728 - mean_absolute_error: 0.3932\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2319 - mean_absolute_error: 0.3541\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2312 - mean_absolute_error: 0.3597\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2471 - mean_absolute_error: 0.3837\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2552 - mean_absolute_error: 0.3884\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2698 - mean_absolute_error: 0.3899\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2373 - mean_absolute_error: 0.3634\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2613 - mean_absolute_error: 0.3916\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2665 - mean_absolute_error: 0.3989\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2500 - mean_absolute_error: 0.3837\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2856 - mean_absolute_error: 0.4075\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2360 - mean_absolute_error: 0.3670\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2495 - mean_absolute_error: 0.3777\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2492 - mean_absolute_error: 0.3844\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2818 - mean_absolute_error: 0.4111\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2607 - mean_absolute_error: 0.3981\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2336 - mean_absolute_error: 0.3631\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2408 - mean_absolute_error: 0.3699\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2790 - mean_absolute_error: 0.4002\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2439 - mean_absolute_error: 0.3780\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2629 - mean_absolute_error: 0.4015\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2359 - mean_absolute_error: 0.3629\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2219 - mean_absolute_error: 0.3495\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2719 - mean_absolute_error: 0.3875\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2447 - mean_absolute_error: 0.3772\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2448 - mean_absolute_error: 0.3814\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2341 - mean_absolute_error: 0.3602\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2278 - mean_absolute_error: 0.3557\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2711 - mean_absolute_error: 0.3969\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2483 - mean_absolute_error: 0.3803\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2273 - mean_absolute_error: 0.3540\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2570 - mean_absolute_error: 0.3851\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2276 - mean_absolute_error: 0.3569\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2578 - mean_absolute_error: 0.3797\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2319 - mean_absolute_error: 0.3546\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2364 - mean_absolute_error: 0.3735\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2240 - mean_absolute_error: 0.3531\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2361 - mean_absolute_error: 0.3696\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2596 - mean_absolute_error: 0.3846\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2242 - mean_absolute_error: 0.3529\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2321 - mean_absolute_error: 0.3642\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2301 - mean_absolute_error: 0.3639\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2328 - mean_absolute_error: 0.3674\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2509 - mean_absolute_error: 0.3755\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2269 - mean_absolute_error: 0.3540\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2539 - mean_absolute_error: 0.3816\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2332 - mean_absolute_error: 0.3679\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2364 - mean_absolute_error: 0.3750\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2340 - mean_absolute_error: 0.3627\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2553 - mean_absolute_error: 0.3779\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2672 - mean_absolute_error: 0.3953\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2344 - mean_absolute_error: 0.3678\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2444 - mean_absolute_error: 0.3816\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2346 - mean_absolute_error: 0.3660\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2943 - mean_absolute_error: 0.4150\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2362 - mean_absolute_error: 0.3672\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2317 - mean_absolute_error: 0.3672\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2197 - mean_absolute_error: 0.3456\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2340 - mean_absolute_error: 0.3696\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2576 - mean_absolute_error: 0.3832\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2209 - mean_absolute_error: 0.3563\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2231 - mean_absolute_error: 0.3572\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2191 - mean_absolute_error: 0.3440\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2279 - mean_absolute_error: 0.3643\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2517 - mean_absolute_error: 0.3725\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2156 - mean_absolute_error: 0.3445\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2270 - mean_absolute_error: 0.3623\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2153 - mean_absolute_error: 0.3432\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2337 - mean_absolute_error: 0.3704\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2388 - mean_absolute_error: 0.3662\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2086 - mean_absolute_error: 0.3412\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2134 - mean_absolute_error: 0.3420\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2322 - mean_absolute_error: 0.3674\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2376 - mean_absolute_error: 0.3635\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2370 - mean_absolute_error: 0.3772\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2148 - mean_absolute_error: 0.3453\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2150 - mean_absolute_error: 0.3428\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2304 - mean_absolute_error: 0.3693\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2406 - mean_absolute_error: 0.3651\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2277 - mean_absolute_error: 0.3672\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2040 - mean_absolute_error: 0.3361\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2167 - mean_absolute_error: 0.3446\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2337 - mean_absolute_error: 0.3664\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2372 - mean_absolute_error: 0.3664\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2285 - mean_absolute_error: 0.3709\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2190 - mean_absolute_error: 0.3503\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2079 - mean_absolute_error: 0.3352\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2324 - mean_absolute_error: 0.3598\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2226 - mean_absolute_error: 0.3585\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2260 - mean_absolute_error: 0.3638\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2115 - mean_absolute_error: 0.3424\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2089 - mean_absolute_error: 0.3382\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2319 - mean_absolute_error: 0.3628\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2194 - mean_absolute_error: 0.3528\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2359 - mean_absolute_error: 0.3748\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2074 - mean_absolute_error: 0.3419\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2063 - mean_absolute_error: 0.3337\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2485 - mean_absolute_error: 0.3756\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2202 - mean_absolute_error: 0.3534\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2329 - mean_absolute_error: 0.3690\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2003 - mean_absolute_error: 0.3318\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2130 - mean_absolute_error: 0.3401\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2550 - mean_absolute_error: 0.3841\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2162 - mean_absolute_error: 0.3513\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2197 - mean_absolute_error: 0.3569\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1988 - mean_absolute_error: 0.3307\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2068 - mean_absolute_error: 0.3361\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2287 - mean_absolute_error: 0.3565\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2281 - mean_absolute_error: 0.3653\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2221 - mean_absolute_error: 0.3632\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2076 - mean_absolute_error: 0.3353\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2159 - mean_absolute_error: 0.3539\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2259 - mean_absolute_error: 0.3542\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2034 - mean_absolute_error: 0.3301\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2315 - mean_absolute_error: 0.3656\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2194 - mean_absolute_error: 0.3592\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2182 - mean_absolute_error: 0.3530\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2272 - mean_absolute_error: 0.3536\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2047 - mean_absolute_error: 0.3333\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2212 - mean_absolute_error: 0.3611\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2217 - mean_absolute_error: 0.3553\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2005 - mean_absolute_error: 0.3288\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2403 - mean_absolute_error: 0.3686\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2063 - mean_absolute_error: 0.3362\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2138 - mean_absolute_error: 0.3502\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.1965 - mean_absolute_error: 0.3254\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2199 - mean_absolute_error: 0.3565\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2397 - mean_absolute_error: 0.3675\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2029 - mean_absolute_error: 0.3296\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2134 - mean_absolute_error: 0.3535\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.1971 - mean_absolute_error: 0.3309\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2168 - mean_absolute_error: 0.3489\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2323 - mean_absolute_error: 0.3608\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2102 - mean_absolute_error: 0.3395\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2159 - mean_absolute_error: 0.3533\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1989 - mean_absolute_error: 0.3284\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2165 - mean_absolute_error: 0.3505\n",
      " 8/10 [=======================>......] - ETA: 3s - loss: 0.2103 - mean_absolute_error: 0.3407Epoch 60/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2236 - mean_absolute_error: 0.3507\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2054 - mean_absolute_error: 0.3345\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2022 - mean_absolute_error: 0.3343\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2110 - mean_absolute_error: 0.3471\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2047 - mean_absolute_error: 0.3351\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2180 - mean_absolute_error: 0.3524\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2272 - mean_absolute_error: 0.3544\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1963 - mean_absolute_error: 0.3312\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2110 - mean_absolute_error: 0.3517\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2021 - mean_absolute_error: 0.3274\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2136 - mean_absolute_error: 0.3458\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2272 - mean_absolute_error: 0.3535\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.1938 - mean_absolute_error: 0.3259\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2113 - mean_absolute_error: 0.3470\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1973 - mean_absolute_error: 0.3246\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2175 - mean_absolute_error: 0.3522\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2411 - mean_absolute_error: 0.3743\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.1944 - mean_absolute_error: 0.3279\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2087 - mean_absolute_error: 0.3467\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2033 - mean_absolute_error: 0.3363\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2143 - mean_absolute_error: 0.3480\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2266 - mean_absolute_error: 0.3512\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.1986 - mean_absolute_error: 0.3332\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2068 - mean_absolute_error: 0.3472\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2019 - mean_absolute_error: 0.3352\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2104 - mean_absolute_error: 0.3437\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2241 - mean_absolute_error: 0.3530\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2068 - mean_absolute_error: 0.3472\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2034 - mean_absolute_error: 0.3362\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2188 - mean_absolute_error: 0.3509\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2187 - mean_absolute_error: 0.3508\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2311 - mean_absolute_error: 0.3595\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2008 - mean_absolute_error: 0.3415\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.1956 - mean_absolute_error: 0.3291\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2288 - mean_absolute_error: 0.3640\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2093 - mean_absolute_error: 0.3449\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2326 - mean_absolute_error: 0.3663\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2134 - mean_absolute_error: 0.3480\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2170 - mean_absolute_error: 0.3503\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2016 - mean_absolute_error: 0.3324\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.1928 - mean_absolute_error: 0.3258\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2316 - mean_absolute_error: 0.3567\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2023 - mean_absolute_error: 0.3409\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2131 - mean_absolute_error: 0.3446\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2123 - mean_absolute_error: 0.3474\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.1962 - mean_absolute_error: 0.3323\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2246 - mean_absolute_error: 0.3569\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2096 - mean_absolute_error: 0.3474\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.1967 - mean_absolute_error: 0.3262\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2210 - mean_absolute_error: 0.3560\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1906 - mean_absolute_error: 0.3230\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2095 - mean_absolute_error: 0.3464\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2282 - mean_absolute_error: 0.3595\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1918 - mean_absolute_error: 0.3192\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2148 - mean_absolute_error: 0.3534\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.1912 - mean_absolute_error: 0.3244\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2065 - mean_absolute_error: 0.3473\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2231 - mean_absolute_error: 0.3529\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.1929 - mean_absolute_error: 0.3220\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2186 - mean_absolute_error: 0.3488\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.1875 - mean_absolute_error: 0.3181\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2112 - mean_absolute_error: 0.3514\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2179 - mean_absolute_error: 0.3502\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1989 - mean_absolute_error: 0.3276\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2286 - mean_absolute_error: 0.3617\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2032 - mean_absolute_error: 0.3412\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2203 - mean_absolute_error: 0.3513\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2001 - mean_absolute_error: 0.3374\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1935 - mean_absolute_error: 0.3223\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2321 - mean_absolute_error: 0.3665\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2103 - mean_absolute_error: 0.3473\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2252 - mean_absolute_error: 0.3511\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.1906 - mean_absolute_error: 0.3227\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1881 - mean_absolute_error: 0.3209\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2051 - mean_absolute_error: 0.3404\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2136 - mean_absolute_error: 0.3535\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2204 - mean_absolute_error: 0.3531\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2066 - mean_absolute_error: 0.3318\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.1889 - mean_absolute_error: 0.3215\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2243 - mean_absolute_error: 0.3609\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2129 - mean_absolute_error: 0.3547\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2288 - mean_absolute_error: 0.3570\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2276 - mean_absolute_error: 0.3636\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.1877 - mean_absolute_error: 0.3239\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2114 - mean_absolute_error: 0.3411\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2059 - mean_absolute_error: 0.3313\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2168 - mean_absolute_error: 0.3431\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2134 - mean_absolute_error: 0.3546\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.1898 - mean_absolute_error: 0.3239\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1943 - mean_absolute_error: 0.3218\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2123 - mean_absolute_error: 0.3416\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2206 - mean_absolute_error: 0.3570\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2131 - mean_absolute_error: 0.3516\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2054 - mean_absolute_error: 0.3467\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1917 - mean_absolute_error: 0.3202\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2154 - mean_absolute_error: 0.3429\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2195 - mean_absolute_error: 0.3576\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2147 - mean_absolute_error: 0.3530\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2010 - mean_absolute_error: 0.3389\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1908 - mean_absolute_error: 0.3245\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2128 - mean_absolute_error: 0.3424\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2175 - mean_absolute_error: 0.3510\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2015 - mean_absolute_error: 0.3360\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.1952 - mean_absolute_error: 0.3272\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2118 - mean_absolute_error: 0.3445\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2190 - mean_absolute_error: 0.3483\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2082 - mean_absolute_error: 0.3406\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2112 - mean_absolute_error: 0.3516\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.1957 - mean_absolute_error: 0.3311\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2090 - mean_absolute_error: 0.3411\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2146 - mean_absolute_error: 0.3418\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2052 - mean_absolute_error: 0.3367\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2057 - mean_absolute_error: 0.3345\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1893 - mean_absolute_error: 0.3260\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.1982 - mean_absolute_error: 0.3376\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2126 - mean_absolute_error: 0.3410\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2037 - mean_absolute_error: 0.3379\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.1994 - mean_absolute_error: 0.3307\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1898 - mean_absolute_error: 0.3225\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.2118 - mean_absolute_error: 0.3503\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2233 - mean_absolute_error: 0.3542\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2130 - mean_absolute_error: 0.3494\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1874 - mean_absolute_error: 0.3204\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2256 - mean_absolute_error: 0.3646\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2110 - mean_absolute_error: 0.3429\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.1831 - mean_absolute_error: 0.3144\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2074 - mean_absolute_error: 0.3451\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1942 - mean_absolute_error: 0.3256\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2103 - mean_absolute_error: 0.3491\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2140 - mean_absolute_error: 0.3421\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.1878 - mean_absolute_error: 0.3224\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2017 - mean_absolute_error: 0.3354\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2042 - mean_absolute_error: 0.3315\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2064 - mean_absolute_error: 0.3503\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2167 - mean_absolute_error: 0.3475\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1829 - mean_absolute_error: 0.3159\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2099 - mean_absolute_error: 0.3500\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1903 - mean_absolute_error: 0.3211\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2133 - mean_absolute_error: 0.3543\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2218 - mean_absolute_error: 0.3486\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1910 - mean_absolute_error: 0.3244\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2077 - mean_absolute_error: 0.3468\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.1994 - mean_absolute_error: 0.3317\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1956 - mean_absolute_error: 0.3311\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2157 - mean_absolute_error: 0.3485\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1881 - mean_absolute_error: 0.3232\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2009 - mean_absolute_error: 0.3329\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1912 - mean_absolute_error: 0.3219\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2016 - mean_absolute_error: 0.3394\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2144 - mean_absolute_error: 0.3442\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1962 - mean_absolute_error: 0.3263\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2004 - mean_absolute_error: 0.3339\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1836 - mean_absolute_error: 0.3133\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2082 - mean_absolute_error: 0.3434\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 6s 878ms/steposs: 0.2053 - mean_absolute_error: 0.33\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2091 - mean_absolute_error: 0.3389\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.1932 - mean_absolute_error: 0.3289\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2050 - mean_absolute_error: 0.3386\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2044 - mean_absolute_error: 0.3448\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2122 - mean_absolute_error: 0.3361\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2047 - mean_absolute_error: 0.3372\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1865 - mean_absolute_error: 0.3160\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.1965 - mean_absolute_error: 0.3331\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2201 - mean_absolute_error: 0.3503\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2021 - mean_absolute_error: 0.3352\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1820 - mean_absolute_error: 0.3149\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.1987 - mean_absolute_error: 0.3399\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2110 - mean_absolute_error: 0.3379\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1960 - mean_absolute_error: 0.3290\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1845 - mean_absolute_error: 0.3224\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.1990 - mean_absolute_error: 0.3384\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.2082 - mean_absolute_error: 0.3415\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.1946 - mean_absolute_error: 0.3351\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1978 - mean_absolute_error: 0.3311\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1891 - mean_absolute_error: 0.3178\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2099 - mean_absolute_error: 0.3334\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.1950 - mean_absolute_error: 0.3306\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1822 - mean_absolute_error: 0.3167\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1991 - mean_absolute_error: 0.3351\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2170 - mean_absolute_error: 0.3471\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.1972 - mean_absolute_error: 0.3343\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1849 - mean_absolute_error: 0.3209\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2010 - mean_absolute_error: 0.3365\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.1925 - mean_absolute_error: 0.3298\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2064 - mean_absolute_error: 0.3421\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2036 - mean_absolute_error: 0.3353\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.1887 - mean_absolute_error: 0.3257\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.1924 - mean_absolute_error: 0.3268\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2083 - mean_absolute_error: 0.3391\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2025 - mean_absolute_error: 0.3379\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 6s 753ms/steploss: 0.2030 - mean_absolute_error: 0.33\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1838 - mean_absolute_error: 0.3216\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.1964 - mean_absolute_error: 0.3335\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.2053 - mean_absolute_error: 0.3394\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 5s 778ms/step\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.1817 - mean_absolute_error: 0.3157\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.2026 - mean_absolute_error: 0.3374\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1869 - mean_absolute_error: 0.3185\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 3s 550ms/steploss: 0.1685 - mean_absolute_error: 0.\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.1893 - mean_absolute_error: 0.3210\n",
      "3/3 [==============================] - 3s 461ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [32, 100, 0.0001, 'sgd', 512] before, using random point [32, 50, 0.001, 'sgd', 128]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      " 6/20 [========>.....................] - ETA: 2s - loss: 0.8587 - mean_absolute_error: 0.7738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 18:24:34.460541: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 13s 164ms/step - loss: 0.6920 - mean_absolute_error: 0.6505\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 13s 153ms/step - loss: 0.7058 - mean_absolute_error: 0.6691\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 13s 193ms/step - loss: 0.6987 - mean_absolute_error: 0.6575\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 14s 232ms/step - loss: 0.7409 - mean_absolute_error: 0.6800\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 3s 165ms/step - loss: 0.4623 - mean_absolute_error: 0.5211\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 3s 162ms/step - loss: 0.4579 - mean_absolute_error: 0.5166\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 0.4610 - mean_absolute_error: 0.5197\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.4314 - mean_absolute_error: 0.5036\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 3s 160ms/step - loss: 0.4055 - mean_absolute_error: 0.4843\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 5s 259ms/step - loss: 0.5778 - mean_absolute_error: 0.5837\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 4s 180ms/step - loss: 0.4077 - mean_absolute_error: 0.4945\n",
      "Epoch 4/50\n",
      "12/20 [=================>............] - ETA: 1s - loss: 0.3279 - mean_absolute_error: 0.4442Epoch 1/50\n",
      "20/20 [==============================] - 3s 141ms/step - loss: 0.3862 - mean_absolute_error: 0.4729\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 3s 156ms/step - loss: 0.3649 - mean_absolute_error: 0.4615\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 3s 144ms/step - loss: 0.3778 - mean_absolute_error: 0.4687\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 5s 247ms/step - loss: 0.5013 - mean_absolute_error: 0.5263\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 4s 181ms/step - loss: 0.3929 - mean_absolute_error: 0.4896\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 3s 145ms/step - loss: 0.3474 - mean_absolute_error: 0.4515\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 3s 155ms/step - loss: 0.3439 - mean_absolute_error: 0.4479\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 3s 156ms/step - loss: 0.3661 - mean_absolute_error: 0.4679\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 3s 132ms/step - loss: 0.3577 - mean_absolute_error: 0.4650\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 5s 247ms/step - loss: 0.4437 - mean_absolute_error: 0.5041\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 3s 133ms/step - loss: 0.3164 - mean_absolute_error: 0.4245\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 3s 141ms/step - loss: 0.3346 - mean_absolute_error: 0.4529\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.3245 - mean_absolute_error: 0.4442\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 4s 186ms/step - loss: 0.4440 - mean_absolute_error: 0.5052\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 3s 138ms/step - loss: 0.3035 - mean_absolute_error: 0.4237\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 3s 158ms/step - loss: 0.3179 - mean_absolute_error: 0.4333\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 3s 148ms/step - loss: 0.3111 - mean_absolute_error: 0.4302\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 3s 158ms/step - loss: 0.2884 - mean_absolute_error: 0.4123\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 15s 77ms/step - loss: 0.7204 - mean_absolute_error: 0.6534\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 3s 164ms/step - loss: 0.2945 - mean_absolute_error: 0.4119\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.3236 - mean_absolute_error: 0.4408\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 5s 239ms/step - loss: 0.3833 - mean_absolute_error: 0.4701\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.4965 - mean_absolute_error: 0.5294\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 3s 157ms/step - loss: 0.3052 - mean_absolute_error: 0.4321\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 2s 88ms/step - loss: 0.4940 - mean_absolute_error: 0.5430\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 4s 182ms/step - loss: 0.2658 - mean_absolute_error: 0.3851\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 4s 203ms/step - loss: 0.2852 - mean_absolute_error: 0.4205\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 2s 100ms/step - loss: 0.4617 - mean_absolute_error: 0.5230\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 3s 143ms/step - loss: 0.3690 - mean_absolute_error: 0.4831\n",
      " 6/20 [========>.....................] - ETA: 1s - loss: 0.4267 - mean_absolute_error: 0.4961Epoch 12/50\n",
      "20/20 [==============================] - 5s 243ms/step - loss: 0.3291 - mean_absolute_error: 0.4363\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.3869 - mean_absolute_error: 0.4681\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.3514 - mean_absolute_error: 0.4654\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 0.3387 - mean_absolute_error: 0.4505\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 4s 205ms/step - loss: 0.2774 - mean_absolute_error: 0.4056\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 2s 98ms/step - loss: 0.3721 - mean_absolute_error: 0.4648\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 3s 132ms/step - loss: 0.2800 - mean_absolute_error: 0.4085\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 0.2914 - mean_absolute_error: 0.4056\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 5s 254ms/step - loss: 0.3229 - mean_absolute_error: 0.4327\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.3747 - mean_absolute_error: 0.4642\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 2s 116ms/step - loss: 0.2682 - mean_absolute_error: 0.4011\n",
      "20/20 [==============================] - 4s 220ms/step - loss: 0.3474 - mean_absolute_error: 0.4595\n",
      "Epoch 15/50\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 2s 116ms/step - loss: 0.3306 - mean_absolute_error: 0.4300\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 4s 216ms/step - loss: 0.2589 - mean_absolute_error: 0.3878\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 2s 123ms/step - loss: 0.2539 - mean_absolute_error: 0.3848\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 5s 232ms/step - loss: 0.3616 - mean_absolute_error: 0.4596\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 3s 127ms/step - loss: 0.3260 - mean_absolute_error: 0.4373\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 4s 220ms/step - loss: 0.2936 - mean_absolute_error: 0.4163\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 3s 133ms/step - loss: 0.2317 - mean_absolute_error: 0.3681\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 3s 127ms/step - loss: 0.2975 - mean_absolute_error: 0.4122\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 4s 202ms/step - loss: 0.2521 - mean_absolute_error: 0.3768\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 4s 213ms/step - loss: 0.2969 - mean_absolute_error: 0.4051\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 3s 136ms/step - loss: 0.2316 - mean_absolute_error: 0.3674\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 3s 140ms/step - loss: 0.2840 - mean_absolute_error: 0.4001\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 4s 225ms/step - loss: 0.2771 - mean_absolute_error: 0.3998\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 4s 204ms/step - loss: 0.2551 - mean_absolute_error: 0.3858\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 3s 151ms/step - loss: 0.2397 - mean_absolute_error: 0.3734\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 3s 152ms/step - loss: 0.3417 - mean_absolute_error: 0.4524\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 5s 240ms/step - loss: 0.2664 - mean_absolute_error: 0.3800\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 4s 206ms/step - loss: 0.2492 - mean_absolute_error: 0.3790\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 3s 156ms/step - loss: 0.2392 - mean_absolute_error: 0.3711\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.2441 - mean_absolute_error: 0.3887\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 3s 146ms/step - loss: 0.3035 - mean_absolute_error: 0.4178\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 5s 227ms/step - loss: 0.2630 - mean_absolute_error: 0.3946\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.2297 - mean_absolute_error: 0.3660\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 3s 164ms/step - loss: 0.2581 - mean_absolute_error: 0.3886\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 4s 202ms/step - loss: 0.2474 - mean_absolute_error: 0.3752\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 3s 152ms/step - loss: 0.2591 - mean_absolute_error: 0.3851\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 3s 138ms/step - loss: 0.2277 - mean_absolute_error: 0.3552\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 3s 144ms/step - loss: 0.2209 - mean_absolute_error: 0.3590\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 3s 157ms/step - loss: 0.2612 - mean_absolute_error: 0.3807\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 5s 231ms/step - loss: 0.2574 - mean_absolute_error: 0.3787\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 4s 202ms/step - loss: 0.2368 - mean_absolute_error: 0.3656\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 3s 129ms/step - loss: 0.2337 - mean_absolute_error: 0.3638\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 3s 145ms/step - loss: 0.2193 - mean_absolute_error: 0.3589\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 3s 155ms/step - loss: 0.2546 - mean_absolute_error: 0.3868\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 3s 133ms/step - loss: 0.2304 - mean_absolute_error: 0.3627\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 4s 203ms/step - loss: 0.2677 - mean_absolute_error: 0.3757\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 4s 200ms/step - loss: 0.2296 - mean_absolute_error: 0.3637\n",
      " 1/20 [>.............................] - ETA: 2s - loss: 0.1071 - mean_absolute_error: 0.2500Epoch 18/50\n",
      "20/20 [==============================] - 3s 152ms/step - loss: 0.2322 - mean_absolute_error: 0.3715\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 3s 159ms/step - loss: 0.2764 - mean_absolute_error: 0.3983\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 3s 134ms/step - loss: 0.2049 - mean_absolute_error: 0.3364\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 4s 180ms/step - loss: 0.2340 - mean_absolute_error: 0.3672\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 4s 185ms/step - loss: 0.2573 - mean_absolute_error: 0.3787\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.2591 - mean_absolute_error: 0.3980\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 3s 137ms/step - loss: 0.2353 - mean_absolute_error: 0.3689\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 3s 174ms/step - loss: 0.3401 - mean_absolute_error: 0.4577\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.2492 - mean_absolute_error: 0.3860\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 4s 201ms/step - loss: 0.2410 - mean_absolute_error: 0.3744\n",
      " 4/20 [=====>........................] - ETA: 2s - loss: 0.2452 - mean_absolute_error: 0.3777Epoch 17/50\n",
      "20/20 [==============================] - 4s 173ms/step - loss: 0.2284 - mean_absolute_error: 0.3632\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 3s 144ms/step - loss: 0.2881 - mean_absolute_error: 0.4185\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 4s 186ms/step - loss: 0.3091 - mean_absolute_error: 0.4217\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.2357 - mean_absolute_error: 0.3684\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 3s 150ms/step - loss: 0.2133 - mean_absolute_error: 0.3435\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 4s 180ms/step - loss: 0.2363 - mean_absolute_error: 0.3671\n",
      " 1/20 [>.............................] - ETA: 3s - loss: 0.1328 - mean_absolute_error: 0.3004Epoch 18/50\n",
      "20/20 [==============================] - 4s 196ms/step - loss: 0.2386 - mean_absolute_error: 0.3782\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 0.2791 - mean_absolute_error: 0.3996\n",
      " 7/20 [=========>....................] - ETA: 2s - loss: 0.2074 - mean_absolute_error: 0.3405Epoch 21/50\n",
      "20/20 [==============================] - 4s 182ms/step - loss: 0.2855 - mean_absolute_error: 0.4113\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.2004 - mean_absolute_error: 0.3332\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.2240 - mean_absolute_error: 0.3480\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.2079 - mean_absolute_error: 0.3455\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 4s 196ms/step - loss: 0.2630 - mean_absolute_error: 0.3883\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 3s 141ms/step - loss: 0.2005 - mean_absolute_error: 0.3325\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.2669 - mean_absolute_error: 0.3990\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.2190 - mean_absolute_error: 0.3477\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.2042 - mean_absolute_error: 0.3485\n",
      " 5/20 [======>.......................] - ETA: 2s - loss: 0.2148 - mean_absolute_error: 0.3434Epoch 29/50\n",
      "20/20 [==============================] - 3s 154ms/step - loss: 0.2207 - mean_absolute_error: 0.3523\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 4s 215ms/step - loss: 0.2622 - mean_absolute_error: 0.3815\n",
      " 8/20 [===========>..................] - ETA: 1s - loss: 0.2186 - mean_absolute_error: 0.3508Epoch 23/50\n",
      "20/20 [==============================] - 3s 159ms/step - loss: 0.2219 - mean_absolute_error: 0.3571\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.2535 - mean_absolute_error: 0.3856\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 4s 176ms/step - loss: 0.2081 - mean_absolute_error: 0.3473\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 3s 147ms/step - loss: 0.2028 - mean_absolute_error: 0.3416\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 3s 154ms/step - loss: 0.2382 - mean_absolute_error: 0.3704\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 4s 216ms/step - loss: 0.2443 - mean_absolute_error: 0.3727\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 4s 180ms/step - loss: 0.2562 - mean_absolute_error: 0.3856\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 3s 159ms/step - loss: 0.1881 - mean_absolute_error: 0.3259\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 4s 213ms/step - loss: 0.2392 - mean_absolute_error: 0.3698\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 3s 156ms/step - loss: 0.2132 - mean_absolute_error: 0.3412\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 4s 180ms/step - loss: 0.2633 - mean_absolute_error: 0.3919\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.1943 - mean_absolute_error: 0.3318\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 4s 218ms/step - loss: 0.2438 - mean_absolute_error: 0.3718\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 4s 201ms/step - loss: 0.2480 - mean_absolute_error: 0.3767\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 3s 156ms/step - loss: 0.2248 - mean_absolute_error: 0.3595\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 4s 176ms/step - loss: 0.1942 - mean_absolute_error: 0.3322\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 4s 186ms/step - loss: 0.2274 - mean_absolute_error: 0.3637\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.2122 - mean_absolute_error: 0.3457\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 4s 187ms/step - loss: 0.2311 - mean_absolute_error: 0.3633\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 4s 224ms/step - loss: 0.2298 - mean_absolute_error: 0.3564\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.1873 - mean_absolute_error: 0.3250\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 0.2234 - mean_absolute_error: 0.3635\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 3s 172ms/step - loss: 0.2104 - mean_absolute_error: 0.3417\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 4s 201ms/step - loss: 0.2220 - mean_absolute_error: 0.3552\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 5s 235ms/step - loss: 0.2513 - mean_absolute_error: 0.3879\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 0.2137 - mean_absolute_error: 0.3573\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.2038 - mean_absolute_error: 0.3329\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 4s 185ms/step - loss: 0.2482 - mean_absolute_error: 0.3871\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 4s 209ms/step - loss: 0.2186 - mean_absolute_error: 0.3542\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 5s 230ms/step - loss: 0.2375 - mean_absolute_error: 0.3629\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 0.2171 - mean_absolute_error: 0.3516\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 0.2336 - mean_absolute_error: 0.3763\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 4s 212ms/step - loss: 0.2238 - mean_absolute_error: 0.3686\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 4s 209ms/step - loss: 0.2171 - mean_absolute_error: 0.3578\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 4s 202ms/step - loss: 0.1876 - mean_absolute_error: 0.3225\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 4s 209ms/step - loss: 0.2342 - mean_absolute_error: 0.3663\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 5s 259ms/step - loss: 0.2453 - mean_absolute_error: 0.3741\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 4s 209ms/step - loss: 0.2164 - mean_absolute_error: 0.3547\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 5s 235ms/step - loss: 0.2258 - mean_absolute_error: 0.3633\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 4s 208ms/step - loss: 0.1777 - mean_absolute_error: 0.3165\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 4s 225ms/step - loss: 0.2419 - mean_absolute_error: 0.3757\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.1991 - mean_absolute_error: 0.3356\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 5s 272ms/step - loss: 0.2376 - mean_absolute_error: 0.3670\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 5s 227ms/step - loss: 0.2246 - mean_absolute_error: 0.3591\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 4s 200ms/step - loss: 0.2028 - mean_absolute_error: 0.3489\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 4s 184ms/step - loss: 0.2028 - mean_absolute_error: 0.3476\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 5s 225ms/step - loss: 0.2293 - mean_absolute_error: 0.3623\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 5s 271ms/step - loss: 0.2216 - mean_absolute_error: 0.3581\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 4s 208ms/step - loss: 0.2156 - mean_absolute_error: 0.3551\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.2031 - mean_absolute_error: 0.3374\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 0.2038 - mean_absolute_error: 0.3450\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 5s 252ms/step - loss: 0.1990 - mean_absolute_error: 0.3303\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.1887 - mean_absolute_error: 0.3290\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 5s 238ms/step - loss: 0.2544 - mean_absolute_error: 0.3843\n",
      " 2/20 [==>...........................] - ETA: 3s - loss: 0.1347 - mean_absolute_error: 0.2953Epoch 34/50\n",
      "20/20 [==============================] - 5s 258ms/step - loss: 0.2187 - mean_absolute_error: 0.3526\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 4s 211ms/step - loss: 0.1829 - mean_absolute_error: 0.3271\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 0.1792 - mean_absolute_error: 0.3170\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 5s 269ms/step - loss: 0.2012 - mean_absolute_error: 0.3344\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 0.1951 - mean_absolute_error: 0.3330\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 5s 238ms/step - loss: 0.2197 - mean_absolute_error: 0.3546\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 6s 276ms/step - loss: 0.2334 - mean_absolute_error: 0.3576\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.1809 - mean_absolute_error: 0.3184\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 3s 163ms/step - loss: 0.1708 - mean_absolute_error: 0.3141\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 6s 285ms/step - loss: 0.1911 - mean_absolute_error: 0.3242\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 5s 253ms/step - loss: 0.2319 - mean_absolute_error: 0.3699\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.1677 - mean_absolute_error: 0.3108\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 3s 156ms/step - loss: 0.1809 - mean_absolute_error: 0.3266\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 6s 288ms/step - loss: 0.2031 - mean_absolute_error: 0.3369\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.1703 - mean_absolute_error: 0.3042\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 3s 153ms/step - loss: 0.2060 - mean_absolute_error: 0.3484\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 6s 288ms/step - loss: 0.2013 - mean_absolute_error: 0.3390\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 5s 270ms/step - loss: 0.2173 - mean_absolute_error: 0.3581\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.1771 - mean_absolute_error: 0.3145\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 3s 159ms/step - loss: 0.1781 - mean_absolute_error: 0.3334\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 6s 300ms/step - loss: 0.2122 - mean_absolute_error: 0.3429\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 3s 141ms/step - loss: 0.1662 - mean_absolute_error: 0.3100\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 3s 160ms/step - loss: 0.1831 - mean_absolute_error: 0.3245\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 5s 274ms/step - loss: 0.2078 - mean_absolute_error: 0.3445\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 6s 296ms/step - loss: 0.2085 - mean_absolute_error: 0.3437\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 3s 142ms/step - loss: 0.1661 - mean_absolute_error: 0.3163\n",
      "15/20 [=====================>........] - ETA: 0s - loss: 0.1854 - mean_absolute_error: 0.3281Epoch 48/50\n",
      "20/20 [==============================] - 3s 162ms/step - loss: 0.1803 - mean_absolute_error: 0.3243\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 6s 302ms/step - loss: 0.2456 - mean_absolute_error: 0.3754\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 5s 247ms/step - loss: 0.1957 - mean_absolute_error: 0.3327\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.1698 - mean_absolute_error: 0.3175\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 5s 275ms/step - loss: 0.2066 - mean_absolute_error: 0.3406\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 3s 167ms/step - loss: 0.1786 - mean_absolute_error: 0.3174\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.1677 - mean_absolute_error: 0.3127\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.1860 - mean_absolute_error: 0.3324\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 6s 324ms/step - loss: 0.2255 - mean_absolute_error: 0.3530\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 5s 230ms/step - loss: 0.2096 - mean_absolute_error: 0.3515\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 3s 154ms/step - loss: 0.1635 - mean_absolute_error: 0.3135\n",
      "20/20 [==============================] - 5s 274ms/step - loss: 0.1904 - mean_absolute_error: 0.3232\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 3s 158ms/step - loss: 0.1682 - mean_absolute_error: 0.3075\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 4s 224ms/step - loss: 0.1963 - mean_absolute_error: 0.3287\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 3s 90ms/steploss: 0.2446 - mean_absolute_error: 0.372\n",
      "20/20 [==============================] - 6s 312ms/step - loss: 0.2362 - mean_absolute_error: 0.3718\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 4s 174ms/step - loss: 0.1664 - mean_absolute_error: 0.3045\n",
      "20/20 [==============================] - 5s 259ms/step - loss: 0.1857 - mean_absolute_error: 0.3214\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 5s 228ms/step - loss: 0.2021 - mean_absolute_error: 0.3472\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 3s 118ms/steposs: 0.2793 - mean_absolute_error: 0.430\n",
      "20/20 [==============================] - 5s 237ms/step - loss: 0.1916 - mean_absolute_error: 0.3213\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.2361 - mean_absolute_error: 0.3682\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 4s 220ms/step - loss: 0.2235 - mean_absolute_error: 0.3674\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 4s 203ms/step - loss: 0.2160 - mean_absolute_error: 0.3475\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 4s 179ms/step - loss: 0.2093 - mean_absolute_error: 0.3493\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 6s 287ms/step - loss: 0.1990 - mean_absolute_error: 0.3353\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 4s 210ms/step - loss: 0.1853 - mean_absolute_error: 0.3216\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 3s 148ms/step - loss: 0.1919 - mean_absolute_error: 0.3274\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 3s 151ms/step - loss: 0.1837 - mean_absolute_error: 0.3200\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 4s 176ms/step - loss: 0.1726 - mean_absolute_error: 0.3066\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 6s 294ms/step - loss: 0.2180 - mean_absolute_error: 0.3506\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.2013 - mean_absolute_error: 0.3425\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.1691 - mean_absolute_error: 0.3053\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 3s 144ms/step - loss: 0.1866 - mean_absolute_error: 0.3285\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 3s 150ms/step - loss: 0.1559 - mean_absolute_error: 0.2949\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 6s 302ms/step - loss: 0.2381 - mean_absolute_error: 0.3688\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 3s 152ms/step - loss: 0.1749 - mean_absolute_error: 0.3097\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 3s 165ms/step - loss: 0.1634 - mean_absolute_error: 0.3022\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 3s 154ms/step - loss: 0.1733 - mean_absolute_error: 0.3119\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.2390 - mean_absolute_error: 0.3663\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.1647 - mean_absolute_error: 0.3060\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 2s 124ms/step - loss: 0.1808 - mean_absolute_error: 0.3247\n",
      "5/5 [==============================] - 2s 63ms/steploss: 0.2706 - mean_absolute_error: 0.39\n",
      "20/20 [==============================] - 3s 164ms/step - loss: 0.1735 - mean_absolute_error: 0.3082\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 6s 314ms/step - loss: 0.2214 - mean_absolute_error: 0.3543\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 4s 176ms/step - loss: 0.1597 - mean_absolute_error: 0.2971\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.1720 - mean_absolute_error: 0.3027\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 6s 316ms/step - loss: 0.2015 - mean_absolute_error: 0.3340\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 3s 164ms/step - loss: 0.1711 - mean_absolute_error: 0.3118\n",
      "5/5 [==============================] - 2s 92ms/steploss: 0.1881 - mean_absolute_error: 0.32\n",
      "20/20 [==============================] - 6s 321ms/step - loss: 0.1873 - mean_absolute_error: 0.3178\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 7s 339ms/step - loss: 0.1929 - mean_absolute_error: 0.3305\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 7s 361ms/step - loss: 0.1929 - mean_absolute_error: 0.3290\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 7s 338ms/step - loss: 0.1980 - mean_absolute_error: 0.3316\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 6s 301ms/step - loss: 0.1923 - mean_absolute_error: 0.3290\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 6s 305ms/step - loss: 0.1974 - mean_absolute_error: 0.3333\n",
      "5/5 [==============================] - 2s 219ms/step\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 18:28:57.388096: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 18:28:57.412088: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 18:28:57.417129: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 11s 116ms/step - loss: 1.0840 - mean_absolute_error: 0.8855\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 12s 183ms/step - loss: 1.0608 - mean_absolute_error: 0.8790\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.8102 - mean_absolute_error: 0.7170\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.7257 - mean_absolute_error: 0.6510\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 0.7324 - mean_absolute_error: 0.6783\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.6377 - mean_absolute_error: 0.6170\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 0.6733 - mean_absolute_error: 0.6351\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 112ms/step - loss: 0.5954 - mean_absolute_error: 0.5894\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 0.5938 - mean_absolute_error: 0.5962\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.5515 - mean_absolute_error: 0.5554\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.5264 - mean_absolute_error: 0.5505\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 0.5590 - mean_absolute_error: 0.5791\n",
      "Epoch 6/20\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 0.4941 - mean_absolute_error: 0.5133Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.5021 - mean_absolute_error: 0.5322\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.5201 - mean_absolute_error: 0.5445\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.4860 - mean_absolute_error: 0.5240\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.4907 - mean_absolute_error: 0.5379\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.4610 - mean_absolute_error: 0.5158\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.4877 - mean_absolute_error: 0.5294\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.4464 - mean_absolute_error: 0.4981\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.4440 - mean_absolute_error: 0.5040\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.4448 - mean_absolute_error: 0.5105\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.4127 - mean_absolute_error: 0.4922\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.4180 - mean_absolute_error: 0.4801\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.4075 - mean_absolute_error: 0.4800\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.4054 - mean_absolute_error: 0.4895\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.3838 - mean_absolute_error: 0.4628\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.3974 - mean_absolute_error: 0.4884\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.3643 - mean_absolute_error: 0.4528\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.3654 - mean_absolute_error: 0.4601\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.3709 - mean_absolute_error: 0.4550\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.3687 - mean_absolute_error: 0.4617\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.3559 - mean_absolute_error: 0.4446\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.3528 - mean_absolute_error: 0.4583\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.3505 - mean_absolute_error: 0.4456\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.3506 - mean_absolute_error: 0.4542\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.3383 - mean_absolute_error: 0.4361\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.3422 - mean_absolute_error: 0.4524\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.3318 - mean_absolute_error: 0.4395\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.3134 - mean_absolute_error: 0.4278\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 2s 23ms/stepss: 0.2331 - mean_absolute_error: 0.3843\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.3063 - mean_absolute_error: 0.4235\n",
      "5/5 [==============================] - 11s 87ms/step - loss: 1.0271 - mean_absolute_error: 0.8593\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 11s 81ms/step - loss: 1.0191 - mean_absolute_error: 0.8649\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 11s 83ms/step - loss: 1.0076 - mean_absolute_error: 0.8453\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.7489 - mean_absolute_error: 0.6896\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.7509 - mean_absolute_error: 0.6883\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.7440 - mean_absolute_error: 0.6741\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.6679 - mean_absolute_error: 0.6344\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.6902 - mean_absolute_error: 0.6315\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.6683 - mean_absolute_error: 0.6221\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.5973 - mean_absolute_error: 0.5985\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.5984 - mean_absolute_error: 0.5944\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.5853 - mean_absolute_error: 0.5828\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.5415 - mean_absolute_error: 0.5687\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.5290 - mean_absolute_error: 0.5580\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.5488 - mean_absolute_error: 0.5533\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 3s 22ms/stepss: 0.5196 - mean_absolute_error: 0.5322\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.5059 - mean_absolute_error: 0.5420\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.5148 - mean_absolute_error: 0.5309\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.5122 - mean_absolute_error: 0.5368\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.4900 - mean_absolute_error: 0.5406\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.4917 - mean_absolute_error: 0.5346\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.4753 - mean_absolute_error: 0.5113\n",
      "Epoch 8/20\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.4569 - mean_absolute_error: 0.5170\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.4571 - mean_absolute_error: 0.5009\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.4353 - mean_absolute_error: 0.4964\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.4362 - mean_absolute_error: 0.5131\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.4233 - mean_absolute_error: 0.4873\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.4325 - mean_absolute_error: 0.4961\n",
      "Epoch 10/20\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.4150 - mean_absolute_error: 0.4976\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.4083 - mean_absolute_error: 0.4793\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.4249 - mean_absolute_error: 0.4910\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.3989 - mean_absolute_error: 0.4750\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.4072 - mean_absolute_error: 0.4880\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.4110 - mean_absolute_error: 0.4841\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.3918 - mean_absolute_error: 0.4698\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.3965 - mean_absolute_error: 0.4903\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.3928 - mean_absolute_error: 0.4724\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3842 - mean_absolute_error: 0.4835\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3759 - mean_absolute_error: 0.4598Epoch 14/20\n",
      "5/5 [==============================] - 1s 89ms/step - loss: 0.3759 - mean_absolute_error: 0.4598\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.3843 - mean_absolute_error: 0.4651\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.3735 - mean_absolute_error: 0.4722\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.3597 - mean_absolute_error: 0.4470\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.3705 - mean_absolute_error: 0.4572\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.3536 - mean_absolute_error: 0.4454\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.3631 - mean_absolute_error: 0.4699\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 1s 99ms/step - loss: 0.3602 - mean_absolute_error: 0.4543\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.3515 - mean_absolute_error: 0.4460\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.3526 - mean_absolute_error: 0.4623\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.3421 - mean_absolute_error: 0.4384\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.3340 - mean_absolute_error: 0.4323\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.3530 - mean_absolute_error: 0.4565\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 1s 98ms/step - loss: 0.3282 - mean_absolute_error: 0.4268\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.3217 - mean_absolute_error: 0.4228\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 1s 99ms/step - loss: 0.3399 - mean_absolute_error: 0.4502\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.3262 - mean_absolute_error: 0.4295\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.3026 - mean_absolute_error: 0.4101\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.3317 - mean_absolute_error: 0.4390Epoch 20/20\n",
      "5/5 [==============================] - 1s 99ms/step - loss: 0.3296 - mean_absolute_error: 0.4402\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.3095 - mean_absolute_error: 0.4151\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 0.3054 - mean_absolute_error: 0.4088\n",
      "5/5 [==============================] - 1s 97ms/step - loss: 0.3165 - mean_absolute_error: 0.4337\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.3312 - mean_absolute_error: 0.4400\n",
      "2/2 [==============================] - 2s 15ms/step\n",
      "2/2 [==============================] - 2s 14ms/step\n",
      "2/2 [==============================] - 2s 14ms/step\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 20s 2s/step - loss: 1.0402 - mean_absolute_error: 0.8706\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 21s 2s/step - loss: 1.1278 - mean_absolute_error: 0.9157\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 23s 3s/step - loss: 1.0794 - mean_absolute_error: 0.8987\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 24s 3s/step - loss: 1.0836 - mean_absolute_error: 0.8901\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 25s 3s/step - loss: 1.1575 - mean_absolute_error: 0.9251\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.8645 - mean_absolute_error: 0.7643\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.9438 - mean_absolute_error: 0.8097\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.9384 - mean_absolute_error: 0.8157\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.9721 - mean_absolute_error: 0.8193\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.9300 - mean_absolute_error: 0.7979\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.7505 - mean_absolute_error: 0.6844\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.8111 - mean_absolute_error: 0.7109\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.8152 - mean_absolute_error: 0.7241\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.8314 - mean_absolute_error: 0.7204\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.7938 - mean_absolute_error: 0.6999\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.6993 - mean_absolute_error: 0.6549\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.7412 - mean_absolute_error: 0.6756\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.7253 - mean_absolute_error: 0.6616\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.7695 - mean_absolute_error: 0.6821\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.7252 - mean_absolute_error: 0.6577\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.6676 - mean_absolute_error: 0.6424\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.6242 - mean_absolute_error: 0.6195\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.6241 - mean_absolute_error: 0.6157\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.7002 - mean_absolute_error: 0.6529\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.5983 - mean_absolute_error: 0.6094\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.5401 - mean_absolute_error: 0.5762\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.6616 - mean_absolute_error: 0.6276\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.6245 - mean_absolute_error: 0.6143\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.5331 - mean_absolute_error: 0.5735\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4904 - mean_absolute_error: 0.5498\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.5266 - mean_absolute_error: 0.5620\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.5938 - mean_absolute_error: 0.5945\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4779 - mean_absolute_error: 0.5381\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4579 - mean_absolute_error: 0.5261\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.5577 - mean_absolute_error: 0.5760\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4840 - mean_absolute_error: 0.5330\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.5255 - mean_absolute_error: 0.5565\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4527 - mean_absolute_error: 0.5152\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.5149 - mean_absolute_error: 0.5474\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4385 - mean_absolute_error: 0.5095\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4519 - mean_absolute_error: 0.5122\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4917 - mean_absolute_error: 0.5264\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4276 - mean_absolute_error: 0.4958\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4742 - mean_absolute_error: 0.5152\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4261 - mean_absolute_error: 0.5067\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4463 - mean_absolute_error: 0.5006\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4699 - mean_absolute_error: 0.5125\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4182 - mean_absolute_error: 0.4965\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4408 - mean_absolute_error: 0.5114\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4577 - mean_absolute_error: 0.5005\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4053 - mean_absolute_error: 0.4875\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.4448 - mean_absolute_error: 0.4957\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4178 - mean_absolute_error: 0.4851\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3993 - mean_absolute_error: 0.4854\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.4443 - mean_absolute_error: 0.4985\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3868 - mean_absolute_error: 0.4791\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.4274 - mean_absolute_error: 0.4880\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3962 - mean_absolute_error: 0.4709\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4280 - mean_absolute_error: 0.4912\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3933 - mean_absolute_error: 0.4817\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3838 - mean_absolute_error: 0.4761\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4070 - mean_absolute_error: 0.4737\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3833 - mean_absolute_error: 0.4623\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4178 - mean_absolute_error: 0.4855\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3856 - mean_absolute_error: 0.4784\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3703 - mean_absolute_error: 0.4669\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3939 - mean_absolute_error: 0.4683\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3747 - mean_absolute_error: 0.4593\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4090 - mean_absolute_error: 0.4764\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3831 - mean_absolute_error: 0.4741\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3628 - mean_absolute_error: 0.4633\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3856 - mean_absolute_error: 0.4639\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3774 - mean_absolute_error: 0.4621\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4011 - mean_absolute_error: 0.4719\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3712 - mean_absolute_error: 0.4667\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3825 - mean_absolute_error: 0.4627\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3508 - mean_absolute_error: 0.4546\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3655 - mean_absolute_error: 0.4557\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3897 - mean_absolute_error: 0.4665\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3708 - mean_absolute_error: 0.4665\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3681 - mean_absolute_error: 0.4496\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 17s 4s/step - loss: 0.3683 - mean_absolute_error: 0.4638\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3459 - mean_absolute_error: 0.4518\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3789 - mean_absolute_error: 0.4605\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3509 - mean_absolute_error: 0.4491\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3614 - mean_absolute_error: 0.4455\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.3411 - mean_absolute_error: 0.4485\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.3596 - mean_absolute_error: 0.4634\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3733 - mean_absolute_error: 0.4544\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3515 - mean_absolute_error: 0.4495\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3517 - mean_absolute_error: 0.4405\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3308 - mean_absolute_error: 0.4411\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3684 - mean_absolute_error: 0.4548\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.3530 - mean_absolute_error: 0.4554\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3332 - mean_absolute_error: 0.4331\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3448 - mean_absolute_error: 0.4403\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3348 - mean_absolute_error: 0.4463\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3645 - mean_absolute_error: 0.4523\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3258 - mean_absolute_error: 0.4271\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3430 - mean_absolute_error: 0.4444\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3369 - mean_absolute_error: 0.4338\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3558 - mean_absolute_error: 0.4459\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3200 - mean_absolute_error: 0.4234\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3253 - mean_absolute_error: 0.4358\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 17s 4s/step - loss: 0.3341 - mean_absolute_error: 0.4455\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3559 - mean_absolute_error: 0.4499\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3169 - mean_absolute_error: 0.4252\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3473 - mean_absolute_error: 0.4396\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3299 - mean_absolute_error: 0.4430\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3465 - mean_absolute_error: 0.4503\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.3264 - mean_absolute_error: 0.4358\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3126 - mean_absolute_error: 0.4216\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3452 - mean_absolute_error: 0.4403\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.3429 - mean_absolute_error: 0.4589\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3505 - mean_absolute_error: 0.4526\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.3215 - mean_absolute_error: 0.4329\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3152 - mean_absolute_error: 0.4271\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3394 - mean_absolute_error: 0.4376\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3209 - mean_absolute_error: 0.4369\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3411 - mean_absolute_error: 0.4418\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3044 - mean_absolute_error: 0.4187\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3221 - mean_absolute_error: 0.4355\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3375 - mean_absolute_error: 0.4368\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3368 - mean_absolute_error: 0.4357\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3076 - mean_absolute_error: 0.4274\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2980 - mean_absolute_error: 0.4106\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3171 - mean_absolute_error: 0.4349\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3459 - mean_absolute_error: 0.4433\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3152 - mean_absolute_error: 0.4207\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2914 - mean_absolute_error: 0.4078\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.3028 - mean_absolute_error: 0.4244\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3100 - mean_absolute_error: 0.4269\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3338 - mean_absolute_error: 0.4370\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2905 - mean_absolute_error: 0.4026\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3190 - mean_absolute_error: 0.4204\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3117 - mean_absolute_error: 0.4318\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3011 - mean_absolute_error: 0.4214\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3467 - mean_absolute_error: 0.4434\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2901 - mean_absolute_error: 0.4048\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3042 - mean_absolute_error: 0.4098\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3044 - mean_absolute_error: 0.4274\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2975 - mean_absolute_error: 0.4184\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3333 - mean_absolute_error: 0.4339\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3029 - mean_absolute_error: 0.4224\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2994 - mean_absolute_error: 0.4085\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2907 - mean_absolute_error: 0.4167\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3247 - mean_absolute_error: 0.4288\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2927 - mean_absolute_error: 0.4151\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2955 - mean_absolute_error: 0.4127\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2987 - mean_absolute_error: 0.4081\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2886 - mean_absolute_error: 0.4152\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3192 - mean_absolute_error: 0.4267\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2807 - mean_absolute_error: 0.3970\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.2919 - mean_absolute_error: 0.4183\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2928 - mean_absolute_error: 0.4055\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3184 - mean_absolute_error: 0.4224\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2742 - mean_absolute_error: 0.3929\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2802 - mean_absolute_error: 0.4062\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2901 - mean_absolute_error: 0.4024\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.2861 - mean_absolute_error: 0.4130\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3334 - mean_absolute_error: 0.4410\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2710 - mean_absolute_error: 0.3918\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.2804 - mean_absolute_error: 0.4078\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2873 - mean_absolute_error: 0.4024\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.2838 - mean_absolute_error: 0.4113\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3139 - mean_absolute_error: 0.4231\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2672 - mean_absolute_error: 0.3886\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2877 - mean_absolute_error: 0.4064\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2804 - mean_absolute_error: 0.4087\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3032 - mean_absolute_error: 0.4139\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3019 - mean_absolute_error: 0.4226\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2627 - mean_absolute_error: 0.3845\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2883 - mean_absolute_error: 0.4055\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2810 - mean_absolute_error: 0.4116\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3009 - mean_absolute_error: 0.4122\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3371 - mean_absolute_error: 0.4572\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2702 - mean_absolute_error: 0.3918\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2784 - mean_absolute_error: 0.3939\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3140 - mean_absolute_error: 0.4223\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2717 - mean_absolute_error: 0.3996\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2704 - mean_absolute_error: 0.3903\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2980 - mean_absolute_error: 0.4230\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2828 - mean_absolute_error: 0.3958\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2982 - mean_absolute_error: 0.4118\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2729 - mean_absolute_error: 0.3952\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.2691 - mean_absolute_error: 0.3988\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.2866 - mean_absolute_error: 0.4102\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2818 - mean_absolute_error: 0.3942\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2976 - mean_absolute_error: 0.4070\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2667 - mean_absolute_error: 0.3899\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2776 - mean_absolute_error: 0.4043\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2796 - mean_absolute_error: 0.4052\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2754 - mean_absolute_error: 0.3935\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2880 - mean_absolute_error: 0.4003\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2570 - mean_absolute_error: 0.3798\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2712 - mean_absolute_error: 0.4009\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2747 - mean_absolute_error: 0.4016\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2745 - mean_absolute_error: 0.3923\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3015 - mean_absolute_error: 0.4164\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2533 - mean_absolute_error: 0.3743\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2641 - mean_absolute_error: 0.3957\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.2680 - mean_absolute_error: 0.3966\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2751 - mean_absolute_error: 0.3928\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2489 - mean_absolute_error: 0.3710\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3226 - mean_absolute_error: 0.4307\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2659 - mean_absolute_error: 0.3998\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 13s 2s/step - loss: 0.2475 - mean_absolute_error: 0.3698\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2766 - mean_absolute_error: 0.3936\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2922 - mean_absolute_error: 0.4060\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.2640 - mean_absolute_error: 0.3921\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2431 - mean_absolute_error: 0.3699\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2702 - mean_absolute_error: 0.4019\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2891 - mean_absolute_error: 0.4100\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3001 - mean_absolute_error: 0.4166\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2656 - mean_absolute_error: 0.3961\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2392 - mean_absolute_error: 0.3633\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2666 - mean_absolute_error: 0.3970\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2844 - mean_absolute_error: 0.4006\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2966 - mean_absolute_error: 0.4167\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2585 - mean_absolute_error: 0.3888\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2382 - mean_absolute_error: 0.3643\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2843 - mean_absolute_error: 0.4108\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2768 - mean_absolute_error: 0.3898\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2633 - mean_absolute_error: 0.3933\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2816 - mean_absolute_error: 0.4030\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2379 - mean_absolute_error: 0.3628\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2641 - mean_absolute_error: 0.3981\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2720 - mean_absolute_error: 0.3863\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2957 - mean_absolute_error: 0.4221\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2708 - mean_absolute_error: 0.4040\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2542 - mean_absolute_error: 0.3819\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2691 - mean_absolute_error: 0.4007\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2689 - mean_absolute_error: 0.3829\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2631 - mean_absolute_error: 0.3978\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2699 - mean_absolute_error: 0.3932\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2643 - mean_absolute_error: 0.3848\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2536 - mean_absolute_error: 0.3908\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2703 - mean_absolute_error: 0.3850\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2671 - mean_absolute_error: 0.3880\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2571 - mean_absolute_error: 0.3907\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2869 - mean_absolute_error: 0.4121\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2617 - mean_absolute_error: 0.3982\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2658 - mean_absolute_error: 0.3857\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2586 - mean_absolute_error: 0.3810\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2668 - mean_absolute_error: 0.3983\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2546 - mean_absolute_error: 0.3841\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2517 - mean_absolute_error: 0.3837\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2790 - mean_absolute_error: 0.3990\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2564 - mean_absolute_error: 0.3771\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2632 - mean_absolute_error: 0.3936\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2546 - mean_absolute_error: 0.3866\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2533 - mean_absolute_error: 0.3846\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2709 - mean_absolute_error: 0.3841\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2589 - mean_absolute_error: 0.3824\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2637 - mean_absolute_error: 0.3914\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2515 - mean_absolute_error: 0.3812\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2516 - mean_absolute_error: 0.3855\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2631 - mean_absolute_error: 0.3816\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2477 - mean_absolute_error: 0.3705\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2485 - mean_absolute_error: 0.3783\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2760 - mean_absolute_error: 0.4051\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2453 - mean_absolute_error: 0.3771\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2571 - mean_absolute_error: 0.3764\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2496 - mean_absolute_error: 0.3749\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2424 - mean_absolute_error: 0.3689\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2518 - mean_absolute_error: 0.3833\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2458 - mean_absolute_error: 0.3764\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2571 - mean_absolute_error: 0.3798\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2486 - mean_absolute_error: 0.3680\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2307 - mean_absolute_error: 0.3590\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2567 - mean_absolute_error: 0.3902\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2796 - mean_absolute_error: 0.4028\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2451 - mean_absolute_error: 0.3791\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2332 - mean_absolute_error: 0.3617\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2506 - mean_absolute_error: 0.3759\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2521 - mean_absolute_error: 0.3861\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2411 - mean_absolute_error: 0.3692\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2651 - mean_absolute_error: 0.3868\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2424 - mean_absolute_error: 0.3771\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2468 - mean_absolute_error: 0.3725\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2449 - mean_absolute_error: 0.3765\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2247 - mean_absolute_error: 0.3526\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2530 - mean_absolute_error: 0.3734\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2391 - mean_absolute_error: 0.3705\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 17s 4s/step - loss: 0.2438 - mean_absolute_error: 0.3662\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2418 - mean_absolute_error: 0.3742\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2249 - mean_absolute_error: 0.3512\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2514 - mean_absolute_error: 0.3729\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2387 - mean_absolute_error: 0.3702\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2381 - mean_absolute_error: 0.3605\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2442 - mean_absolute_error: 0.3763\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2213 - mean_absolute_error: 0.3496\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2590 - mean_absolute_error: 0.3815\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2409 - mean_absolute_error: 0.3711\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2558 - mean_absolute_error: 0.3834\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2308 - mean_absolute_error: 0.3585\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2510 - mean_absolute_error: 0.3850\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2844 - mean_absolute_error: 0.4035\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2423 - mean_absolute_error: 0.3660\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2375 - mean_absolute_error: 0.3698\n",
      "2/5 [===========>..................] - ETA: 8s - loss: 0.2705 - mean_absolute_error: 0.3779 Epoch 59/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2347 - mean_absolute_error: 0.3670\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2609 - mean_absolute_error: 0.3912\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2634 - mean_absolute_error: 0.3868\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2373 - mean_absolute_error: 0.3640\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2363 - mean_absolute_error: 0.3689\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2174 - mean_absolute_error: 0.3441\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2525 - mean_absolute_error: 0.3850\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2584 - mean_absolute_error: 0.3832\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2409 - mean_absolute_error: 0.3618\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2394 - mean_absolute_error: 0.3720\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2144 - mean_absolute_error: 0.3418\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2398 - mean_absolute_error: 0.3802\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2520 - mean_absolute_error: 0.3763\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2363 - mean_absolute_error: 0.3600\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2387 - mean_absolute_error: 0.3712\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2446 - mean_absolute_error: 0.3809\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2161 - mean_absolute_error: 0.3458\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2461 - mean_absolute_error: 0.3707\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2335 - mean_absolute_error: 0.3571\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2371 - mean_absolute_error: 0.3691\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2554 - mean_absolute_error: 0.3864\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2144 - mean_absolute_error: 0.3439\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2441 - mean_absolute_error: 0.3670\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2360 - mean_absolute_error: 0.3566\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2748 - mean_absolute_error: 0.4096\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2475 - mean_absolute_error: 0.3854\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2419 - mean_absolute_error: 0.3669\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2176 - mean_absolute_error: 0.3512\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2387 - mean_absolute_error: 0.3658\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2546 - mean_absolute_error: 0.3895\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2372 - mean_absolute_error: 0.3727\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2375 - mean_absolute_error: 0.3640\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2198 - mean_absolute_error: 0.3491\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2461 - mean_absolute_error: 0.3746\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2602 - mean_absolute_error: 0.3932\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2400 - mean_absolute_error: 0.3675\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2361 - mean_absolute_error: 0.3740\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2103 - mean_absolute_error: 0.3394\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2553 - mean_absolute_error: 0.3884\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.2371 - mean_absolute_error: 0.3629\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2373 - mean_absolute_error: 0.3595\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2358 - mean_absolute_error: 0.3693\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2124 - mean_absolute_error: 0.3443\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2393 - mean_absolute_error: 0.3724\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2456 - mean_absolute_error: 0.3728\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2344 - mean_absolute_error: 0.3633\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2058 - mean_absolute_error: 0.3374\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2438 - mean_absolute_error: 0.3797\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2547 - mean_absolute_error: 0.3795\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2300 - mean_absolute_error: 0.3646\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2408 - mean_absolute_error: 0.3672\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2063 - mean_absolute_error: 0.3350\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2446 - mean_absolute_error: 0.3820\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2260 - mean_absolute_error: 0.3580\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2327 - mean_absolute_error: 0.3548\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2321 - mean_absolute_error: 0.3592\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2067 - mean_absolute_error: 0.3389\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2374 - mean_absolute_error: 0.3752\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2415 - mean_absolute_error: 0.3649\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2298 - mean_absolute_error: 0.3643\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2341 - mean_absolute_error: 0.3631\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2074 - mean_absolute_error: 0.3399\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2465 - mean_absolute_error: 0.3821\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2343 - mean_absolute_error: 0.3678\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2320 - mean_absolute_error: 0.3550\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2318 - mean_absolute_error: 0.3576\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.1999 - mean_absolute_error: 0.3316\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2334 - mean_absolute_error: 0.3741\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2330 - mean_absolute_error: 0.3572\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2318 - mean_absolute_error: 0.3666\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2079 - mean_absolute_error: 0.3416\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2305 - mean_absolute_error: 0.3588\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2318 - mean_absolute_error: 0.3676\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2272 - mean_absolute_error: 0.3595\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2168 - mean_absolute_error: 0.3403\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.1990 - mean_absolute_error: 0.3313\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2290 - mean_absolute_error: 0.3588\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2255 - mean_absolute_error: 0.3614\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2234 - mean_absolute_error: 0.3569\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2216 - mean_absolute_error: 0.3460\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2007 - mean_absolute_error: 0.3321\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2343 - mean_absolute_error: 0.3605\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2247 - mean_absolute_error: 0.3622\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2385 - mean_absolute_error: 0.3772\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2210 - mean_absolute_error: 0.3494\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2046 - mean_absolute_error: 0.3404\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2461 - mean_absolute_error: 0.3764\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.2218 - mean_absolute_error: 0.3600\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2561 - mean_absolute_error: 0.3915\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2211 - mean_absolute_error: 0.3498\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2441 - mean_absolute_error: 0.3780\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.1998 - mean_absolute_error: 0.3316\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2305 - mean_absolute_error: 0.3705\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2492 - mean_absolute_error: 0.3857\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2419 - mean_absolute_error: 0.3715\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2298 - mean_absolute_error: 0.3569\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.1979 - mean_absolute_error: 0.3287\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2192 - mean_absolute_error: 0.3554\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2349 - mean_absolute_error: 0.3669\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2376 - mean_absolute_error: 0.3634\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2221 - mean_absolute_error: 0.3502\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2021 - mean_absolute_error: 0.3367\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2178 - mean_absolute_error: 0.3559\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2305 - mean_absolute_error: 0.3580\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2323 - mean_absolute_error: 0.3648\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2025 - mean_absolute_error: 0.3368\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2247 - mean_absolute_error: 0.3534\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2173 - mean_absolute_error: 0.3568\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2352 - mean_absolute_error: 0.3644\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2005 - mean_absolute_error: 0.3326\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2262 - mean_absolute_error: 0.3565\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2187 - mean_absolute_error: 0.3485\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2168 - mean_absolute_error: 0.3553\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2278 - mean_absolute_error: 0.3533\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.1968 - mean_absolute_error: 0.3293\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2287 - mean_absolute_error: 0.3605\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2364 - mean_absolute_error: 0.3701\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2319 - mean_absolute_error: 0.3639\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2181 - mean_absolute_error: 0.3588\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.1973 - mean_absolute_error: 0.3317\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2175 - mean_absolute_error: 0.3471\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2349 - mean_absolute_error: 0.3701\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.1940 - mean_absolute_error: 0.3277\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2264 - mean_absolute_error: 0.3552\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2166 - mean_absolute_error: 0.3542\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2192 - mean_absolute_error: 0.3477\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2234 - mean_absolute_error: 0.3604\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2126 - mean_absolute_error: 0.3511\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2268 - mean_absolute_error: 0.3566\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2193 - mean_absolute_error: 0.3564\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2147 - mean_absolute_error: 0.3412\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2238 - mean_absolute_error: 0.3591\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2101 - mean_absolute_error: 0.3466\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2274 - mean_absolute_error: 0.3558\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2257 - mean_absolute_error: 0.3643\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2202 - mean_absolute_error: 0.3435\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2135 - mean_absolute_error: 0.3504\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2238 - mean_absolute_error: 0.3573\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2335 - mean_absolute_error: 0.3653\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2284 - mean_absolute_error: 0.3672\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2075 - mean_absolute_error: 0.3462\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2172 - mean_absolute_error: 0.3432\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2430 - mean_absolute_error: 0.3775\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2315 - mean_absolute_error: 0.3600\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2164 - mean_absolute_error: 0.3556\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2092 - mean_absolute_error: 0.3474\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2187 - mean_absolute_error: 0.3482\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2278 - mean_absolute_error: 0.3647\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2212 - mean_absolute_error: 0.3489\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2156 - mean_absolute_error: 0.3540\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2021 - mean_absolute_error: 0.3354\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2473 - mean_absolute_error: 0.3820\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2280 - mean_absolute_error: 0.3589\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2182 - mean_absolute_error: 0.3562\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2215 - mean_absolute_error: 0.3487\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.1952 - mean_absolute_error: 0.3300\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2406 - mean_absolute_error: 0.3643\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2200 - mean_absolute_error: 0.3569\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2114 - mean_absolute_error: 0.3536\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2241 - mean_absolute_error: 0.3538\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.1994 - mean_absolute_error: 0.3327\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2374 - mean_absolute_error: 0.3675\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2247 - mean_absolute_error: 0.3603\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2106 - mean_absolute_error: 0.3508\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2230 - mean_absolute_error: 0.3512\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2001 - mean_absolute_error: 0.3349\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2283 - mean_absolute_error: 0.3603\n",
      "3/5 [=================>............] - ETA: 6s - loss: 0.2142 - mean_absolute_error: 0.3599Epoch 94/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2166 - mean_absolute_error: 0.3551\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2292 - mean_absolute_error: 0.3683\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2198 - mean_absolute_error: 0.3506\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2387 - mean_absolute_error: 0.3723\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.1968 - mean_absolute_error: 0.3278\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2108 - mean_absolute_error: 0.3513\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2269 - mean_absolute_error: 0.3631\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 7s 954ms/stepss: 0.2303 - mean_absolute_error: 0.36\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2184 - mean_absolute_error: 0.3476\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2409 - mean_absolute_error: 0.3719\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2152 - mean_absolute_error: 0.3556\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2258 - mean_absolute_error: 0.3662\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2209 - mean_absolute_error: 0.3495\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 13s 2s/step - loss: 0.2385 - mean_absolute_error: 0.3717\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2104 - mean_absolute_error: 0.3505\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2297 - mean_absolute_error: 0.3667\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 13s 2s/step - loss: 0.2212 - mean_absolute_error: 0.3494\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2411 - mean_absolute_error: 0.3713\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2280 - mean_absolute_error: 0.3730\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2165 - mean_absolute_error: 0.3500\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2258 - mean_absolute_error: 0.3537\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2205 - mean_absolute_error: 0.3511\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2116 - mean_absolute_error: 0.3481\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 5s 766ms/steps: 0.1775 - mean_absolute_error: 0.31\n",
      "5/5 [==============================] - 13s 2s/step - loss: 0.2149 - mean_absolute_error: 0.3462\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.2173 - mean_absolute_error: 0.3455\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2079 - mean_absolute_error: 0.3468\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.2132 - mean_absolute_error: 0.3468\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.2130 - mean_absolute_error: 0.3416\n",
      "2/2 [==============================] - 4s 595ms/steps: 0.2128 - mean_absolute_error: 0.34\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.2096 - mean_absolute_error: 0.3464\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.2157 - mean_absolute_error: 0.3486\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.2053 - mean_absolute_error: 0.3440\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.2125 - mean_absolute_error: 0.3443\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.2059 - mean_absolute_error: 0.3439\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.2115 - mean_absolute_error: 0.3427\n",
      "2/2 [==============================] - 3s 434ms/step\n",
      "2/2 [==============================] - 3s 506ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [32, 100, 0.0001, 'sgd', 512] before, using random point [128, 30, 0.001, 'sgd', 512]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 18:56:06.260184: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 18:56:06.276795: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 18:56:06.283807: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 18s 2s/step - loss: 0.8352 - mean_absolute_error: 0.7327\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 18s 2s/step - loss: 0.8128 - mean_absolute_error: 0.7180\n",
      "Epoch 2/30\n",
      "1/5 [=====>........................] - ETA: 6s - loss: 1.2814 - mean_absolute_error: 0.9113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/5 [=================>............] - ETA: 3s - loss: 0.8643 - mean_absolute_error: 0.7404Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.8695 - mean_absolute_error: 0.7629\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.7755 - mean_absolute_error: 0.7041\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.7209 - mean_absolute_error: 0.6828\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.6625 - mean_absolute_error: 0.6278\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.6188 - mean_absolute_error: 0.5862\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 25s 2s/step - loss: 0.9132 - mean_absolute_error: 0.7750\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 25s 2s/step - loss: 0.7837 - mean_absolute_error: 0.7074\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.9250 - mean_absolute_error: 0.7792Epoch 2/30\n",
      "5/5 [==============================] - 25s 2s/step - loss: 0.9250 - mean_absolute_error: 0.7792\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.6158 - mean_absolute_error: 0.5799\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.7161 - mean_absolute_error: 0.6608\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.7955 - mean_absolute_error: 0.7188\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.6526 - mean_absolute_error: 0.6142\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.5737 - mean_absolute_error: 0.5781\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.5970 - mean_absolute_error: 0.5847\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.7243 - mean_absolute_error: 0.6880\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.6427 - mean_absolute_error: 0.6293\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.5622 - mean_absolute_error: 0.5679\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.5048 - mean_absolute_error: 0.5250\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.6129 - mean_absolute_error: 0.6001\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.5904 - mean_absolute_error: 0.5923\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.5400 - mean_absolute_error: 0.5406\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.4960 - mean_absolute_error: 0.5247\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4797 - mean_absolute_error: 0.5238\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.5524 - mean_absolute_error: 0.5647\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.4765 - mean_absolute_error: 0.5117\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.5437 - mean_absolute_error: 0.5690\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.5000 - mean_absolute_error: 0.5326\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.5206 - mean_absolute_error: 0.5471\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4381 - mean_absolute_error: 0.4999\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.5898 - mean_absolute_error: 0.6020\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4842 - mean_absolute_error: 0.5319\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4966 - mean_absolute_error: 0.5375\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.5067 - mean_absolute_error: 0.5425\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4901 - mean_absolute_error: 0.5231\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4566 - mean_absolute_error: 0.5190\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4057 - mean_absolute_error: 0.4807\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4622 - mean_absolute_error: 0.5069\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4749 - mean_absolute_error: 0.5213\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.5163 - mean_absolute_error: 0.5531\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4233 - mean_absolute_error: 0.4991\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4191 - mean_absolute_error: 0.5001\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4855 - mean_absolute_error: 0.5238\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4680 - mean_absolute_error: 0.5180\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4771 - mean_absolute_error: 0.5181\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4071 - mean_absolute_error: 0.4942\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3779 - mean_absolute_error: 0.4727\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4148 - mean_absolute_error: 0.4804\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4524 - mean_absolute_error: 0.5105\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4715 - mean_absolute_error: 0.5183\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4519 - mean_absolute_error: 0.5345\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3542 - mean_absolute_error: 0.4614\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3829 - mean_absolute_error: 0.4601\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4334 - mean_absolute_error: 0.4994\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4238 - mean_absolute_error: 0.4893\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4293 - mean_absolute_error: 0.5103\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3227 - mean_absolute_error: 0.4320\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3540 - mean_absolute_error: 0.4460\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4149 - mean_absolute_error: 0.4925\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3779 - mean_absolute_error: 0.4652\n",
      "3/5 [=================>............] - ETA: 5s - loss: 0.2966 - mean_absolute_error: 0.4023Epoch 13/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4013 - mean_absolute_error: 0.4922\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2966 - mean_absolute_error: 0.4095\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3474 - mean_absolute_error: 0.4506\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3720 - mean_absolute_error: 0.4668\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4072 - mean_absolute_error: 0.4905\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3820 - mean_absolute_error: 0.4786\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3235 - mean_absolute_error: 0.4247\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2847 - mean_absolute_error: 0.4058\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3470 - mean_absolute_error: 0.4522\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3514 - mean_absolute_error: 0.4496\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3568 - mean_absolute_error: 0.4670\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2953 - mean_absolute_error: 0.4109\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4750 - mean_absolute_error: 0.5503\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3268 - mean_absolute_error: 0.4422\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3935 - mean_absolute_error: 0.4956\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3263 - mean_absolute_error: 0.4427\n",
      "4/5 [=======================>......] - ETA: 3s - loss: 0.6990 - mean_absolute_error: 0.6444Epoch 16/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4153 - mean_absolute_error: 0.5056\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.6740 - mean_absolute_error: 0.6298\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3359 - mean_absolute_error: 0.4528\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3569 - mean_absolute_error: 0.4589\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4809 - mean_absolute_error: 0.5347\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3121 - mean_absolute_error: 0.4358\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4574 - mean_absolute_error: 0.5126\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4746 - mean_absolute_error: 0.5380\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3207 - mean_absolute_error: 0.4303\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4520 - mean_absolute_error: 0.5247\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3194 - mean_absolute_error: 0.4367\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4230 - mean_absolute_error: 0.4896\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4005 - mean_absolute_error: 0.4922\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4180 - mean_absolute_error: 0.4863\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2942 - mean_absolute_error: 0.4044\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4069 - mean_absolute_error: 0.4911\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2777 - mean_absolute_error: 0.4087\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3857 - mean_absolute_error: 0.4877\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3690 - mean_absolute_error: 0.4531\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3558 - mean_absolute_error: 0.4428\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2806 - mean_absolute_error: 0.3983\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.3015 - mean_absolute_error: 0.4244\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3222 - mean_absolute_error: 0.4262\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3093 - mean_absolute_error: 0.4201\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3605 - mean_absolute_error: 0.4665\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2796 - mean_absolute_error: 0.3987\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.2920 - mean_absolute_error: 0.4180\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3070 - mean_absolute_error: 0.4223\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2917 - mean_absolute_error: 0.4115\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3381 - mean_absolute_error: 0.4533\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2667 - mean_absolute_error: 0.3897\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2942 - mean_absolute_error: 0.4208\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2762 - mean_absolute_error: 0.3981\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2698 - mean_absolute_error: 0.4022\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3101 - mean_absolute_error: 0.4302\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2968 - mean_absolute_error: 0.4224\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2780 - mean_absolute_error: 0.4026\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2902 - mean_absolute_error: 0.4202\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.2593 - mean_absolute_error: 0.3908\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2877 - mean_absolute_error: 0.4113\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3192 - mean_absolute_error: 0.4327\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2544 - mean_absolute_error: 0.3794\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2860 - mean_absolute_error: 0.4097\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2998 - mean_absolute_error: 0.4226\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2842 - mean_absolute_error: 0.4109\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2495 - mean_absolute_error: 0.3726\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2915 - mean_absolute_error: 0.4154\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2820 - mean_absolute_error: 0.4136\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.3667 - mean_absolute_error: 0.4745\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2722 - mean_absolute_error: 0.4057\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2378 - mean_absolute_error: 0.3672\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2978 - mean_absolute_error: 0.4251\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2865 - mean_absolute_error: 0.4106\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3548 - mean_absolute_error: 0.4677\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2978 - mean_absolute_error: 0.4330\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2628 - mean_absolute_error: 0.3907\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2778 - mean_absolute_error: 0.4069\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2838 - mean_absolute_error: 0.4055\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2343 - mean_absolute_error: 0.3584\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2856 - mean_absolute_error: 0.4130\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2678 - mean_absolute_error: 0.4073\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2437 - mean_absolute_error: 0.3737\n",
      "2/2 [==============================] - 5s 744ms/steps: 0.2700 - mean_absolute_error: 0.38\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.2649 - mean_absolute_error: 0.3884\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0209daa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 5s 761ms/step\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2650 - mean_absolute_error: 0.3990\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2778 - mean_absolute_error: 0.4110\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.2452 - mean_absolute_error: 0.3700\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.2707 - mean_absolute_error: 0.4052\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2775 - mean_absolute_error: 0.4036\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.2430 - mean_absolute_error: 0.3753\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.2723 - mean_absolute_error: 0.4118\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2716 - mean_absolute_error: 0.4015\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.2989 - mean_absolute_error: 0.4183\n",
      "2/2 [==============================] - 5s 731ms/steps: 0.2701 - mean_absolute_error: 0.39\n",
      "2/2 [==============================] - 4s 595ms/step\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.2468 - mean_absolute_error: 0.3784\n",
      "2/2 [==============================] - 3s 541ms/step\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "20/20 [==============================] - 11s 70ms/step - loss: 0.7817 - mean_absolute_error: 0.7109\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 11s 83ms/step - loss: 0.7407 - mean_absolute_error: 0.6792\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 11s 83ms/step - loss: 0.7780 - mean_absolute_error: 0.7030\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 11s 88ms/step - loss: 0.7305 - mean_absolute_error: 0.6834\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 11s 76ms/step - loss: 0.8196 - mean_absolute_error: 0.7174\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.5430 - mean_absolute_error: 0.5580\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.5409 - mean_absolute_error: 0.5508\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.5647 - mean_absolute_error: 0.5849\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.5631 - mean_absolute_error: 0.5587\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 2s 89ms/step - loss: 0.5147 - mean_absolute_error: 0.5505\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 0.4565 - mean_absolute_error: 0.5079\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.4884 - mean_absolute_error: 0.5400\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.4802 - mean_absolute_error: 0.5263\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.4632 - mean_absolute_error: 0.5136\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.4229 - mean_absolute_error: 0.5062\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.4079 - mean_absolute_error: 0.4853\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.4475 - mean_absolute_error: 0.5165\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.4461 - mean_absolute_error: 0.5072\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 0.4077 - mean_absolute_error: 0.4863\n",
      " 2/20 [==>...........................] - ETA: 1s - loss: 0.3219 - mean_absolute_error: 0.4207Epoch 5/20\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 0.3805 - mean_absolute_error: 0.4668\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 2s 98ms/step - loss: 0.4027 - mean_absolute_error: 0.4942\n",
      " 5/20 [======>.......................] - ETA: 1s - loss: 0.2677 - mean_absolute_error: 0.4072Epoch 5/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.4014 - mean_absolute_error: 0.4859\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.3969 - mean_absolute_error: 0.4746\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.3674 - mean_absolute_error: 0.4537\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.3608 - mean_absolute_error: 0.4615\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.3885 - mean_absolute_error: 0.4809\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.3707 - mean_absolute_error: 0.4683\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.3673 - mean_absolute_error: 0.4582\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.3658 - mean_absolute_error: 0.4491\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.3588 - mean_absolute_error: 0.4588\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 2s 99ms/step - loss: 0.3827 - mean_absolute_error: 0.4800\n",
      "13/20 [==================>...........] - ETA: 0s - loss: 0.3350 - mean_absolute_error: 0.4308Epoch 7/20\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.3585 - mean_absolute_error: 0.4573\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.3638 - mean_absolute_error: 0.4543\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.3130 - mean_absolute_error: 0.4277\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.3499 - mean_absolute_error: 0.4326\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.3455 - mean_absolute_error: 0.4593\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.3136 - mean_absolute_error: 0.4325\n",
      "Epoch 8/20\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.3695 - mean_absolute_error: 0.4709\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.3430 - mean_absolute_error: 0.4348\n",
      " 2/20 [==>...........................] - ETA: 2s - loss: 0.3011 - mean_absolute_error: 0.4417Epoch 9/20\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.3107 - mean_absolute_error: 0.4167\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 1s 70ms/step - loss: 0.2875 - mean_absolute_error: 0.4057\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.3204 - mean_absolute_error: 0.4378\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.3559 - mean_absolute_error: 0.4558\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.3064 - mean_absolute_error: 0.4140\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 2s 100ms/step - loss: 0.3135 - mean_absolute_error: 0.4339\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.3013 - mean_absolute_error: 0.4218\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 1s 69ms/step - loss: 0.3166 - mean_absolute_error: 0.4381\n",
      "14/20 [====================>.........] - ETA: 0s - loss: 0.3165 - mean_absolute_error: 0.4442Epoch 11/20\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.3138 - mean_absolute_error: 0.4318\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.3269 - mean_absolute_error: 0.4286\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.3130 - mean_absolute_error: 0.4370\n",
      " 9/20 [============>.................] - ETA: 0s - loss: 0.2742 - mean_absolute_error: 0.4123Epoch 10/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.2804 - mean_absolute_error: 0.4049\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.3054 - mean_absolute_error: 0.4162\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.2865 - mean_absolute_error: 0.4108\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 2s 91ms/step - loss: 0.2989 - mean_absolute_error: 0.4094\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 2s 88ms/step - loss: 0.3104 - mean_absolute_error: 0.4291\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.2790 - mean_absolute_error: 0.3869\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.2814 - mean_absolute_error: 0.4026\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.2772 - mean_absolute_error: 0.4027\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 0.3216 - mean_absolute_error: 0.4305\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.2624 - mean_absolute_error: 0.3802\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 2s 105ms/step - loss: 0.3082 - mean_absolute_error: 0.4312\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.2633 - mean_absolute_error: 0.3814\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.2746 - mean_absolute_error: 0.4087\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.3129 - mean_absolute_error: 0.4254\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.2647 - mean_absolute_error: 0.3873\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.2430 - mean_absolute_error: 0.3688\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 2s 99ms/step - loss: 0.2852 - mean_absolute_error: 0.4139\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.2645 - mean_absolute_error: 0.3979\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.3040 - mean_absolute_error: 0.4200\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 0.2424 - mean_absolute_error: 0.3601\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.2402 - mean_absolute_error: 0.3703\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 1s 71ms/step - loss: 0.2691 - mean_absolute_error: 0.4031\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 0.2658 - mean_absolute_error: 0.3971\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 1s 71ms/step - loss: 0.2424 - mean_absolute_error: 0.3660\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.3010 - mean_absolute_error: 0.4148\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.2293 - mean_absolute_error: 0.3559\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.2550 - mean_absolute_error: 0.3910\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 2s 75ms/step - loss: 0.2437 - mean_absolute_error: 0.3683\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 2s 101ms/step - loss: 0.2840 - mean_absolute_error: 0.4026\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.2710 - mean_absolute_error: 0.3926\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.2519 - mean_absolute_error: 0.3817\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 2s 89ms/step - loss: 0.2411 - mean_absolute_error: 0.3660\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.2498 - mean_absolute_error: 0.3713\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 1s 70ms/step - loss: 0.2381 - mean_absolute_error: 0.3807\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.2669 - mean_absolute_error: 0.3902\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 2s 102ms/step - loss: 0.2674 - mean_absolute_error: 0.3958\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.2490 - mean_absolute_error: 0.3798\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 2s 75ms/step - loss: 0.2622 - mean_absolute_error: 0.3842\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.2351 - mean_absolute_error: 0.3731\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.2564 - mean_absolute_error: 0.3799\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 2s 95ms/step - loss: 0.2587 - mean_absolute_error: 0.3920\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.2452 - mean_absolute_error: 0.3829\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.2716 - mean_absolute_error: 0.3947\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.2269 - mean_absolute_error: 0.3627\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.2839 - mean_absolute_error: 0.4097\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 2s 98ms/step - loss: 0.2423 - mean_absolute_error: 0.3751\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 2s 34ms/steploss: 0.1954 - mean_absolute_error: 0.3487\n",
      "5/5 [==============================] - 2s 22ms/steploss: 0.2555 - mean_absolute_error: 0.385\n",
      "5/5 [==============================] - 2s 32ms/steploss: 0.2115 - mean_absolute_error: 0.3646\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.2601 - mean_absolute_error: 0.3799\n",
      "20/20 [==============================] - 2s 89ms/step - loss: 0.2352 - mean_absolute_error: 0.3668\n",
      "Epoch 19/20\n",
      "10/20 [==============>...............] - ETA: 0s - loss: 0.2341 - mean_absolute_error: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd090a59670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 36ms/steploss: 0.2328 - mean_absolute_error: 0.37\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.2482 - mean_absolute_error: 0.3791\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.2391 - mean_absolute_error: 0.3765\n",
      "5/5 [==============================] - 2s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/myenv/lib/python3.8/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 11s 79ms/step - loss: 1.0102 - mean_absolute_error: 0.8513\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.7683 - mean_absolute_error: 0.6950\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.6142 - mean_absolute_error: 0.5995\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.5161 - mean_absolute_error: 0.5482\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 2s 98ms/step - loss: 0.4751 - mean_absolute_error: 0.5213\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 3s 116ms/step - loss: 0.4478 - mean_absolute_error: 0.5045\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 3s 114ms/step - loss: 0.4223 - mean_absolute_error: 0.4876\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 4s 178ms/step - loss: 0.4047 - mean_absolute_error: 0.4803\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 3s 135ms/step - loss: 0.3943 - mean_absolute_error: 0.4739\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 0.3813 - mean_absolute_error: 0.4685\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 0.3771 - mean_absolute_error: 0.4666\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 0.3820 - mean_absolute_error: 0.4711\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 5s 184ms/step - loss: 0.3632 - mean_absolute_error: 0.4567\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 5s 199ms/step - loss: 0.3549 - mean_absolute_error: 0.4532\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 5s 199ms/step - loss: 0.3493 - mean_absolute_error: 0.4501\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 5s 214ms/step - loss: 0.3446 - mean_absolute_error: 0.4407\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 5s 211ms/step - loss: 0.3342 - mean_absolute_error: 0.4354\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 5s 186ms/step - loss: 0.3222 - mean_absolute_error: 0.4309\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 5s 201ms/step - loss: 0.3224 - mean_absolute_error: 0.4285\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 5s 209ms/step - loss: 0.3140 - mean_absolute_error: 0.4230\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 5s 208ms/step - loss: 0.3037 - mean_absolute_error: 0.4144\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 5s 200ms/step - loss: 0.3073 - mean_absolute_error: 0.4143\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 5s 187ms/step - loss: 0.2996 - mean_absolute_error: 0.4134\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 5s 180ms/step - loss: 0.2881 - mean_absolute_error: 0.4052\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 0.2984 - mean_absolute_error: 0.4153\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.2910 - mean_absolute_error: 0.4055\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 4s 146ms/step - loss: 0.2894 - mean_absolute_error: 0.4104\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 0.2857 - mean_absolute_error: 0.4061\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 4s 155ms/step - loss: 0.2960 - mean_absolute_error: 0.4144\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 3s 133ms/step - loss: 0.2790 - mean_absolute_error: 0.3974\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 4s 154ms/step - loss: 0.2769 - mean_absolute_error: 0.4001\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 4s 151ms/step - loss: 0.2718 - mean_absolute_error: 0.3986\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 4s 181ms/step - loss: 0.2643 - mean_absolute_error: 0.3847\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.2652 - mean_absolute_error: 0.3867\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 5s 208ms/step - loss: 0.2691 - mean_absolute_error: 0.3916\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 6s 231ms/step - loss: 0.2592 - mean_absolute_error: 0.3834\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 6s 242ms/step - loss: 0.2592 - mean_absolute_error: 0.3820\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 6s 253ms/step - loss: 0.2611 - mean_absolute_error: 0.3828\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 6s 250ms/step - loss: 0.2617 - mean_absolute_error: 0.3841\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 6s 256ms/step - loss: 0.2552 - mean_absolute_error: 0.3808\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 6s 251ms/step - loss: 0.2580 - mean_absolute_error: 0.3853\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 5s 195ms/step - loss: 0.2494 - mean_absolute_error: 0.3800\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 5s 198ms/step - loss: 0.2428 - mean_absolute_error: 0.3683\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 5s 209ms/step - loss: 0.2469 - mean_absolute_error: 0.3774\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 5s 218ms/step - loss: 0.2466 - mean_absolute_error: 0.3763\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 5s 200ms/step - loss: 0.2468 - mean_absolute_error: 0.3795\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 5s 198ms/step - loss: 0.2418 - mean_absolute_error: 0.3706\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 5s 190ms/step - loss: 0.2389 - mean_absolute_error: 0.3617\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 5s 184ms/step - loss: 0.2401 - mean_absolute_error: 0.3661\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 4s 175ms/step - loss: 0.2441 - mean_absolute_error: 0.3714\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 0.2456 - mean_absolute_error: 0.3768\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 4s 150ms/step - loss: 0.2395 - mean_absolute_error: 0.3650\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 3s 134ms/step - loss: 0.2314 - mean_absolute_error: 0.3605\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 0.2351 - mean_absolute_error: 0.3626\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 4s 154ms/step - loss: 0.2320 - mean_absolute_error: 0.3574\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 3s 136ms/step - loss: 0.2343 - mean_absolute_error: 0.3617\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 0.2338 - mean_absolute_error: 0.3640\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 3s 140ms/step - loss: 0.2365 - mean_absolute_error: 0.3652\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 4s 156ms/step - loss: 0.2288 - mean_absolute_error: 0.3553\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 0.2278 - mean_absolute_error: 0.3581\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 5s 181ms/step - loss: 0.2293 - mean_absolute_error: 0.3575\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 5s 197ms/step - loss: 0.2376 - mean_absolute_error: 0.3683\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 5s 214ms/step - loss: 0.2274 - mean_absolute_error: 0.3522\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 5s 198ms/step - loss: 0.2339 - mean_absolute_error: 0.3617\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 5s 200ms/step - loss: 0.2227 - mean_absolute_error: 0.3493\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 5s 191ms/step - loss: 0.2436 - mean_absolute_error: 0.3741\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 5s 187ms/step - loss: 0.2272 - mean_absolute_error: 0.3577\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 5s 184ms/step - loss: 0.2268 - mean_absolute_error: 0.3576\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 4s 179ms/step - loss: 0.2212 - mean_absolute_error: 0.3509\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 4s 180ms/step - loss: 0.2199 - mean_absolute_error: 0.3504\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 5s 181ms/step - loss: 0.2311 - mean_absolute_error: 0.3616\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 5s 219ms/step - loss: 0.2304 - mean_absolute_error: 0.3637\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 7s 262ms/step - loss: 0.2228 - mean_absolute_error: 0.3547\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 6s 221ms/step - loss: 0.2265 - mean_absolute_error: 0.3617\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 5s 203ms/step - loss: 0.2165 - mean_absolute_error: 0.3460\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 5s 205ms/step - loss: 0.2190 - mean_absolute_error: 0.3484\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 5s 212ms/step - loss: 0.2209 - mean_absolute_error: 0.3517\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 5s 205ms/step - loss: 0.2132 - mean_absolute_error: 0.3463\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 5s 196ms/step - loss: 0.2268 - mean_absolute_error: 0.3566\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 5s 205ms/step - loss: 0.2200 - mean_absolute_error: 0.3502\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 5s 185ms/step - loss: 0.2359 - mean_absolute_error: 0.3690\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 4s 156ms/step - loss: 0.2247 - mean_absolute_error: 0.3521\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 0.2193 - mean_absolute_error: 0.3524\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 5s 181ms/step - loss: 0.2182 - mean_absolute_error: 0.3514\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 5s 184ms/step - loss: 0.2132 - mean_absolute_error: 0.3447\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 5s 183ms/step - loss: 0.2137 - mean_absolute_error: 0.3457\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 0.2181 - mean_absolute_error: 0.3502\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 4s 180ms/step - loss: 0.2162 - mean_absolute_error: 0.3484\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 4s 155ms/step - loss: 0.2158 - mean_absolute_error: 0.3467\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 0.2154 - mean_absolute_error: 0.3455\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 4s 148ms/step - loss: 0.2136 - mean_absolute_error: 0.3431\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 4s 144ms/step - loss: 0.2102 - mean_absolute_error: 0.3427\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 0.2107 - mean_absolute_error: 0.3426\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 3s 137ms/step - loss: 0.2074 - mean_absolute_error: 0.3409\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 3s 130ms/step - loss: 0.2132 - mean_absolute_error: 0.3434\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.2119 - mean_absolute_error: 0.3430\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 3s 135ms/step - loss: 0.2171 - mean_absolute_error: 0.3511\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 0.2113 - mean_absolute_error: 0.3429\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 4s 152ms/step - loss: 0.2064 - mean_absolute_error: 0.3373\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 4s 156ms/step - loss: 0.2095 - mean_absolute_error: 0.3365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(estimator=KerasRegressor(build_fn=&lt;function create_model at 0x7fb408966670&gt;, learning_rate=0.01, units=64),\n",
       "              n_jobs=-1, scoring=&#x27;neg_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;batch_size&#x27;: [32, 64, 128],\n",
       "                             &#x27;epochs&#x27;: [10, 20, 30, 50, 100],\n",
       "                             &#x27;learning_rate&#x27;: [0.01, 0.001, 0.0001],\n",
       "                             &#x27;optimizer&#x27;: [&#x27;adam&#x27;, &#x27;rmsprop&#x27;, &#x27;sgd&#x27;],\n",
       "                             &#x27;units&#x27;: [64, 128, 256, 512]},\n",
       "              verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(estimator=KerasRegressor(build_fn=&lt;function create_model at 0x7fb408966670&gt;, learning_rate=0.01, units=64),\n",
       "              n_jobs=-1, scoring=&#x27;neg_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;batch_size&#x27;: [32, 64, 128],\n",
       "                             &#x27;epochs&#x27;: [10, 20, 30, 50, 100],\n",
       "                             &#x27;learning_rate&#x27;: [0.01, 0.001, 0.0001],\n",
       "                             &#x27;optimizer&#x27;: [&#x27;adam&#x27;, &#x27;rmsprop&#x27;, &#x27;sgd&#x27;],\n",
       "                             &#x27;units&#x27;: [64, 128, 256, 512]},\n",
       "              verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function create_model at 0x7fb408966670&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tunits=64\n",
       "\tlearning_rate=0.01\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function create_model at 0x7fb408966670&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tunits=64\n",
       "\tlearning_rate=0.01\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(estimator=KerasRegressor(build_fn=<function create_model at 0x7fb408966670>, learning_rate=0.01, units=64),\n",
       "              n_jobs=-1, scoring='neg_mean_squared_error',\n",
       "              search_spaces={'batch_size': [32, 64, 128],\n",
       "                             'epochs': [10, 20, 30, 50, 100],\n",
       "                             'learning_rate': [0.01, 0.001, 0.0001],\n",
       "                             'optimizer': ['adam', 'rmsprop', 'sgd'],\n",
       "                             'units': [64, 128, 256, 512]},\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "bayes_search.fit(X, y, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardo los mejores hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los mejores hiperparámetros han sido guardados en best_params.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Obtener los mejores hiperparámetros\n",
    "best_params = bayes_search.best_params_\n",
    "\n",
    "# Guardar los mejores hiperparámetros en un archivo JSON\n",
    "with open('best_params.json', 'w') as file:\n",
    "    json.dump(best_params, file)\n",
    "\n",
    "print('Los mejores hiperparámetros han sido guardados en best_params.json.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 11s 111ms/step - loss: 1.0302 - mean_absolute_error: 0.8636\n",
      "Configuración del nuevo modelo:\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 34, 128)           68096     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 34, 128)           0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 199809 (780.50 KB)\n",
      "Trainable params: 199809 (780.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with open('best_params.json', 'r') as file:\n",
    "    best_params = json.load(file)\n",
    "\n",
    "# Reconstruir el modelo con los mejores hiperparámetros\n",
    "mejor_modelo = create_model(units=best_params['units'], learning_rate=best_params['learning_rate'], optimizer=best_params['optimizer'])\n",
    "mejor_modelo.fit(X, y)\n",
    "# Verificar la configuración del nuevo modelo\n",
    "print(\"Configuración del nuevo modelo:\")\n",
    "print(mejor_modelo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hago las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = BayesSearchCV.best_params_\n",
    "\n",
    "# best_units = best_params['build_fn__units']\n",
    "# best_dropout_rate = best_params['build_fn__dropout_rate']\n",
    "# best_optimizer = best_params['build_fn__optimizer']\n",
    "\n",
    "# best_model = create_model(units=best_units, dropout_rate=best_dropout_rate, optimizer=best_optimizer)\n",
    "# best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f, product_ids, _ = prepare_data(scaled_data, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 3s 65ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.03749761],\n",
       "       [ 0.07719515],\n",
       "       [-0.28504974],\n",
       "       [-0.16752963],\n",
       "       [ 0.00191359],\n",
       "       [-0.46567208],\n",
       "       [-0.5009722 ],\n",
       "       [-0.50684524],\n",
       "       [ 0.08870511],\n",
       "       [-0.2601701 ],\n",
       "       [-0.35600978],\n",
       "       [-0.5058283 ],\n",
       "       [-0.24785617],\n",
       "       [-0.13520795],\n",
       "       [-0.28447428],\n",
       "       [-0.52350885],\n",
       "       [-0.49021673],\n",
       "       [-0.45785466],\n",
       "       [-0.32442707],\n",
       "       [-0.38365418],\n",
       "       [-0.3616345 ],\n",
       "       [-0.1745336 ],\n",
       "       [-0.1690569 ],\n",
       "       [-0.40086722],\n",
       "       [-0.3435718 ],\n",
       "       [-0.2885229 ],\n",
       "       [-0.19864361],\n",
       "       [-0.32962388],\n",
       "       [-0.51589715],\n",
       "       [-0.6266643 ],\n",
       "       [-0.37555188],\n",
       "       [-0.04145496],\n",
       "       [-0.29670253],\n",
       "       [-0.3770427 ],\n",
       "       [-0.03380069],\n",
       "       [-0.28932574],\n",
       "       [-0.44118848],\n",
       "       [-0.37785086],\n",
       "       [-0.06397761],\n",
       "       [-0.43387252],\n",
       "       [-0.12032729],\n",
       "       [-0.36022997],\n",
       "       [-0.26667163],\n",
       "       [-0.23500235],\n",
       "       [ 0.0042713 ],\n",
       "       [-0.3462353 ],\n",
       "       [-0.20838092],\n",
       "       [-0.49287635],\n",
       "       [-0.33186266],\n",
       "       [-0.20829011],\n",
       "       [-0.48015544],\n",
       "       [-0.34228492],\n",
       "       [-0.25859642],\n",
       "       [-0.4107947 ],\n",
       "       [-0.14103614],\n",
       "       [-0.1835302 ],\n",
       "       [-0.4608457 ],\n",
       "       [-0.17010643],\n",
       "       [-0.20884869],\n",
       "       [-0.31820124],\n",
       "       [-0.33453554],\n",
       "       [-0.43422347],\n",
       "       [-0.18936421],\n",
       "       [-0.3089106 ],\n",
       "       [-0.11791895],\n",
       "       [-0.4735755 ],\n",
       "       [ 0.13032307],\n",
       "       [-0.40687776],\n",
       "       [-0.23368268],\n",
       "       [-0.2632572 ],\n",
       "       [-0.40254077],\n",
       "       [-0.51560456],\n",
       "       [-0.15990393],\n",
       "       [-0.34787598],\n",
       "       [-0.42483783],\n",
       "       [ 0.20932901],\n",
       "       [-0.02258306],\n",
       "       [-0.32183155],\n",
       "       [-0.3372138 ],\n",
       "       [ 0.05521755],\n",
       "       [-0.2848818 ],\n",
       "       [-0.16240235],\n",
       "       [-0.37197605],\n",
       "       [-0.2963395 ],\n",
       "       [-0.22263855],\n",
       "       [-0.04596784],\n",
       "       [-0.311271  ],\n",
       "       [-0.48787796],\n",
       "       [-0.482158  ],\n",
       "       [-0.07562096],\n",
       "       [-0.29330593],\n",
       "       [-0.506248  ],\n",
       "       [-0.41601324],\n",
       "       [-0.30815548],\n",
       "       [-0.14801155],\n",
       "       [-0.28829527],\n",
       "       [-0.60154927],\n",
       "       [-0.10363793],\n",
       "       [ 0.19286446],\n",
       "       [-0.29194927],\n",
       "       [ 0.1799947 ],\n",
       "       [-0.55127174],\n",
       "       [-0.43455374],\n",
       "       [-0.046548  ],\n",
       "       [-0.21178274],\n",
       "       [ 0.12630178],\n",
       "       [-0.24786328],\n",
       "       [-0.2861271 ],\n",
       "       [-0.5133756 ],\n",
       "       [-0.16590688],\n",
       "       [-0.08291819],\n",
       "       [-0.0820049 ],\n",
       "       [-0.20486794],\n",
       "       [ 0.07547497],\n",
       "       [-0.21173605],\n",
       "       [-0.15592282],\n",
       "       [-0.20290276],\n",
       "       [-0.21095233],\n",
       "       [-0.37224692],\n",
       "       [-0.5739515 ],\n",
       "       [-0.09948268],\n",
       "       [-0.11072557],\n",
       "       [ 0.04305215],\n",
       "       [ 0.03014738],\n",
       "       [-0.42650977],\n",
       "       [-0.11712434],\n",
       "       [-0.34631062],\n",
       "       [ 0.21214706],\n",
       "       [-0.08311032],\n",
       "       [-0.6108824 ],\n",
       "       [ 0.08048622],\n",
       "       [-0.03582934],\n",
       "       [-0.10649274],\n",
       "       [-0.02630461],\n",
       "       [ 0.09191599],\n",
       "       [ 0.00267341],\n",
       "       [-0.11927056],\n",
       "       [-0.0932802 ],\n",
       "       [ 0.15403661],\n",
       "       [ 0.19828607],\n",
       "       [-0.16527303],\n",
       "       [-0.12183869],\n",
       "       [-0.69419247],\n",
       "       [ 0.06083138],\n",
       "       [-0.03184849],\n",
       "       [-0.31118175],\n",
       "       [-0.27478415],\n",
       "       [-0.22720228],\n",
       "       [-0.17319973],\n",
       "       [-0.23373789],\n",
       "       [-0.28414157],\n",
       "       [-0.24483104],\n",
       "       [-0.46897796],\n",
       "       [-0.21538736],\n",
       "       [-0.28512156],\n",
       "       [-0.22258873],\n",
       "       [-0.02552018],\n",
       "       [ 0.06626927],\n",
       "       [-0.15421683],\n",
       "       [ 0.14253023],\n",
       "       [-0.45564356],\n",
       "       [-0.06127626],\n",
       "       [-0.03161131],\n",
       "       [-0.38708222],\n",
       "       [-0.18318443],\n",
       "       [ 0.03977526],\n",
       "       [-0.22514626],\n",
       "       [-0.3272236 ],\n",
       "       [-0.5125517 ],\n",
       "       [-0.16015978],\n",
       "       [-0.22940403],\n",
       "       [-0.07128303],\n",
       "       [-0.5568899 ],\n",
       "       [-0.03978862],\n",
       "       [-0.06880855],\n",
       "       [-0.14108357],\n",
       "       [-0.30172315],\n",
       "       [ 0.12008917],\n",
       "       [-0.47299513],\n",
       "       [-0.33148783],\n",
       "       [-0.39035434],\n",
       "       [ 0.12457158],\n",
       "       [-0.1337245 ],\n",
       "       [-0.3130536 ],\n",
       "       [ 0.345878  ],\n",
       "       [-0.55070394],\n",
       "       [-0.07830579],\n",
       "       [-0.37665737],\n",
       "       [ 0.25880748],\n",
       "       [ 0.12087638],\n",
       "       [-0.26477966],\n",
       "       [ 0.1471411 ],\n",
       "       [-0.01207764],\n",
       "       [ 0.06000277],\n",
       "       [-0.24514113],\n",
       "       [ 0.02917884],\n",
       "       [-0.0534524 ],\n",
       "       [-0.19791794],\n",
       "       [-0.52789915],\n",
       "       [-0.21423902],\n",
       "       [-0.26971507],\n",
       "       [-0.31899458],\n",
       "       [-0.20065208],\n",
       "       [-0.19331488],\n",
       "       [-0.16611888],\n",
       "       [-0.00496896],\n",
       "       [-0.37385258],\n",
       "       [-0.2734564 ],\n",
       "       [-0.0586837 ],\n",
       "       [-0.02495529],\n",
       "       [-0.02620691],\n",
       "       [-0.02917465],\n",
       "       [-0.22658677],\n",
       "       [-0.49637693],\n",
       "       [-0.17278716],\n",
       "       [ 0.01158163],\n",
       "       [-0.21022697],\n",
       "       [-0.23946494],\n",
       "       [-0.3373009 ],\n",
       "       [-0.0900767 ],\n",
       "       [-0.19097683],\n",
       "       [-0.33834666],\n",
       "       [-0.3063518 ],\n",
       "       [ 0.00915503],\n",
       "       [-0.26177284],\n",
       "       [-0.17463505],\n",
       "       [-0.24713643],\n",
       "       [-0.3106725 ],\n",
       "       [-0.19289522],\n",
       "       [-0.06742487],\n",
       "       [-0.26605034],\n",
       "       [-0.2763393 ],\n",
       "       [-0.09541991],\n",
       "       [-0.0821804 ],\n",
       "       [-0.3369346 ],\n",
       "       [-0.31375057],\n",
       "       [-0.01516916],\n",
       "       [-0.27960736],\n",
       "       [-0.34309468],\n",
       "       [-0.22673677],\n",
       "       [-0.23781693],\n",
       "       [-0.13464108],\n",
       "       [-0.02646969],\n",
       "       [ 0.02776722],\n",
       "       [-0.26209813],\n",
       "       [-0.338165  ],\n",
       "       [-0.25304994],\n",
       "       [-0.15498503],\n",
       "       [-0.4099617 ],\n",
       "       [-0.2651758 ],\n",
       "       [-0.16260193],\n",
       "       [-0.32047677],\n",
       "       [-0.313628  ],\n",
       "       [-0.1129159 ],\n",
       "       [-0.08374374],\n",
       "       [ 0.23572552],\n",
       "       [-0.1378813 ],\n",
       "       [-0.32622963],\n",
       "       [ 0.15845509],\n",
       "       [-0.43642685],\n",
       "       [-0.34699905],\n",
       "       [-0.204666  ],\n",
       "       [-0.13440116],\n",
       "       [-0.52463055],\n",
       "       [ 0.03631757],\n",
       "       [-0.26039183],\n",
       "       [-0.5598936 ],\n",
       "       [-0.3263543 ],\n",
       "       [-0.23409994],\n",
       "       [-0.04858927],\n",
       "       [-0.3195008 ],\n",
       "       [-0.48650306],\n",
       "       [-0.20559739],\n",
       "       [-0.12250507],\n",
       "       [-0.33121914],\n",
       "       [-0.32943946],\n",
       "       [-0.01499739],\n",
       "       [-0.37665784],\n",
       "       [-0.12773027],\n",
       "       [-0.4607138 ],\n",
       "       [-0.12055123],\n",
       "       [ 0.00970531],\n",
       "       [-0.3322415 ],\n",
       "       [-0.4034474 ],\n",
       "       [-0.3465245 ],\n",
       "       [-0.3382927 ],\n",
       "       [-0.29129153],\n",
       "       [-0.10350978],\n",
       "       [-0.03946079],\n",
       "       [-0.39177954],\n",
       "       [-0.07834601],\n",
       "       [-0.02508146],\n",
       "       [-0.16370046],\n",
       "       [-0.27385244],\n",
       "       [-0.47952276],\n",
       "       [-0.33790046],\n",
       "       [ 0.12449832],\n",
       "       [-0.43835616],\n",
       "       [ 0.03432743],\n",
       "       [-0.45520332],\n",
       "       [-0.47715232],\n",
       "       [-0.34506053],\n",
       "       [-0.08849623],\n",
       "       [-0.41552746],\n",
       "       [-0.5827476 ],\n",
       "       [ 0.03318472],\n",
       "       [-0.30883622],\n",
       "       [-0.4868675 ],\n",
       "       [-0.1540419 ],\n",
       "       [-0.1004182 ],\n",
       "       [-0.44971773],\n",
       "       [-0.35788417],\n",
       "       [-0.3170247 ],\n",
       "       [-0.49270564],\n",
       "       [-0.25452206],\n",
       "       [-0.2812168 ],\n",
       "       [-0.2262537 ],\n",
       "       [ 0.05287356],\n",
       "       [-0.4317205 ],\n",
       "       [-0.02944058],\n",
       "       [-0.37365746],\n",
       "       [-0.31480134],\n",
       "       [-0.32739934],\n",
       "       [-0.54145676],\n",
       "       [-0.06145143],\n",
       "       [-0.34122863],\n",
       "       [-0.39081088],\n",
       "       [-0.17251338],\n",
       "       [-0.38995287],\n",
       "       [-0.20636438],\n",
       "       [-0.53034234],\n",
       "       [-0.46342784],\n",
       "       [-0.4426481 ],\n",
       "       [-0.03178011],\n",
       "       [-0.53182006],\n",
       "       [-0.28055248],\n",
       "       [-0.05062566],\n",
       "       [-0.27174962],\n",
       "       [-0.32558462],\n",
       "       [ 0.00975208],\n",
       "       [-0.24096711],\n",
       "       [-0.36071908],\n",
       "       [-0.42887607],\n",
       "       [-0.28593555],\n",
       "       [-0.26490757],\n",
       "       [-0.34485173],\n",
       "       [-0.20408906],\n",
       "       [-0.29550642],\n",
       "       [-0.2581265 ],\n",
       "       [-0.07722213],\n",
       "       [-0.07967156],\n",
       "       [-0.4505544 ],\n",
       "       [-0.48576242],\n",
       "       [-0.24030544],\n",
       "       [-0.10503621],\n",
       "       [-0.28137606],\n",
       "       [-0.4153403 ],\n",
       "       [-0.02820176],\n",
       "       [-0.11700455],\n",
       "       [ 0.05137902],\n",
       "       [-0.0028853 ],\n",
       "       [-0.3153957 ],\n",
       "       [-0.39531738],\n",
       "       [-0.41317022],\n",
       "       [-0.01861423],\n",
       "       [-0.33980787],\n",
       "       [-0.12584475],\n",
       "       [-0.24045646],\n",
       "       [-0.01636283],\n",
       "       [-0.20360488],\n",
       "       [-0.53654695],\n",
       "       [-0.1013636 ],\n",
       "       [-0.5742891 ],\n",
       "       [-0.09321067],\n",
       "       [-0.2623383 ],\n",
       "       [-0.16714576],\n",
       "       [-0.31864858],\n",
       "       [-0.18088527],\n",
       "       [-0.21725254],\n",
       "       [-0.11936292],\n",
       "       [-0.09710401],\n",
       "       [-0.41953236],\n",
       "       [-0.260109  ],\n",
       "       [-0.17997785],\n",
       "       [-0.34375915],\n",
       "       [ 0.01262331],\n",
       "       [-0.30825114],\n",
       "       [-0.5195546 ],\n",
       "       [-0.25898346],\n",
       "       [-0.05093936],\n",
       "       [-0.15289302],\n",
       "       [-0.28073943],\n",
       "       [-0.3776971 ],\n",
       "       [-0.26268455],\n",
       "       [-0.01654544],\n",
       "       [-0.18971586],\n",
       "       [-0.08181293],\n",
       "       [-0.18500037],\n",
       "       [-0.02503321],\n",
       "       [-0.02877683],\n",
       "       [-0.12011103],\n",
       "       [-0.51917493],\n",
       "       [-0.016725  ],\n",
       "       [-0.4656891 ],\n",
       "       [-0.35062945],\n",
       "       [-0.02145662],\n",
       "       [-0.12879382],\n",
       "       [-0.37085664],\n",
       "       [-0.14001837],\n",
       "       [-0.24319996],\n",
       "       [-0.04054483],\n",
       "       [-0.2843358 ],\n",
       "       [-0.12421667],\n",
       "       [-0.09801013],\n",
       "       [-0.08683645],\n",
       "       [-0.36889684],\n",
       "       [-0.4408434 ],\n",
       "       [-0.17609507],\n",
       "       [-0.13389689],\n",
       "       [-0.04442222],\n",
       "       [-0.11064904],\n",
       "       [-0.41577983],\n",
       "       [-0.23418938],\n",
       "       [-0.08171726],\n",
       "       [-0.00884769],\n",
       "       [-0.11907224],\n",
       "       [-0.3358363 ],\n",
       "       [-0.0741711 ],\n",
       "       [-0.21990387],\n",
       "       [-0.07979885],\n",
       "       [-0.5061183 ],\n",
       "       [-0.29823261],\n",
       "       [-0.01518495],\n",
       "       [-0.1314982 ],\n",
       "       [-0.00791808],\n",
       "       [-0.3480699 ],\n",
       "       [-0.5107197 ],\n",
       "       [-0.03575849],\n",
       "       [-0.23297365],\n",
       "       [ 0.00756471],\n",
       "       [-0.2706745 ],\n",
       "       [-0.37357673],\n",
       "       [-0.23180768],\n",
       "       [-0.03933738],\n",
       "       [-0.05077547],\n",
       "       [-0.4829626 ],\n",
       "       [-0.24039614],\n",
       "       [-0.41321218],\n",
       "       [-0.23480003],\n",
       "       [-0.27593175],\n",
       "       [-0.44838673],\n",
       "       [-0.01593117],\n",
       "       [-0.1759624 ],\n",
       "       [-0.44517484],\n",
       "       [-0.37483272],\n",
       "       [-0.48100188],\n",
       "       [-0.17042835],\n",
       "       [ 0.04202986],\n",
       "       [-0.508499  ],\n",
       "       [-0.07215007],\n",
       "       [-0.5419376 ],\n",
       "       [-0.10489283],\n",
       "       [-0.04433592],\n",
       "       [-0.07470477],\n",
       "       [-0.0558603 ],\n",
       "       [-0.28979802],\n",
       "       [-0.11320232],\n",
       "       [-0.23664902],\n",
       "       [-0.5104289 ],\n",
       "       [-0.49149612],\n",
       "       [-0.0049746 ],\n",
       "       [-0.25486055],\n",
       "       [-0.3387876 ],\n",
       "       [-0.07551535],\n",
       "       [-0.31001776],\n",
       "       [-0.28310615],\n",
       "       [-0.37721416],\n",
       "       [-0.41817358],\n",
       "       [-0.50084704],\n",
       "       [-0.27887717],\n",
       "       [-0.19672985],\n",
       "       [-0.0469423 ],\n",
       "       [-0.2964482 ],\n",
       "       [-0.07884873],\n",
       "       [-0.12458339],\n",
       "       [-0.46486184],\n",
       "       [-0.50691307],\n",
       "       [-0.2847927 ],\n",
       "       [ 0.02008841],\n",
       "       [-0.06203183],\n",
       "       [-0.36539   ],\n",
       "       [-0.261451  ],\n",
       "       [-0.09836525],\n",
       "       [-0.26121864],\n",
       "       [-0.45642883],\n",
       "       [-0.35470176],\n",
       "       [ 0.06991093],\n",
       "       [ 0.00596832],\n",
       "       [-0.2882831 ],\n",
       "       [-0.057184  ],\n",
       "       [-0.04088503],\n",
       "       [-0.45005158],\n",
       "       [-0.42104912],\n",
       "       [-0.30516422],\n",
       "       [-0.03769981],\n",
       "       [-0.2984808 ],\n",
       "       [-0.06095648],\n",
       "       [-0.1999882 ],\n",
       "       [-0.5974697 ],\n",
       "       [-0.24870627],\n",
       "       [-0.02774611],\n",
       "       [-0.07381693],\n",
       "       [-0.05053686],\n",
       "       [-0.24955189],\n",
       "       [-0.0784492 ],\n",
       "       [-0.28914478],\n",
       "       [-0.44652045],\n",
       "       [-0.13752195],\n",
       "       [-0.11384068],\n",
       "       [-0.22180869],\n",
       "       [-0.5719069 ],\n",
       "       [-0.02830455],\n",
       "       [-0.19206895],\n",
       "       [-0.23538785],\n",
       "       [-0.30564263],\n",
       "       [-0.02474086],\n",
       "       [-0.02612351],\n",
       "       [-0.4876356 ],\n",
       "       [-0.18691677],\n",
       "       [-0.52663577],\n",
       "       [-0.06686714],\n",
       "       [-0.05590164],\n",
       "       [-0.32325727],\n",
       "       [-0.3190031 ],\n",
       "       [-0.03620075],\n",
       "       [-0.38400102],\n",
       "       [-0.03369925],\n",
       "       [-0.30676258],\n",
       "       [-0.27340811],\n",
       "       [-0.0991949 ],\n",
       "       [-0.39108396],\n",
       "       [-0.30949277],\n",
       "       [-0.1714079 ],\n",
       "       [-0.5155889 ],\n",
       "       [-0.4125703 ],\n",
       "       [-0.4892196 ],\n",
       "       [-0.02099101],\n",
       "       [-0.1351465 ],\n",
       "       [-0.1201563 ],\n",
       "       [-0.2084095 ],\n",
       "       [-0.05222904],\n",
       "       [-0.4176193 ],\n",
       "       [-0.10791107],\n",
       "       [-0.00538102],\n",
       "       [-0.43896407],\n",
       "       [-0.15541665],\n",
       "       [-0.07622169],\n",
       "       [-0.2953375 ],\n",
       "       [-0.46863937],\n",
       "       [-0.53452253],\n",
       "       [-0.03155117],\n",
       "       [-0.29103637],\n",
       "       [-0.04718675],\n",
       "       [-0.28117436],\n",
       "       [-0.34432924],\n",
       "       [-0.35424644],\n",
       "       [ 0.01723532],\n",
       "       [-0.04028694],\n",
       "       [-0.25335157],\n",
       "       [-0.62618786],\n",
       "       [-0.3554913 ],\n",
       "       [ 0.1614365 ],\n",
       "       [-0.01971615],\n",
       "       [-0.47163525],\n",
       "       [-0.21721928],\n",
       "       [-0.57188   ],\n",
       "       [-0.51163244],\n",
       "       [-0.04638125],\n",
       "       [-0.22401501],\n",
       "       [-0.37219667],\n",
       "       [-0.17155397],\n",
       "       [-0.42861965],\n",
       "       [-0.06328569],\n",
       "       [-0.06113195],\n",
       "       [-0.37594268],\n",
       "       [-0.19255681],\n",
       "       [-0.04244475],\n",
       "       [-0.30587035],\n",
       "       [-0.5422931 ],\n",
       "       [-0.5139555 ],\n",
       "       [-0.04481252],\n",
       "       [-0.34590608],\n",
       "       [-0.5688081 ],\n",
       "       [ 0.17352708],\n",
       "       [-0.30785215],\n",
       "       [-0.07063697],\n",
       "       [-0.41310287],\n",
       "       [-0.448638  ],\n",
       "       [-0.1581885 ],\n",
       "       [-0.03354637],\n",
       "       [-0.4326962 ],\n",
       "       [-0.39129043],\n",
       "       [-0.43928728],\n",
       "       [-0.26235726],\n",
       "       [-0.04060941],\n",
       "       [-0.26626453],\n",
       "       [-0.05713134],\n",
       "       [-0.07763677],\n",
       "       [-0.34277216],\n",
       "       [-0.25399375],\n",
       "       [-0.13398935],\n",
       "       [-0.3782374 ],\n",
       "       [-0.41677248],\n",
       "       [-0.31070778],\n",
       "       [-0.16121703],\n",
       "       [-0.16290487],\n",
       "       [-0.3268122 ],\n",
       "       [-0.19951487],\n",
       "       [-0.04011973],\n",
       "       [-0.28063887],\n",
       "       [-0.14861517],\n",
       "       [-0.06425721],\n",
       "       [-0.41391373],\n",
       "       [-0.10047261],\n",
       "       [-0.04015091],\n",
       "       [-0.36323214],\n",
       "       [-0.04221369],\n",
       "       [-0.12357482],\n",
       "       [-0.03838686],\n",
       "       [-0.03657378],\n",
       "       [-0.17131452],\n",
       "       [-0.31877887],\n",
       "       [-0.03624762],\n",
       "       [-0.4552645 ],\n",
       "       [-0.03242117],\n",
       "       [-0.368697  ],\n",
       "       [-0.06773443],\n",
       "       [-0.3117934 ],\n",
       "       [-0.04998372],\n",
       "       [-0.05163854],\n",
       "       [-0.22468778],\n",
       "       [-0.06066193],\n",
       "       [-0.05700219],\n",
       "       [-0.34066278],\n",
       "       [-0.32609946],\n",
       "       [-0.5719745 ],\n",
       "       [-0.06068085],\n",
       "       [-0.09376623],\n",
       "       [-0.05777471],\n",
       "       [-0.4311449 ],\n",
       "       [-0.4505909 ],\n",
       "       [-0.2715475 ],\n",
       "       [-0.09930734],\n",
       "       [-0.03893866],\n",
       "       [-0.35214663],\n",
       "       [-0.2032522 ],\n",
       "       [-0.35735363],\n",
       "       [-0.02410099],\n",
       "       [-0.399669  ],\n",
       "       [-0.079662  ],\n",
       "       [-0.12686282],\n",
       "       [-0.03913153],\n",
       "       [-0.4452514 ],\n",
       "       [-0.02414076],\n",
       "       [-0.2791924 ],\n",
       "       [-0.19568935],\n",
       "       [-0.2986532 ],\n",
       "       [-0.06055822],\n",
       "       [-0.02475642],\n",
       "       [-0.10060748],\n",
       "       [-0.24501711],\n",
       "       [-0.45832807],\n",
       "       [-0.02457562],\n",
       "       [-0.14026679],\n",
       "       [-0.20663248],\n",
       "       [-0.14818498],\n",
       "       [-0.28529367],\n",
       "       [-0.01024162],\n",
       "       [-0.06773692],\n",
       "       [-0.35510492],\n",
       "       [-0.24616206],\n",
       "       [-0.37922162],\n",
       "       [-0.13004571],\n",
       "       [-0.3026551 ],\n",
       "       [ 0.08891828],\n",
       "       [-0.13965403],\n",
       "       [-0.4205943 ],\n",
       "       [-0.1016342 ],\n",
       "       [-0.25369167],\n",
       "       [-0.08542056],\n",
       "       [-0.15154235],\n",
       "       [-0.2748837 ],\n",
       "       [-0.04041165],\n",
       "       [-0.2340666 ],\n",
       "       [-0.06556748],\n",
       "       [-0.06976245],\n",
       "       [-0.5995993 ],\n",
       "       [-0.47625518],\n",
       "       [-0.27208793],\n",
       "       [-0.1020693 ],\n",
       "       [-0.19745402],\n",
       "       [-0.1006049 ],\n",
       "       [-0.0335285 ],\n",
       "       [-0.32064152],\n",
       "       [-0.07685257],\n",
       "       [-0.02245831],\n",
       "       [-0.53476596],\n",
       "       [-0.0100311 ],\n",
       "       [-0.30439466],\n",
       "       [-0.01410603],\n",
       "       [-0.04055111],\n",
       "       [-0.09985749],\n",
       "       [-0.4274815 ],\n",
       "       [-0.05425374],\n",
       "       [-0.11341488],\n",
       "       [-0.08812409],\n",
       "       [-0.03522399],\n",
       "       [-0.13881233],\n",
       "       [-0.051971  ],\n",
       "       [-0.08690844],\n",
       "       [-0.07607154],\n",
       "       [-0.00686587],\n",
       "       [-0.09040795],\n",
       "       [-0.33579192],\n",
       "       [-0.08132703],\n",
       "       [ 0.04105245],\n",
       "       [-0.0707907 ],\n",
       "       [-0.37471926],\n",
       "       [-0.03891544],\n",
       "       [-0.04093707],\n",
       "       [-0.13717215],\n",
       "       [-0.03028118],\n",
       "       [-0.01915007],\n",
       "       [-0.06138153],\n",
       "       [-0.02438331],\n",
       "       [-0.15274581],\n",
       "       [-0.3657802 ],\n",
       "       [-0.07105613],\n",
       "       [-0.04249269],\n",
       "       [-0.1536992 ],\n",
       "       [-0.34756672],\n",
       "       [-0.07876577],\n",
       "       [-0.2988394 ],\n",
       "       [-0.05418849],\n",
       "       [-0.17285486],\n",
       "       [-0.06455215],\n",
       "       [-0.34767044],\n",
       "       [-0.32111424],\n",
       "       [-0.40729538],\n",
       "       [-0.16339222],\n",
       "       [-0.18021585],\n",
       "       [-0.32064497],\n",
       "       [-0.35284874],\n",
       "       [-0.05669848],\n",
       "       [-0.2802403 ],\n",
       "       [-0.06226501],\n",
       "       [-0.35125774],\n",
       "       [-0.35436934],\n",
       "       [-0.17102857],\n",
       "       [-0.3632273 ],\n",
       "       [-0.07815845],\n",
       "       [-0.30052602],\n",
       "       [-0.32743222],\n",
       "       [-0.1566303 ],\n",
       "       [-0.16393337],\n",
       "       [-0.05732917],\n",
       "       [-0.17358284],\n",
       "       [-0.22585265],\n",
       "       [-0.20016402],\n",
       "       [-0.23044445],\n",
       "       [-0.23757319],\n",
       "       [-0.10237306],\n",
       "       [-0.23504944],\n",
       "       [-0.22651403],\n",
       "       [-0.22918397],\n",
       "       [-0.22730036],\n",
       "       [-0.08304323],\n",
       "       [-0.08004671],\n",
       "       [-0.08257589],\n",
       "       [-0.10507337]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_predictions = mejor_modelo.predict(X_f)\n",
    "display(scaled_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03749761,  0.07719515, -0.28504974, -0.16752963,  0.00191359,\n",
       "       -0.46567208, -0.5009722 , -0.50684524,  0.08870511, -0.2601701 ,\n",
       "       -0.35600978, -0.5058283 , -0.24785617, -0.13520795, -0.28447428,\n",
       "       -0.52350885, -0.49021673, -0.45785466, -0.32442707, -0.38365418,\n",
       "       -0.3616345 , -0.1745336 , -0.1690569 , -0.40086722, -0.3435718 ,\n",
       "       -0.2885229 , -0.19864361, -0.32962388, -0.51589715, -0.6266643 ,\n",
       "       -0.37555188, -0.04145496, -0.29670253, -0.3770427 , -0.03380069,\n",
       "       -0.28932574, -0.44118848, -0.37785086, -0.06397761, -0.43387252,\n",
       "       -0.12032729, -0.36022997, -0.26667163, -0.23500235,  0.0042713 ,\n",
       "       -0.3462353 , -0.20838092, -0.49287635, -0.33186266, -0.20829011,\n",
       "       -0.48015544, -0.34228492, -0.25859642, -0.4107947 , -0.14103614,\n",
       "       -0.1835302 , -0.4608457 , -0.17010643, -0.20884869, -0.31820124,\n",
       "       -0.33453554, -0.43422347, -0.18936421, -0.3089106 , -0.11791895,\n",
       "       -0.4735755 ,  0.13032307, -0.40687776, -0.23368268, -0.2632572 ,\n",
       "       -0.40254077, -0.51560456, -0.15990393, -0.34787598, -0.42483783,\n",
       "        0.20932901, -0.02258306, -0.32183155, -0.3372138 ,  0.05521755,\n",
       "       -0.2848818 , -0.16240235, -0.37197605, -0.2963395 , -0.22263855,\n",
       "       -0.04596784, -0.311271  , -0.48787796, -0.482158  , -0.07562096,\n",
       "       -0.29330593, -0.506248  , -0.41601324, -0.30815548, -0.14801155,\n",
       "       -0.28829527, -0.60154927, -0.10363793,  0.19286446, -0.29194927,\n",
       "        0.1799947 , -0.55127174, -0.43455374, -0.046548  , -0.21178274,\n",
       "        0.12630178, -0.24786328, -0.2861271 , -0.5133756 , -0.16590688,\n",
       "       -0.08291819, -0.0820049 , -0.20486794,  0.07547497, -0.21173605,\n",
       "       -0.15592282, -0.20290276, -0.21095233, -0.37224692, -0.5739515 ,\n",
       "       -0.09948268, -0.11072557,  0.04305215,  0.03014738, -0.42650977,\n",
       "       -0.11712434, -0.34631062,  0.21214706, -0.08311032, -0.6108824 ,\n",
       "        0.08048622, -0.03582934, -0.10649274, -0.02630461,  0.09191599,\n",
       "        0.00267341, -0.11927056, -0.0932802 ,  0.15403661,  0.19828607,\n",
       "       -0.16527303, -0.12183869, -0.69419247,  0.06083138, -0.03184849,\n",
       "       -0.31118175, -0.27478415, -0.22720228, -0.17319973, -0.23373789,\n",
       "       -0.28414157, -0.24483104, -0.46897796, -0.21538736, -0.28512156,\n",
       "       -0.22258873, -0.02552018,  0.06626927, -0.15421683,  0.14253023,\n",
       "       -0.45564356, -0.06127626, -0.03161131, -0.38708222, -0.18318443,\n",
       "        0.03977526, -0.22514626, -0.3272236 , -0.5125517 , -0.16015978,\n",
       "       -0.22940403, -0.07128303, -0.5568899 , -0.03978862, -0.06880855,\n",
       "       -0.14108357, -0.30172315,  0.12008917, -0.47299513, -0.33148783,\n",
       "       -0.39035434,  0.12457158, -0.1337245 , -0.3130536 ,  0.345878  ,\n",
       "       -0.55070394, -0.07830579, -0.37665737,  0.25880748,  0.12087638,\n",
       "       -0.26477966,  0.1471411 , -0.01207764,  0.06000277, -0.24514113,\n",
       "        0.02917884, -0.0534524 , -0.19791794, -0.52789915, -0.21423902,\n",
       "       -0.26971507, -0.31899458, -0.20065208, -0.19331488, -0.16611888,\n",
       "       -0.00496896, -0.37385258, -0.2734564 , -0.0586837 , -0.02495529,\n",
       "       -0.02620691, -0.02917465, -0.22658677, -0.49637693, -0.17278716,\n",
       "        0.01158163, -0.21022697, -0.23946494, -0.3373009 , -0.0900767 ,\n",
       "       -0.19097683, -0.33834666, -0.3063518 ,  0.00915503, -0.26177284,\n",
       "       -0.17463505, -0.24713643, -0.3106725 , -0.19289522, -0.06742487,\n",
       "       -0.26605034, -0.2763393 , -0.09541991, -0.0821804 , -0.3369346 ,\n",
       "       -0.31375057, -0.01516916, -0.27960736, -0.34309468, -0.22673677,\n",
       "       -0.23781693, -0.13464108, -0.02646969,  0.02776722, -0.26209813,\n",
       "       -0.338165  , -0.25304994, -0.15498503, -0.4099617 , -0.2651758 ,\n",
       "       -0.16260193, -0.32047677, -0.313628  , -0.1129159 , -0.08374374,\n",
       "        0.23572552, -0.1378813 , -0.32622963,  0.15845509, -0.43642685,\n",
       "       -0.34699905, -0.204666  , -0.13440116, -0.52463055,  0.03631757,\n",
       "       -0.26039183, -0.5598936 , -0.3263543 , -0.23409994, -0.04858927,\n",
       "       -0.3195008 , -0.48650306, -0.20559739, -0.12250507, -0.33121914,\n",
       "       -0.32943946, -0.01499739, -0.37665784, -0.12773027, -0.4607138 ,\n",
       "       -0.12055123,  0.00970531, -0.3322415 , -0.4034474 , -0.3465245 ,\n",
       "       -0.3382927 , -0.29129153, -0.10350978, -0.03946079, -0.39177954,\n",
       "       -0.07834601, -0.02508146, -0.16370046, -0.27385244, -0.47952276,\n",
       "       -0.33790046,  0.12449832, -0.43835616,  0.03432743, -0.45520332,\n",
       "       -0.47715232, -0.34506053, -0.08849623, -0.41552746, -0.5827476 ,\n",
       "        0.03318472, -0.30883622, -0.4868675 , -0.1540419 , -0.1004182 ,\n",
       "       -0.44971773, -0.35788417, -0.3170247 , -0.49270564, -0.25452206,\n",
       "       -0.2812168 , -0.2262537 ,  0.05287356, -0.4317205 , -0.02944058,\n",
       "       -0.37365746, -0.31480134, -0.32739934, -0.54145676, -0.06145143,\n",
       "       -0.34122863, -0.39081088, -0.17251338, -0.38995287, -0.20636438,\n",
       "       -0.53034234, -0.46342784, -0.4426481 , -0.03178011, -0.53182006,\n",
       "       -0.28055248, -0.05062566, -0.27174962, -0.32558462,  0.00975208,\n",
       "       -0.24096711, -0.36071908, -0.42887607, -0.28593555, -0.26490757,\n",
       "       -0.34485173, -0.20408906, -0.29550642, -0.2581265 , -0.07722213,\n",
       "       -0.07967156, -0.4505544 , -0.48576242, -0.24030544, -0.10503621,\n",
       "       -0.28137606, -0.4153403 , -0.02820176, -0.11700455,  0.05137902,\n",
       "       -0.0028853 , -0.3153957 , -0.39531738, -0.41317022, -0.01861423,\n",
       "       -0.33980787, -0.12584475, -0.24045646, -0.01636283, -0.20360488,\n",
       "       -0.53654695, -0.1013636 , -0.5742891 , -0.09321067, -0.2623383 ,\n",
       "       -0.16714576, -0.31864858, -0.18088527, -0.21725254, -0.11936292,\n",
       "       -0.09710401, -0.41953236, -0.260109  , -0.17997785, -0.34375915,\n",
       "        0.01262331, -0.30825114, -0.5195546 , -0.25898346, -0.05093936,\n",
       "       -0.15289302, -0.28073943, -0.3776971 , -0.26268455, -0.01654544,\n",
       "       -0.18971586, -0.08181293, -0.18500037, -0.02503321, -0.02877683,\n",
       "       -0.12011103, -0.51917493, -0.016725  , -0.4656891 , -0.35062945,\n",
       "       -0.02145662, -0.12879382, -0.37085664, -0.14001837, -0.24319996,\n",
       "       -0.04054483, -0.2843358 , -0.12421667, -0.09801013, -0.08683645,\n",
       "       -0.36889684, -0.4408434 , -0.17609507, -0.13389689, -0.04442222,\n",
       "       -0.11064904, -0.41577983, -0.23418938, -0.08171726, -0.00884769,\n",
       "       -0.11907224, -0.3358363 , -0.0741711 , -0.21990387, -0.07979885,\n",
       "       -0.5061183 , -0.29823261, -0.01518495, -0.1314982 , -0.00791808,\n",
       "       -0.3480699 , -0.5107197 , -0.03575849, -0.23297365,  0.00756471,\n",
       "       -0.2706745 , -0.37357673, -0.23180768, -0.03933738, -0.05077547,\n",
       "       -0.4829626 , -0.24039614, -0.41321218, -0.23480003, -0.27593175,\n",
       "       -0.44838673, -0.01593117, -0.1759624 , -0.44517484, -0.37483272,\n",
       "       -0.48100188, -0.17042835,  0.04202986, -0.508499  , -0.07215007,\n",
       "       -0.5419376 , -0.10489283, -0.04433592, -0.07470477, -0.0558603 ,\n",
       "       -0.28979802, -0.11320232, -0.23664902, -0.5104289 , -0.49149612,\n",
       "       -0.0049746 , -0.25486055, -0.3387876 , -0.07551535, -0.31001776,\n",
       "       -0.28310615, -0.37721416, -0.41817358, -0.50084704, -0.27887717,\n",
       "       -0.19672985, -0.0469423 , -0.2964482 , -0.07884873, -0.12458339,\n",
       "       -0.46486184, -0.50691307, -0.2847927 ,  0.02008841, -0.06203183,\n",
       "       -0.36539   , -0.261451  , -0.09836525, -0.26121864, -0.45642883,\n",
       "       -0.35470176,  0.06991093,  0.00596832, -0.2882831 , -0.057184  ,\n",
       "       -0.04088503, -0.45005158, -0.42104912, -0.30516422, -0.03769981,\n",
       "       -0.2984808 , -0.06095648, -0.1999882 , -0.5974697 , -0.24870627,\n",
       "       -0.02774611, -0.07381693, -0.05053686, -0.24955189, -0.0784492 ,\n",
       "       -0.28914478, -0.44652045, -0.13752195, -0.11384068, -0.22180869,\n",
       "       -0.5719069 , -0.02830455, -0.19206895, -0.23538785, -0.30564263,\n",
       "       -0.02474086, -0.02612351, -0.4876356 , -0.18691677, -0.52663577,\n",
       "       -0.06686714, -0.05590164, -0.32325727, -0.3190031 , -0.03620075,\n",
       "       -0.38400102, -0.03369925, -0.30676258, -0.27340811, -0.0991949 ,\n",
       "       -0.39108396, -0.30949277, -0.1714079 , -0.5155889 , -0.4125703 ,\n",
       "       -0.4892196 , -0.02099101, -0.1351465 , -0.1201563 , -0.2084095 ,\n",
       "       -0.05222904, -0.4176193 , -0.10791107, -0.00538102, -0.43896407,\n",
       "       -0.15541665, -0.07622169, -0.2953375 , -0.46863937, -0.53452253,\n",
       "       -0.03155117, -0.29103637, -0.04718675, -0.28117436, -0.34432924,\n",
       "       -0.35424644,  0.01723532, -0.04028694, -0.25335157, -0.62618786,\n",
       "       -0.3554913 ,  0.1614365 , -0.01971615, -0.47163525, -0.21721928,\n",
       "       -0.57188   , -0.51163244, -0.04638125, -0.22401501, -0.37219667,\n",
       "       -0.17155397, -0.42861965, -0.06328569, -0.06113195, -0.37594268,\n",
       "       -0.19255681, -0.04244475, -0.30587035, -0.5422931 , -0.5139555 ,\n",
       "       -0.04481252, -0.34590608, -0.5688081 ,  0.17352708, -0.30785215,\n",
       "       -0.07063697, -0.41310287, -0.448638  , -0.1581885 , -0.03354637,\n",
       "       -0.4326962 , -0.39129043, -0.43928728, -0.26235726, -0.04060941,\n",
       "       -0.26626453, -0.05713134, -0.07763677, -0.34277216, -0.25399375,\n",
       "       -0.13398935, -0.3782374 , -0.41677248, -0.31070778, -0.16121703,\n",
       "       -0.16290487, -0.3268122 , -0.19951487, -0.04011973, -0.28063887,\n",
       "       -0.14861517, -0.06425721, -0.41391373, -0.10047261, -0.04015091,\n",
       "       -0.36323214, -0.04221369, -0.12357482, -0.03838686, -0.03657378,\n",
       "       -0.17131452, -0.31877887, -0.03624762, -0.4552645 , -0.03242117,\n",
       "       -0.368697  , -0.06773443, -0.3117934 , -0.04998372, -0.05163854,\n",
       "       -0.22468778, -0.06066193, -0.05700219, -0.34066278, -0.32609946,\n",
       "       -0.5719745 , -0.06068085, -0.09376623, -0.05777471, -0.4311449 ,\n",
       "       -0.4505909 , -0.2715475 , -0.09930734, -0.03893866, -0.35214663,\n",
       "       -0.2032522 , -0.35735363, -0.02410099, -0.399669  , -0.079662  ,\n",
       "       -0.12686282, -0.03913153, -0.4452514 , -0.02414076, -0.2791924 ,\n",
       "       -0.19568935, -0.2986532 , -0.06055822, -0.02475642, -0.10060748,\n",
       "       -0.24501711, -0.45832807, -0.02457562, -0.14026679, -0.20663248,\n",
       "       -0.14818498, -0.28529367, -0.01024162, -0.06773692, -0.35510492,\n",
       "       -0.24616206, -0.37922162, -0.13004571, -0.3026551 ,  0.08891828,\n",
       "       -0.13965403, -0.4205943 , -0.1016342 , -0.25369167, -0.08542056,\n",
       "       -0.15154235, -0.2748837 , -0.04041165, -0.2340666 , -0.06556748,\n",
       "       -0.06976245, -0.5995993 , -0.47625518, -0.27208793, -0.1020693 ,\n",
       "       -0.19745402, -0.1006049 , -0.0335285 , -0.32064152, -0.07685257,\n",
       "       -0.02245831, -0.53476596, -0.0100311 , -0.30439466, -0.01410603,\n",
       "       -0.04055111, -0.09985749, -0.4274815 , -0.05425374, -0.11341488,\n",
       "       -0.08812409, -0.03522399, -0.13881233, -0.051971  , -0.08690844,\n",
       "       -0.07607154, -0.00686587, -0.09040795, -0.33579192, -0.08132703,\n",
       "        0.04105245, -0.0707907 , -0.37471926, -0.03891544, -0.04093707,\n",
       "       -0.13717215, -0.03028118, -0.01915007, -0.06138153, -0.02438331,\n",
       "       -0.15274581, -0.3657802 , -0.07105613, -0.04249269, -0.1536992 ,\n",
       "       -0.34756672, -0.07876577, -0.2988394 , -0.05418849, -0.17285486,\n",
       "       -0.06455215, -0.34767044, -0.32111424, -0.40729538, -0.16339222,\n",
       "       -0.18021585, -0.32064497, -0.35284874, -0.05669848, -0.2802403 ,\n",
       "       -0.06226501, -0.35125774, -0.35436934, -0.17102857, -0.3632273 ,\n",
       "       -0.07815845, -0.30052602, -0.32743222, -0.1566303 , -0.16393337,\n",
       "       -0.05732917, -0.17358284, -0.22585265, -0.20016402, -0.23044445,\n",
       "       -0.23757319, -0.10237306, -0.23504944, -0.22651403, -0.22918397,\n",
       "       -0.22730036, -0.08304323, -0.08004671, -0.08257589, -0.10507337],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_predictions_1d =  scaled_predictions.reshape(-1)\n",
    "display(scaled_predictions_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las predicciones han sido generadas y guardadas en predictions.csv después de aplicar la inversa de los scalers.\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "    'product_id': product_ids,\n",
    "    'predicted_y': scaled_predictions_1d\n",
    "})\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame predictions_df\n",
    "for index, row in predictions_df.iterrows():\n",
    "    # Obtener el ID del producto y la predicción escalada para este producto\n",
    "    product_id = row['product_id']\n",
    "    scaled_prediction = row['predicted_y']\n",
    "    \n",
    "    # Obtener el escalador correspondiente a 'predicted_y' para este producto\n",
    "    scaler = scalers['y'][product_id]\n",
    "    \n",
    "    # Aplicar la inversa del escalador a la predicción 'predicted_y' para este producto\n",
    "    inverse_scaled_prediction = scaler.inverse_transform([[scaled_prediction]])[0][0]\n",
    "    \n",
    "    # Reemplazar la predicción escalada con la predicción invertida en el DataFrame final\n",
    "    predictions_df.at[index, 'predicted_y'] = inverse_scaled_prediction\n",
    "\n",
    "# Guardar el DataFrame final con las predicciones invertidas\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print('Todas las predicciones han sido generadas y guardadas en predictions.csv después de aplicar la inversa de los scalers.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
