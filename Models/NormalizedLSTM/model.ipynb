{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from skopt import BayesSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.metrics import MeanSquaredError\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization\n",
    "from skopt.space import Categorical\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.read_csv('../../Datasets/final_dataset.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>y</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>stock_final</th>\n",
       "      <th>close_quarter</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>479</td>\n",
       "      <td>937.72717</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201702</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>833.72187</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201703</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>509</td>\n",
       "      <td>1330.74697</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201704</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>1132.94430</td>\n",
       "      <td>1069.96130</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201705</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>701</td>\n",
       "      <td>1550.68936</td>\n",
       "      <td>1502.20132</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   periodo  product_id  plan_precios_cuidados  cust_request_qty  \\\n",
       "0   201701       20001                      0               479   \n",
       "1   201702       20001                      0               432   \n",
       "2   201703       20001                      0               509   \n",
       "3   201704       20001                      0               279   \n",
       "4   201705       20001                      0               701   \n",
       "\n",
       "   cust_request_tn           y cat1         cat2     cat3  brand  sku_size  \\\n",
       "0        937.72717   934.77222   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "1        833.72187   798.01620   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "2       1330.74697  1303.35771   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "3       1132.94430  1069.96130   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "4       1550.68936  1502.20132   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "\n",
       "   stock_final  close_quarter  age  \n",
       "0          NaN              0    0  \n",
       "1          NaN              0    1  \n",
       "2          NaN              1    2  \n",
       "3          NaN              0    3  \n",
       "4          NaN              0    4  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['plan_precios_cuidados', 'cust_request_qty', 'cust_request_tn', 'close_quarter', 'cat1', 'cat2', 'cat3', 'close_quarter', 'y']\n",
    "non_scalable_columns = ['cat1', 'cat2', 'cat3', 'plan_precios_cuidados', 'close_quarter']\n",
    "n_features = len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['cat1', 'cat2', 'cat3']\n",
    "\n",
    "# Transformar las columnas categóricas en numéricas\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    final_dataset[col] = le.fit_transform(final_dataset[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x2dea54fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped = final_dataset.groupby(['product_id', 'cat1', 'cat2', 'cat3'])\n",
    "display(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {col: {} for col in columns}\n",
    "scaled_data_list = []\n",
    "\n",
    "for (product_id, _, _, _ ), group in grouped:\n",
    "    scaled_group = group.copy()\n",
    "    for col in columns:\n",
    "        if col not in non_scalable_columns:\n",
    "            scaler = StandardScaler()\n",
    "            scaled_group[col] = scaler.fit_transform(group[[col]])\n",
    "            scalers[col][product_id] = scaler\n",
    "    scaled_data_list.append(scaled_group)\n",
    "\n",
    "# Combinar todos los datos escalados en un solo DataFrame\n",
    "scaled_data = pd.concat(scaled_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>close_quarter</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>close_quarter</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.461891</td>\n",
       "      <td>-1.704215</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.576908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.046911</td>\n",
       "      <td>-2.039835</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.042103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.786658</td>\n",
       "      <td>-0.435961</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.323111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.703222</td>\n",
       "      <td>-1.074260</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.117043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.865166</td>\n",
       "      <td>0.273781</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21615</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.652507</td>\n",
       "      <td>-0.792584</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.792584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21616</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.268679</td>\n",
       "      <td>-0.649760</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.649760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21617</th>\n",
       "      <td>0</td>\n",
       "      <td>0.115148</td>\n",
       "      <td>-0.595870</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.595870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21618</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.012794</td>\n",
       "      <td>-0.290890</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.290890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21619</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.036335</td>\n",
       "      <td>-0.882724</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.882724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22349 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       plan_precios_cuidados  cust_request_qty  cust_request_tn  \\\n",
       "0                          0          0.461891        -1.704215   \n",
       "1                          0         -0.046911        -2.039835   \n",
       "2                          0          0.786658        -0.435961   \n",
       "3                          0         -1.703222        -1.074260   \n",
       "4                          0          2.865166         0.273781   \n",
       "...                      ...               ...              ...   \n",
       "21615                      0         -0.652507        -0.792584   \n",
       "21616                      0         -0.268679        -0.649760   \n",
       "21617                      0          0.115148        -0.595870   \n",
       "21618                      0         -0.012794        -0.290890   \n",
       "21619                      0         -1.036335        -0.882724   \n",
       "\n",
       "       close_quarter  cat1  cat2  cat3  close_quarter         y  \n",
       "0                  0     1    10    47              0 -1.576908  \n",
       "1                  0     1    10    47              0 -2.042103  \n",
       "2                  1     1    10    47              1 -0.323111  \n",
       "3                  0     1    10    47              0 -1.117043  \n",
       "4                  0     1    10    47              0  0.353285  \n",
       "...              ...   ...   ...   ...            ...       ...  \n",
       "21615              0     2     6    18              0 -0.792584  \n",
       "21616              1     2     6    18              1 -0.649760  \n",
       "21617              0     2     6    18              0 -0.595870  \n",
       "21618              0     2     6    18              0 -0.290890  \n",
       "21619              1     2     6    18              1 -0.882724  \n",
       "\n",
       "[22349 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(scaled_data[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_data[scaled_data['cat1'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion para preparar los datos y crear el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es predecir 2 dias en el futuro, por lo que la idea es re-armar el dataset. Donde el valor de X sera el conjunto de datos hasta N-2 e Y va a ser N (siendo N la cantidad de ventas para ese producto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data,validation=False):\n",
    "    X, y = [], []\n",
    "    unique_product_ids = data['product_id'].unique()\n",
    "    \n",
    "    max_seq_length = 0\n",
    "    \n",
    "    for product_id in unique_product_ids:\n",
    "        product_data = data[data['product_id'] == product_id].copy()\n",
    "        product_values = product_data[columns].values\n",
    "        \n",
    "        max_seq_length = max(max_seq_length, len(product_values))\n",
    "    \n",
    "    for product_id in unique_product_ids:\n",
    "        product_data = data[data['product_id'] == product_id].copy()\n",
    "        product_values = product_data[columns].values\n",
    "        \n",
    "        pad_length = max_seq_length - len(product_values)\n",
    "        \n",
    "        # Aplicar padding con ceros a la izquierda para igualar la longitud\n",
    "        padded_product_values = np.pad(product_values[:, :-1], ((pad_length, 0), (0, 0)), mode='constant')\n",
    "        \n",
    "        if validation:\n",
    "            X.append(padded_product_values)\n",
    "            y.append(product_id)\n",
    "        else:\n",
    "            # Todas las observaciones menos las últimas dos. Como despues necesito agregar esos 2 registros\n",
    "            # para predecir el future, le agrego un pad left extra de 2 para no romper el shape de la red\n",
    "            X.append(np.pad(padded_product_values, ((2, 0), (0, 0)), mode='constant')[:-2])\n",
    "            y.append(product_values[-1, -1])      # Última observación\n",
    "    \n",
    "    if validation:\n",
    "        return np.array(X), np.array(y), max_seq_length\n",
    "    else:\n",
    "        return np.array(X), np.array(y), max_seq_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la funcion para crear el modelo LSTM, sobre este se ejecutara la optimizacion bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2  # número de pasos de tiempo\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scaled_data[columns].values\n",
    "X, y, max_seq_length = prepare_data(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisamos que la funcion genere registros coherentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  4.61890740e-01, -1.70421544e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -1.57690786e+00],\n",
       "       [ 0.00000000e+00, -4.69107783e-02, -2.03983510e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -2.04210334e+00],\n",
       "       [ 0.00000000e+00,  7.86657667e-01, -4.35961139e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00, -3.23110762e-01],\n",
       "       [ 0.00000000e+00, -1.70322210e+00, -1.07425999e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -1.11704256e+00],\n",
       "       [ 0.00000000e+00,  2.86516600e+00,  2.73781431e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00,  3.53284671e-01],\n",
       "       [ 0.00000000e+00,  1.44701708e+00,  3.54905442e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00,  4.14051901e-01],\n",
       "       [ 0.00000000e+00, -5.99014554e-01, -1.22422686e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -1.25068433e+00],\n",
       "       [ 0.00000000e+00,  2.23728327e+00, -5.68518596e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -4.45444438e-01],\n",
       "       [ 0.00000000e+00, -5.99014554e-01, -3.51369740e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00, -2.76888083e-01],\n",
       "       [ 0.00000000e+00, -1.76817549e+00, -7.82362477e-02,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00,  1.40866583e-01],\n",
       "       [ 0.00000000e+00,  8.94913309e-01,  3.90771836e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00,  6.19540600e-01],\n",
       "       [ 0.00000000e+00, -1.44340856e-02, -1.18431507e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00, -1.18702359e+00],\n",
       "       [ 0.00000000e+00,  7.21704282e-03, -6.77129037e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -7.79891824e-01],\n",
       "       [ 0.00000000e+00, -1.45423413e+00, -1.01800077e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -1.20615411e+00],\n",
       "       [ 0.00000000e+00,  1.67435393e+00,  1.40999356e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00,  1.55962382e+00],\n",
       "       [ 0.00000000e+00, -5.66537861e-01, -5.79961094e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -5.00244944e-01],\n",
       "       [ 0.00000000e+00,  2.12902763e-01, -5.23494287e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -3.55289748e-01],\n",
       "       [ 0.00000000e+00,  6.56750896e-01, -8.62710503e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00, -8.42086248e-01],\n",
       "       [ 0.00000000e+00,  2.34553892e-01,  2.02480217e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00,  2.45142183e-01],\n",
       "       [ 0.00000000e+00,  1.06812234e+00,  1.27153863e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00,  1.36956145e+00],\n",
       "       [ 0.00000000e+00, -3.82503269e-01,  5.27709100e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00,  1.37189132e-01],\n",
       "       [ 0.00000000e+00, -2.09294242e-01,  3.09096946e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00,  3.05077920e+00],\n",
       "       [ 0.00000000e+00,  1.15472685e-01,  1.54894286e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00,  1.41056294e+00],\n",
       "       [ 0.00000000e+00,  1.80426070e-01,  3.11215056e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00,  3.00509403e-01],\n",
       "       [ 0.00000000e+00, -7.18095760e-01, -3.03600364e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -4.16942426e-01],\n",
       "       [ 0.00000000e+00, -7.50572453e-01, -3.93212537e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -4.73681462e-01],\n",
       "       [ 0.00000000e+00,  1.91251635e-01,  4.56098679e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00,  2.45980484e-01],\n",
       "       [ 0.00000000e+00,  4.51065176e-01,  9.41899475e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00,  8.48010304e-01],\n",
       "       [ 0.00000000e+00, -1.38928074e+00,  7.37515359e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00,  7.87270015e-01],\n",
       "       [ 0.00000000e+00, -4.36631090e-01, -6.59302216e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00, -9.81057065e-01],\n",
       "       [ 0.00000000e+00, -4.69107783e-02,  1.02283623e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00,  9.54667872e-01],\n",
       "       [ 0.00000000e+00, -7.72223581e-01, -6.54132969e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -4.66022113e-01],\n",
       "       [ 0.00000000e+00, -4.79933347e-01,  8.66095991e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00,  8.90078894e-01],\n",
       "       [ 0.00000000e+00, -7.50572453e-01,  3.93778350e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00,  5.55016525e-01],\n",
       "       [ 0.00000000e+00, -4.79933347e-01, -6.37905585e-02,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00, -3.30643892e-03],\n",
       "       [ 0.00000000e+00, -3.17549884e-01,  5.95740868e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00,  3.61745379e-01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Muestro todos los registros del ultimo producto\n",
    "unique_product_ids = scaled_data['product_id'].unique()\n",
    "product_data = scaled_data[scaled_data['product_id'] == unique_product_ids[0]] #<= cambiar el indice entre 0 y -1 para ver la diferencia agregada por el padleft\n",
    "product_values = product_data[columns].values\n",
    "display(product_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  4.61890740e-01, -1.70421544e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -4.69107783e-02, -2.03983510e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  7.86657667e-01, -4.35961139e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00],\n",
       "       [ 0.00000000e+00, -1.70322210e+00, -1.07425999e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  2.86516600e+00,  2.73781431e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  1.44701708e+00,  3.54905442e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00],\n",
       "       [ 0.00000000e+00, -5.99014554e-01, -1.22422686e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  2.23728327e+00, -5.68518596e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -5.99014554e-01, -3.51369740e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00],\n",
       "       [ 0.00000000e+00, -1.76817549e+00, -7.82362477e-02,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  8.94913309e-01,  3.90771836e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -1.44340856e-02, -1.18431507e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00],\n",
       "       [ 0.00000000e+00,  7.21704282e-03, -6.77129037e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -1.45423413e+00, -1.01800077e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  1.67435393e+00,  1.40999356e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00],\n",
       "       [ 0.00000000e+00, -5.66537861e-01, -5.79961094e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  2.12902763e-01, -5.23494287e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  6.56750896e-01, -8.62710503e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00],\n",
       "       [ 0.00000000e+00,  2.34553892e-01,  2.02480217e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  1.06812234e+00,  1.27153863e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -3.82503269e-01,  5.27709100e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00],\n",
       "       [ 0.00000000e+00, -2.09294242e-01,  3.09096946e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  1.15472685e-01,  1.54894286e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  1.80426070e-01,  3.11215056e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00],\n",
       "       [ 0.00000000e+00, -7.18095760e-01, -3.03600364e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -7.50572453e-01, -3.93212537e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  1.91251635e-01,  4.56098679e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00],\n",
       "       [ 0.00000000e+00,  4.51065176e-01,  9.41899475e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -1.38928074e+00,  7.37515359e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -4.36631090e-01, -6.59302216e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00],\n",
       "       [ 0.00000000e+00, -4.69107783e-02,  1.02283623e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -7.72223581e-01, -6.54132969e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -4.79933347e-01,  8.66095991e-01,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  1.00000000e+00],\n",
       "       [ 0.00000000e+00, -7.50572453e-01,  3.93778350e-01,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+01,\n",
       "         4.70000000e+01,  0.00000000e+00]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X[0]) #<= cambiar el indice entre 0 y -1 para ver la diferencia agregada por el padleft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3617453793178112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y[0]) #<= cambiar el indice entre 0 y -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def create_model(units, learning_rate, optimizer='adam', dropout=0.1, activation=\"tanh\", depth=2, l2_penalty=1e-6):\n",
    "    display(f\"Creating model with parameters: units={units}, learning_rate={learning_rate}, \"\n",
    "                f\"optimizer={optimizer}, dropout={dropout}, activation={activation}, \"\n",
    "                f\"depth={depth}, l2_penalty={l2_penalty}\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(depth):\n",
    "        if i == 0:\n",
    "            model.add(LSTM(units=units, return_sequences=True, input_shape=(max_seq_length, n_features - 1), activation=activation, kernel_regularizer=l2(l2_penalty)))\n",
    "            model.add(BatchNormalization())\n",
    "        else:\n",
    "            model.add(LSTM(units=units, return_sequences=True, activation=activation, kernel_regularizer=l2(l2_penalty)))\n",
    "            model.add(Dropout(dropout))\n",
    "            model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LSTM(units=units, return_sequences=False, activation=activation, kernel_regularizer=l2(l2_penalty)))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    # Usamos el error cuadratico medio, porque penaliza errores grandes. Como tenemos ciertos\n",
    "    # productos \"estrella\", para los cuales hay mas ventas, y tener un error en lo mismos\n",
    "    # puede implicar una gran diferencia de las estimaciones, decidimos probar con esta funcion de perdida.\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armado de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'depth': [1, 2, 3, 4],#, 5, 6],\n",
    "    'activation': ['relu', 'tanh'], #'selu', 'swish'\n",
    "    'units': [64, 512],\n",
    "    'dropout': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': Categorical(categories=(0.0001, 0.001), prior=None),#0.01\n",
    "    'epochs': [10, 20, 30, 50, 100],\n",
    "    'batch_size': Categorical([32, 128], prior=None),#[32, 64, 128],\n",
    "    'optimizer': ['adam', 'rmsprop', 'sgd'],\n",
    "    'l2_penalty': [1e-6, 1e-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/LaboratorioIII/my_env/lib/python3.10/site-packages/skopt/space/space.py:116: UserWarning: Dimension [64, 512] was inferred to Integer(low=64, high=512, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(64, 512), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "/Users/mmarchetta/Desktop/LaboratorioIII/my_env/lib/python3.10/site-packages/skopt/space/space.py:116: UserWarning: Dimension [1e-06, 0.1] was inferred to Real(low=1e-06, high=0.1, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(1e-06, 0.1), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5) mean_squared_error\n",
    "early_stopping = EarlyStopping(monitor='mean_squared_error', patience=5)\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "model = KerasRegressor(\n",
    "    build_fn=create_model,\n",
    "    verbose=1,\n",
    "    units=64,\n",
    "    learning_rate=0.01,\n",
    "    dropout=0.1,\n",
    "    activation=\"tanh\",\n",
    "    depth=1,\n",
    "    l2_penalty=1e-6,\n",
    "    callbacks = callbacks\n",
    ")\n",
    "\n",
    "# Como ahora cada observacion, representa la serie de un producto, no hace falta usar \n",
    "# un cv especifico de time series, con el cv normal deberia ser suficiente.\n",
    "# cv = TimeSeriesSplit(n_splits=5).split(X)\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    # n_iter=50,\n",
    "    cv=10,\n",
    "    verbose=1,\n",
    "    # n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_search.fit(X, y, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardo los mejores hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = bayes_search.cv_results_['params'][bayes_search.best_index_]\n",
    "display(best_params)\n",
    "\n",
    "best_model = create_model(\n",
    "    units=best_params['units'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    optimizer=best_params['optimizer'],\n",
    "    dropout=best_params['dropout'],\n",
    "    activation=best_params['activation'],\n",
    "    depth=best_params['depth'],\n",
    "    l2_penalty=best_params['l2_penalty'],\n",
    ")\n",
    "best_model.fit(X, y, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1)\n",
    "\n",
    "display(best_params)\n",
    "display(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X)\n",
    "mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los mejores hiperparámetros\n",
    "best_params = bayes_search.cv_results_['params'][bayes_search.best_index_]\n",
    "\n",
    "# Guardar los mejores hiperparámetros en un archivo JSON\n",
    "with open('best_params.json', 'w') as file:\n",
    "    json.dump(best_params, file)\n",
    "\n",
    "print('Los mejores hiperparámetros han sido guardados en best_params.json.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_params.json', 'r') as file:\n",
    "    best_params = json.load(file)\n",
    "\n",
    "# Reconstruir el modelo con los mejores hiperparámetros\n",
    "mejor_modelo = create_model(units=best_params['units'], learning_rate=best_params['learning_rate'], optimizer=best_params['optimizer'], dropout=best_params['dropout'], activation=best_params['activation'], depth=best_params['depth'], l2_penalty=best_params['l2_penalty'])\n",
    "mejor_modelo.fit(X, y, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1)\n",
    "# Verificar la configuración del nuevo modelo\n",
    "print(\"Configuración del nuevo modelo:\")\n",
    "print(mejor_modelo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hago las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = BayesSearchCV.best_params_\n",
    "\n",
    "# best_units = best_params['build_fn__units']\n",
    "# best_dropout_rate = best_params['build_fn__dropout_rate']\n",
    "# best_optimizer = best_params['build_fn__optimizer']\n",
    "\n",
    "# best_model = create_model(units=best_units, dropout_rate=best_dropout_rate, optimizer=best_optimizer)\n",
    "# best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f, product_ids, _ = prepare_data(scaled_data, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_predictions = mejor_modelo.predict(X_f)\n",
    "display(scaled_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_predictions_1d =  scaled_predictions.reshape(-1)\n",
    "display(scaled_predictions_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "    'product_id': product_ids,\n",
    "    'predicted_y': scaled_predictions_1d\n",
    "})\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame predictions_df\n",
    "for index, row in predictions_df.iterrows():\n",
    "    # Obtener el ID del producto y la predicción escalada para este producto\n",
    "    product_id = row['product_id']\n",
    "    scaled_prediction = row['predicted_y']\n",
    "    \n",
    "    # Obtener el escalador correspondiente a 'predicted_y' para este producto\n",
    "    scaler = scalers['y'][(product_id)]\n",
    "    \n",
    "    # Aplicar la inversa del escalador a la predicción 'predicted_y' para este producto\n",
    "    inverse_scaled_prediction = scaler.inverse_transform([[scaled_prediction]])[0][0]\n",
    "    \n",
    "    # Reemplazar la predicción escalada con la predicción invertida en el DataFrame final\n",
    "    predictions_df.at[index, 'predicted_y'] = inverse_scaled_prediction\n",
    "\n",
    "# Guardar el DataFrame final con las predicciones invertidas\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print('Todas las predicciones han sido generadas y guardadas en predictions.csv después de aplicar la inversa de los scalers.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
