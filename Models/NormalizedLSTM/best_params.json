{"activation": "tanh", "batch_size": 128, "depth": 1, "dropout": 0.3, "epochs": 100, "learning_rate": 0.001, "optimizer": "adam", "units": 108}